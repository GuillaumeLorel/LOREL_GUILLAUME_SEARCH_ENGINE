id	titre	auteur	date	url	texte	type	nb_comments	co_auteurs
0	Software Engineering Podcasts & Conference Talks (week 48, 2025)	TechTalksWeekly	2025-11-27T14:16:41Z	https://redd.it/1p81yr4	Hi [r/SoftwareEngineering](https://www.reddit.com/r/SoftwareEngineering/)! Welcome to another post in this series brought to you by [Tech Talks Weekly](https://www.techtalksweekly.io/). Below, you'll find the most notable Software Engineering conference talks and podcasts published this week you need to be aware of:  1. [**‚ÄúWhat Every Software Architect Should Know About Infra? ‚Ä¢ Maciej Jedrzejewski ‚Ä¢ Devoxx Poland 2024‚Äù**](https://youtube.com/watch?v=O9FEkHS1Nac&utm_source=techtalksweekly&utm_medium=email) **Conference** ‚∏± **+600 views** ‚∏± Nov 21, 2025 ‚∏± 00h 00m 00s **tldw:** If you design systems, watch this talk to see how continuous delivery, cloud vs hybrid vs on-prem, choosing cloud-agnostic or provider lock-in and the CAP theorem affect architecture and scalability. 2. [**‚ÄúCode security for software engineers‚Äù**](https://newsletter.pragmaticengineer.com/p/code-security?utm_source=techtalksweekly&utm_medium=email) from [**The Pragmatic Engineer**](https://newsletter.pragmaticengineer.com/podcast) **Podcast** ‚∏± Nov 26, 2025 ‚∏± 01h 07m 38s **tldl:** Learn who really owns security, how dependency risk, CVEs and software composition analysis matter, and where AI helps or creates new risks. 3. [**‚ÄúTeam topologies and the microservice architecture - Chris Richardson - DDD Europe 2025‚Äù**](https://youtube.com/watch?v=S7XqnWz28zw&utm_source=techtalksweekly&utm_medium=email) **Conference** ‚∏± **+400 views** ‚∏± Nov 24, 2025 ‚∏± 00h 00m 00s **tldw:** Learn how to structure teams and services for fast flow. The talk shows which team types you need and how service boundaries should map to team boundaries so you can ship small changes quickly. 4. [**‚ÄúLearn Pandas Fast: 5 Real Data Projects Every Beginner Can Actually Do‚Äù**](https://www.thenerdnook.io/p/5-real-data-projects?utm_source=techtalksweekly&utm_medium=email) from [**The PyPod Chronicles**](https://www.thenerdnook.io/podcast) **Podcast** ‚∏± Nov 20, 2025 ‚∏± 00h 11m 17s **tldl:** Learn Pandas fast with five hands-on projects that show how to clean, group, filter and analyze real datasets you can use at work. Clear step by step code makes it worth a watch. 5. [**‚ÄúBuilding a lightning-fast search engine - Cl√©ment Renault | EuroRust 2025‚Äù**](https://youtube.com/watch?v=ULA1S-FCM1I&utm_source=techtalksweekly&utm_medium=email) **Conference** ‚∏± **+900 views** ‚∏± Nov 21, 2025 ‚∏± 00h 00m 00s **tldw:** An open source search engine built in Rust shows how to get blazing search performance with architecture and techniques for fast indexing and querying.  This post is an excerpt from the latest issue of [**Tech Talks Weekly**](https://www.techtalksweekly.io/) which is a free weekly email with all the recently published Software Engineering podcasts and conference talks. Currently subscribed by +7,200 Software Engineers who stopped scrolling through messy YT subscriptions/RSS feeds and reduced FOMO. Consider subscribing if this sounds useful: [https://www.techtalksweekly.io/](https://www.techtalksweekly.io/)  Please let me know what you think üëá Thank you üôè	Reddit	5	[]
1	What methodology to be used?	nickk21321	2025-11-25T09:14:50Z	https://redd.it/1p670x2	Hi everyone I'm a junior programmer in my company. We are doing a b2c business with crud features, payment, login. Those basic web and app stuff. Nothing very complex. The thing is this company previous developers have had a very bad software design. Whereby everything was hardcoded and each new product entry was just a copy paste of the old script. No rest API for many features. All vanilla PHP from top to bottom of the code. I'm currently working on a new project and my thinking is on how to scale my code for future developers. Meaning if the next product is being developed my code should be a simple matter of plug and play and no more copy and paste scripts. My idea is very basic whereby I want to do control on the data entry side of things via rest API. So the new project developers will just have call this API. And for added validation I'll run cronjob daily to check if data entry is tally.  I saw that there are some methodology like microservices or monolith but in my case I only know building a simple REST API endpoints will do for now. Am I in the right direction or is there something else I need to consider. Hope to hear your thoughts on this. 	Reddit	18	[]
2	How to measure dropping software quality?	b1-88er	2025-11-23T13:46:17Z	https://redd.it/1p4lv9m	My impression is that software is getting worse every year. Whether it‚Äôs due to AI or the monopolistic behaviour of Big Tech, it feels like everything is about to collapse. From small, annoying bugs to high-profile downtimes, tech products just don‚Äôt feel as reliable as they did five years ago.  Apart from high-profile incidents, how would you measure this perceived drop in software quality? I would like to either confirm or disprove my hunch.   Also, do you think this trend will reverse at some point? What would be the turning point? 	Reddit	24	[]
3	Software Engineering Podcasts & Conference Talks (week 47, 2025)	TechTalksWeekly	2025-11-20T15:12:08Z	https://redd.it/1p246c5	Hi r/SoftwareEngineering !  As part of [Tech Talks Weekly](https://www.techtalksweekly.io/), I'll be posting here every week an excerpt from my newsletter containing the most notable Software Engineering conference talks and podcasts that I think you need to be aware of.  If you want to see the complete list of all the talks (beware: it's huge!), you can head to the latest issue of my newsletter ([link](https://www.techtalksweekly.io/)).  To build this list, I'm following over [100 software engineering conferences](https://www.techtalksweekly.io/i/170091550/conferences) and even more podcasts. This means you no longer need to scroll through messy YT subscriptions or RSS feeds!  In addition, I'll periodically post compilations, for example a list of the most-watched Software Engineering talks of 2025 ([see 2024 edition](https://www.techtalksweekly.io/p/100-most-watched-software-engineering)).  The following list includes all the talks and podcasts published in the past 7 days (2025-11-13 - 2025-11-20).  Let's get started!  1. [**‚ÄúHow AI will change software engineering ‚Äì with Martin Fowler‚Äù**](https://newsletter.pragmaticengineer.com/p/martin-fowler?utm_source=techtalksweekly&utm_medium=email) from [**The Pragmatic Engineer**](https://newsletter.pragmaticengineer.com/podcast) **Podcast** ‚∏± Nov 19, 2025 ‚∏± 01h 48m 53s **tldl:** Martin Fowler explains how AI is making coding non deterministic, where LLMs actually help tame legacy and refactoring, and why rigorous testing plus deterministic tooling is still our best bet. Definitely worth listening to. 2. [**‚ÄúArchitect mindset: how to pass System Design Interview ‚Ä¢ Oleksandr Ivanov ‚Ä¢ Devoxx Poland 2024‚Äù**](https://youtube.com/watch?v=SMfwb7_ABp8&utm_source=techtalksweekly&utm_medium=email) **Conference** ‚∏± **+1k views** ‚∏± Nov 14, 2025 ‚∏± 00h 00m 00s **tldw:** This talk gives a practical, research based playbook for succeeding in system design interviews, from generating solution options to steering tradeoff discussions and clearly justifying decisions. 3. [**‚ÄúNetflix‚Äôs Engineering Culture‚Äù**](https://youtube.com/watch?v=sAp9RjO79cU&utm_source=techtalksweekly&utm_medium=email) from [**The Pragmatic Engineer Podcast**](http://localhost:3000/issue-builder#) **Podcast** ‚∏± Nov 12, 2025 ‚∏± 00h 59m 35s **tldl:** See what it really means to be ‚Äúunusually responsible‚Äù, how teams make decisions without layers of approval, build and guardrail Live at global scale, learn from outages, and balance hiring and AI trade-offs. 4. [**‚ÄúThe Past, Present and Future of Programming Languages - Kevlin Henney - ACCU 2025‚Äù**](https://youtube.com/watch?v=8-3QwoAmyuk&utm_source=techtalksweekly&utm_medium=email) **Conference** ‚∏± **+3k views** ‚∏± Nov 14, 2025 ‚∏± 00h 00m 00s **tldw:** See how programming languages encode ways of thinking, why progress feels slow, and how trends like FOSS and LLMs might reshape code. 5. [**‚ÄúAlgorithms Demystified - Dylan Beattie - NDC Copenhagen 2025‚Äù**](https://youtube.com/watch?v=QJJb7cC3CGs&utm_source=techtalksweekly&utm_medium=email) **Conference** ‚∏± **+1k views** ‚∏± Nov 19, 2025 ‚∏± 00h 00m 00s **tldw:** This talk makes core algorithms intuitive, shows where they actually apply in real projects from networks to autocorrect, and is worth watching if you want to stop freezing when someone says ‚Äúuse Dijkstra‚Äù. 6. [**‚ÄúMicro-Frontends: Stop Building a Distributed Monolith! (Scale with Conway‚Äôs Law)‚Äù**](https://youtube.com/watch?v=YBkaO0TkNaA&utm_source=techtalksweekly&utm_medium=email) **Conference** ‚∏± **<100 views** ‚∏± Nov 20, 2025 ‚∏± 00h 00m 00s **tldw:** Why you‚Äôre often just assembling libraries, why reusability is a form of coupling, and how a decisions framework plus a Frontend Discovery Service can finally enable independent deploys and canary releases, and it‚Äôs worth watching. 7. [**‚ÄúWhat‚Äôs new in AWS Lambda - Julian Wood‚Äù**](https://youtube.com/watch?v=fPygxaFZgeI&utm_source=techtalksweekly&utm_medium=email) **Conference** ‚∏± **<100 views** ‚∏± Nov 14, 2025 ‚∏± 00h 00m 00s **tldw:** Nice demo of new features like remote debugging, DX improvements, and real-world scaling tricks, making this a must-watch if you run or build serverless systems. 8. [**‚Äú#239 - Taming Your Technical Debt: Mastering the Trade-Off Problem - Andrew Brown‚Äù**](https://podcasters.spotify.com/pod/show/techleadjournal/episodes/239---Taming-Your-Technical-Debt-Mastering-the-Trade-Off-Problem---Andrew-Brown-e3b0852?utm_source=techtalksweekly&utm_medium=email) from [**Tech Lead Journal**](https://techleadjournal.dev/) **Podcast** ‚∏± Nov 17, 2025 ‚∏± 01h 06m 29s **tldl:** Technical debt isn‚Äôt mainly a coding problem but a trade-off tangled in human bias and incentives; watch for the Technical Debt Onion, Ulysses contracts, and practical systems-thinking tactics I think will be helpful. 9. [**‚ÄúWhy Postgres? and why now? with Claire Giordano‚Äù**](https://www.hanselminutes.com/?utm_source=techtalksweekly&utm_medium=email) from [**Hanselminutes**](https://www.hanselminutes.com/) **Podcast** ‚∏± Nov 13, 2025 ‚∏± 00h 36m 11s **tldl:** Postgres quietly became the world‚Äôs favorite database, and this talk breaks down how its design and open-source community keep it winning in the age of AI and hyperscale data, worth a watch. 10. [**‚ÄúWhat‚Äôs Coming in TypeScript 6/7 | Daniel Rosenwasser | Jake Bailey | Ep 43B‚Äù**](https://share.transistor.fm/s/ad05eae6?utm_source=techtalksweekly&utm_medium=email) from [**TypeScript.fm - The Friendly Show for TypeScript Developers**](https://typescript.fm/) **Podcast** ‚∏± Nov 13, 2025 ‚∏± 01h 09m 01s **tldl:** TypeScript 6 and 7 push smarter defaults, make ES2024 the default target, tighten DOM typings, and introduce a new compiler API with a Go port in progress, module resolution, WASM embedding, and the real performance tradeoffs you should be aware of. 11. [**‚ÄúModern Architecture 101 for New Engineers & Forgetful Experts - Jerry Nixon - NDC Copenhagen 2025‚Äù**](https://youtube.com/watch?v=WRg13Ze_UpY&utm_source=techtalksweekly&utm_medium=email) **Conference** ‚∏± **+1k views** ‚∏± Nov 19, 2025 ‚∏± 00h 00m 00s **tldw:** See the common modern patterns for scalability, security, integration, and maintainability. 12. [**‚ÄúThe New Realities of SaaS: Why Building is Harder Than Ever - Luis Rubiera - NDC Copenhagen 2025‚Äù**](https://youtube.com/watch?v=ccs-6TOXFmU&utm_source=techtalksweekly&utm_medium=email) **Conference** ‚∏± **+500 views** ‚∏± Nov 17, 2025 ‚∏± 00h 00m 00s **tldw:** Creating SaaS today is far more than shipping features; this talk explains the operational, legal, and geopolitical realities you must handle to actually launch and scale in 2025.  **Tech Talks Weekly** is a free weekly email with all the recently published Software Engineering podcasts and conference talks. Currently subscribed by +7,200 Software Engineers who stopped scrolling through messy YT subscriptions/RSS feeds and reduced FOMO. Consider subscribing if this sounds useful: [https://www.techtalksweekly.io/](https://www.techtalksweekly.io/)  Please let me know what you think about this format üëá Thank you üôè	Reddit	3	[]
4	Creating an SDK from a Monorepo	Reasonable-Tour-9719	2025-11-19T11:14:21Z	https://redd.it/1p13uf3	We have a monorepo setup, and we have created an SDK in that which uses some of the code from different modules across the repository, along with some external dependencies like Guice, Maven repositories.   Now, inside the monorepo the SDK can be used easily, but when we try to use the SDK in any module outside the monorepo, we are facing several challenges.   First of all, the size of the SDK, the fat-jar created comes out to be 150Mb, which is too much for a simple SDK   For this, we are thinking of abstracting out as much as possible in the SDK, but this will require the modules to then implement everything, which we do not want, since that would receive resistance from the modules   Another issue is the dependency injection issue, since the SDK use Guice, and expects dependencies to be present in the Guice Dependency Graph, all the modules which do not use Guice(for example-a Spring Boot project) will also have to bind the dependencies using Guice so that they can be fetched in the SDK.  Could you guys please suggest any papers, or any precendence in the industry, which can show what are the best practices to follow when creating an SDK, how different frameworks for Dependency Injection are bridged, I do not need suggestions to use any actual tools, just a reference to how it is actually done in the industry?   Thanks	Reddit	0	[]
5	How to setup QA benchmark?	maskicz	2025-11-12T22:03:42Z	https://redd.it/1ovhf26	"# Description of my Company  We have 10+ teams and each has around 5 devs + QA engineer. Each tester works independently within the team. Some test manually, others write automated tests. They usually determine what and how to test together with the developers. Product owners do not usually have any quality requirements. Everything ""must work.""  Currently, we only monitor the percentage of quarterly targets achieved, but quality is not taken into account in any way.¬†  At the same time, we do not have any significant feedback from users indicating a quality problem.¬†  # My Task  I was tasked with preparing a strategy for unifying QA across teams, and I needed to figure out how to do it. I thought I could create a metric that would describe our quality level and set a strategy based on that. Maybe the metric will show me what to focus on, or maybe it will show me that we don't actually need to address anything and a strategy is not necessary.¬†  # My questions  1. Am I right in thinking that we need some kind of metric to work from? 2. Is the DORA DevOps metric the right one? 3. Is there another way to measure QA?¬†"	Reddit	2	[]
6	Sacred Fig Architecture (FIG): an adaptive, feedback-driven alternative to Hexagonal ‚Äî thoughts?	Resident-Escape-7959	2025-11-12T19:47:29Z	https://redd.it/1ovdpe9	Hey everyone,  I‚Äôve been working on¬†**Sacred Fig Architecture (FIG)**¬†‚Äî an evolution of Hexagonal that treats a system like a living tree:  * **Trunk**¬†= pure domain core * **Roots**¬†= infrastructure adapters * **Branches**¬†= UI/API surfaces * **Canopy**¬†= composition & feature gating * **Aerial Roots**¬†= built-in telemetry/feedback that adapts policies at runtime  Key idea: keep the domain pure and testable, but make¬†**feedback a first-class layer**¬†so the system can adjust (e.g., throttle workers, change caching strategy) without piercing domain boundaries. The repo has a whitepaper, diagrams, and a minimal example to try the layering and contracts.¬†  Repo:¬†[github.com/sanjuoo7live/sacred-fig-architecture](http://github.com/sanjuoo7live/sacred-fig-architecture)  What I‚Äôd love feedback on:  1. Does the¬†**Aerial Roots**¬†layer (feedback ‚Üí canopy policy) feel like a clean way to add adaptation without contaminating the domain? 2. Are the¬†**channel contracts**¬†(typed boundaries) enough to keep Branches/Roots from drifting into Trunk concerns? 3. Would you adopt this as an¬†**architectural model/pattern**¬†alongside Hexagonal/Clean, or is it overkill unless you need runtime policy adaptation? 4. Anything obvious missing in the minimal example or the guardrail docs (invariants/promotion policy)?¬†  Curious where this breaks, and where it shines. Tear it apart! üå≥	Reddit	0	[]
7	Designing Benchmarks for Evaluating Adaptive and Memory-Persistent Systems	NoDimension8116	2025-11-12T07:22:49Z	https://redd.it/1ouxrnb	Software systems that evolve or adapt over time pose a unique engineering challenge ‚Äî how do we evaluate their long-term reliability, consistency, and learning capability?    I‚Äôve been working on a framework that treats adaptive intelligence as a measurable property, assessing systems across dimensions like memory persistence, reasoning continuity, and cross-session learning.    The goal isn‚Äôt to rank models but to explore whether our current evaluation practices can meaningfully measure evolving software behavior.    The framework and early findings are published here for open analysis: [dropstone.io/research/agci-benchmark](https://www.dropstone.io/research/agci-benchmark)    I‚Äôd be interested to hear how others approach evaluation or validation in self-adapting, learning, or context-retaining systems ‚Äî especially from a software engineering perspective.	Reddit	3	[]
8	Agile Methodologies Master Thesis Survey	Banana_Crusader00	2025-11-11T00:07:08Z	https://redd.it/1ott3w0	Hi there! With mods permission!      I am a student at Merito University in Poland, and I am conducting a survey for my master‚Äôs thesis, and would love your input! The purpose of the survey is to understand which parts of Agile methodologies most often cause difficulties in practice and what might be the reasons behind them.  The survey is intended for professionals working with Agile methodologies such as Scrum, SAFe, or Kanban, but other methodologies are also welcome! All responses are anonymous and will be used only for academic purposes.  [https://docs.google.com/forms/d/e/1FAIpQLSdBNlPzP81jmWcvQUh9GkiFch\_u88f3tBqpXk0WZxM5exstgg/viewform?usp=publish-editor](https://docs.google.com/forms/d/e/1FAIpQLSdBNlPzP81jmWcvQUh9GkiFch_u88f3tBqpXk0WZxM5exstgg/viewform?usp=publish-editor)	Reddit	2	[]
9	Scalability Driven Design and Estimations	Remote-Classic-3749	2025-11-04T05:25:22Z	https://redd.it/1ony49o	When designing a backend or distributed system, we usually sketch diagrams (Lucidchart, Excalidraw, Mermaid, etc.) ‚Äî but those are static.  To really validate scalability or latency trade-offs, we either rely on experience or spin up infra to test.  Curious to know how you handle this - Do you make any rough estimations before testing? Or do you just build and measure? 	Reddit	5	[]
10	How do you practice TDD/outside-in development when it's unclear how you should describe your test scenario in code?	LingonberrySpecific6	2025-10-19T10:29:01Z	https://redd.it/1oakeq5	I'm trying to prototype how NPCs should behave in my game, but it's unclear what I should focus on. I have a general idea of what I want but not how to make it, so I thought to write a simple scenario, make the simplest implementation that would satisfy it, and repeat that until I uncover a good implementation and API.  (This is not relevant to the question, but for context, I'm imagining a kind of event-based utility AI that reacts to events by simulating their likely outcomes based on the actor's knowledge, judging the outcome based on the actor's drives and desires, deciding on a goal, and then iterating through the actor's possible actions and evaluating their outcomes to find the one most likely to achieve it.)  However, I found I can't even translate the simplest scenario into code.      Given a bear is charging at Bob and Bob has bear spray,     When Bob notices the bear (receives the event),     Then he should use the bear spray.  How do I describe this? Do I make an `Actor` class for both Bob and the bear? Do I instantiate them as objects in the test itself or make a `Scene` class that holds them? How do I create the charge event and communicate it to Bob?  There are a myriad ways to implement this, but I don't know which to pick. I'm facing the same problem I'm trying to fix with outside-in development when doing outside-in development.	Reddit	15	[]
11	What makes software engineers stay away from cost observability & optimization?	n4r735	2025-10-17T19:00:32Z	https://redd.it/1o96unq	"The past few weeks I‚Äôve been exposed to FinOps practices and something seems off:  1. The predominant thinking about engineering teams is that while they might care about costs, their #1 priority is still performance/scalability. Only after that‚Äôs stable, cost optimization becomes a topic (usually when pain is felt).  2.	‚Å†At the same time FinOps platforms are advocating for shift-left. Well, if engineers don‚Äôt care about costs during the initial stages of a project, what realistic chances do we still have for shift-left adoption? Isn‚Äôt this just lip-service?  3.	‚Å†Most FinOps platforms I‚Äôve seen (beginner here, so I might be in the wrong) are not very engineering-friendly because they‚Äôre expensive and focused on enterprise customers; their buyer is not the engineer, but the CFO/CTO/CIO; so naturally they‚Äôre dashboard-first vs. code-first.  Curios on your perspective as software engineers on the cost matter üôèüôá"	Reddit	22	[]
12	Should Information Technology have a unified licensing body? Should Information Technology practices be monitored and regulated?	Longjumping_Book_758	2025-10-10T06:42:01Z	https://redd.it/1o2rnsn	Hello, this topic came up in my Social Issues and Professional Practice class. We had a debate if IT practices should be formally regulated not just through company policies or certifications, but through an official licensing body, much like doctors or engineers have. Right now, anyone, with a lot of effort, can deploy systems that can compromise the safety of the people due to how accessible IT is, especially with the advent of AI. What do you guys think?	Reddit	23	[]
13	New Book: Effective Behavior-Driven Development	ManningBooks	2025-10-07T10:08:11Z	https://redd.it/1o08rtc	Hey everyone,  Stjepan from Manning here. Firstly, I'd like to thank the moderators for letting me post this.   I wanted to share something that might interest folks here who care about building the *right* software, not just shipping fast ‚Äî Manning just released ***Effective Behavior-Driven Development*** by **G√°sp√°r Nagy** and **Sebastian Rose**.  I‚Äôve been around long enough to see ‚ÄúBDD‚Äù mentioned in conference talks, code reviews, and team retros, but it‚Äôs still one of those practices that‚Äôs *often misunderstood* or implemented halfway. What I liked about this book (and why I thought it might be worth posting here) is that it tackles **modern BDD as it‚Äôs actually practiced today**, not as a buzzword.  It breaks BDD down into its three key pillars ‚Äî **Discovery, Formulation, and Automation** ‚Äî and treats them as distinct, complementary skills:  * **Discovery:** Running example mapping sessions and structured conversations that build real shared understanding between devs, testers, and stakeholders. * **Formulation:** Turning those examples into clear, testable specifications written in business-friendly language. * **Automation:** Building living documentation and maintainable automation patterns that evolve with the system.  The authors (G√°sp√°r and Sebastian) both have deep hands-on BDD experience and tool-building backgrounds, and they don‚Äôt just focus on Gherkin or Cucumber syntax ‚Äî it‚Äôs about *why* you‚Äôre doing BDD in the first place, not just how to write ‚ÄúGiven/When/Then.‚Äù  Here‚Äôs the link if you want to check it out:   üëâ [Effective Behavior-Driven Development | Manning Publications](https://hubs.la/Q03MtN-h0)  üöÄ Use the community discount code to save 50%: **MLNAGY50RE**  Personally, I‚Äôve seen BDD work beautifully when teams use it as a **communication framework** rather than just a testing style ‚Äî especially in distributed or cross-functional teams where assumptions kill projects.  Curious how others here feel:  * Have you used BDD effectively in a real-world software engineering context? * Did it actually help align teams?  Would love to hear how it‚Äôs worked (or not worked) in your organizations.  Thank you.  Cheers,	Reddit	10	[]
14	Cardinality between APIs and resources?	ChallengeFit2766	2025-09-23T08:47:53Z	https://redd.it/1noadc0	"For instance say for an e-commerce application we need the following endpoints:  GET       /user/{id}          : Get user with ""id""  POST    /user                 : Create new user  PUT      /user/{id}           : Update user with ""id""  DELETE /user/{id}           : Delete user with ""id""  GET      /product/{id}      : Get product with ""id""  POST    /product            : Create new product  PUT      /product/{id}     : Update product with ""id""  DELETE /product/{id}     : Delete product with ""id""  Could 'user' and 'product' endpoints be considered part of the same single API or do they have to be considered two separate APIs? Every API example I've seen out there operates on just a single resource."	Reddit	21	[]
15	Driving Complex Decisions	OutsidePosition4250	2025-09-22T19:38:55Z	https://redd.it/1nnt3zo	I created a blog post for my software engineering team this weekend related to driving complex decisions:¬†[https://garrettdbates.com/driving-complex-decisions](https://garrettdbates.com/driving-complex-decisions)  It covers some mental models, practical steps, and pitfalls to avoid. Thought it might be useful for this community as well.  Also in the spirit of the article - please rip it to shreds and/or provide your own insights on how engineers can navigate complex decisions more gracefully.	Reddit	9	[]
16	A Software Engineer‚Äôs Guide to Observability (Intro + Logging)	Outside_Laugh_4660	2025-09-17T13:11:27Z	https://redd.it/1nja6s3	At Blueground we‚Äôve been rethinking observability from the ground up. Instead of just buying tools, we wanted to set principles and practices that scale across dozens of teams.  We‚Äôve started a blog series to document the journey:  * The [intro post](https://engineering.theblueground.com/a-software-engineers-guide-to-observability/) explains why observability matters now, the gaps we faced, and what the series will cover (logging, metrics, tracing, dashboards, SLOs, etc). * [Part 1 (Logging)](https://engineering.theblueground.com/a-software-engineers-guide-to-observability-part-1-logging/) dives into concrete lessons:    * Logs are primarily for troubleshooting, not alerting.    * Standardization across teams is invaluable.    * Good logs provide the right context and will increasingly serve AI systems as much as humans.  I‚Äôd love to hear how others approach this, do you enforce logging schemas and policies, or let each team handle it their own way?	Reddit	11	[]
17	Is this a good way to structure engineering reports, or am I overthinking it?	Andrew_Tit026	2025-09-15T07:46:40Z	https://redd.it/1nhdqm7	I‚Äôve been experimenting with how to summarize engineering work in a way leadership actually understands.  My current take looks like this:  * **Investment** \- Where effort goes (features, bugs, infra, tech debt) * **Delivery** \- Trendlines over time * **Custom views** \- Tailored to what execs care about (e.g., product vs. infra split)  This feels more useful than dumping a bunch of Jira burndown charts. But I‚Äôm not sure if this breakdown is *too simplistic* or actually the right level.  how do you structure their reporting, would love to compare notes.	Reddit	8	[]
18	What Happens When You Decide to Reinvent the Wheel?	InternationalAd3651	2025-09-13T21:40:36Z	https://redd.it/1ng6qzi	You might just learn something. Like, what started as following a tutorial from a Youtube video, to learning about the docker snap package, to learning about the ease of Coolify, to getting my butt handed to me on a silver platter, and eventually developing a framework for myself. [Come along with me into an insightful journey!](https://blog.kalilarosa.xyz/posts/introducing-egg/)	Reddit	14	[]
19	How do you actually use and/or implement TDD?	MacroProcessor	2025-09-07T05:02:22Z	https://redd.it/1naidd4	"I'm familiar with Test-Driven Development, mostly from school. The way we did it there, you write tests for what you expect, run them red, then code until they turn green.  I like the *philosophy* of TDD, and there's seemingly a lot of benefits--catches unexpected bugs, easier changes down the road, clear idea of what you have to do before a feature is ""complete""--but in actuality, what I see happening (or perhaps this is my own fault, as it's what I do) is complete a feature, then write a test to match it to make sure it doesn't break in the future. I know this isn't ""pure"" TDD, but it does get most of the same benefit, right? I know that pure TDD would probably be better, but I don't currently have the context at my work to be able to cleanly and perfectly write the tests or modify existing tests to make the test match the feature exactly. Sometimes it's because I don't fully understand the test, sometimes it's because the feature is ambiguous and we figure it out as we go along. Do I just need to spend more time upfront understanding everything and writing/re-writing the test?   I should mention that we usually have a test *plan* in place before we begin coding, but we don't write the tests to fail, we write the feature first and then write the test to pass in accordance with the feature. Is this bad?  The second part is: I'm building a personal project that I plan on being fairly large, and would like to have it be well-tested, for the aforementioned benefits. When you do this, do you actually sit down and write failing tests first? Do you write all of the failing tests and then do all of the features? Or do you go test-by-test, feature-by-feature, but just write the tests first?   Overall, how should I make my workflow more test-driven? "	Reddit	131	[]
20	Why did actor model not take off?	FatefulDonkey	2025-09-05T08:08:01Z	https://redd.it/1n8xhz5	There seems to be numerous actor model frameworks (Akka) but I've never run into any company actually using them. Why is that?	Reddit	51	[]
21	Legacy software owners: What was your single biggest challenge before modernizing or migrating?	Inside_Topic5142	2025-09-04T07:43:09Z	https://redd.it/1n81ze3	Hi everyone,  I‚Äôm curious about the real-world challenges teams face with legacy systems. If you‚Äôve been through a modernization or migration project (or considered one!), I‚Äôd love to hear your experiences.  Some key questions I'd like you to answer:  * What was the most pressing challenge your team faced before deciding to modernize or migrate? (Technical, operational, organizational... anything counts) * Were there unexpected hurdles that influenced your decision or approach? * What lessons would you share for teams still running legacy systems?  I‚Äôm looking for honest, experience-driven insights rather than theory. Any stories or takeaways are appreciated!  Thanks in advance for sharing your perspective.	Reddit	81	[]
22	DDD- Should I model products/quantities as entities or just value objects	remster85	2025-08-27T18:26:22Z	https://redd.it/1n1lpqs	I‚Äôm working on a system that needs to pull **products + their quantities** from a few different upstream systems (around 4 sources, \~1000 products each).  * Two sources go offline after **5:00 PM** ‚Üí that‚Äôs their end-of-day. * The others stay up until **6:00 PM** ‚Üí that‚Äôs their end-of-day. * For each source, I want to keep:    * One **intraday capture** (latest fetch).   * One **end-of-day capture** per weekday (so I can look back in history).  The goal is to **reconcile the numbers across sources** and show the results in a **UI** (grid by product √ó source).  üëâ The only hard invariant: products being compared must come from captures taken within **5 minutes of each other**.  * Normally I can just use a global ‚Äúcapture time per source.‚Äù * But if there are integration delays, I might also need to show **per-product capture times** in the UI.  What I‚Äôm unsure about is the modeling side:  * Should each **product quantity** be an **entity/aggregate** (with identity + lifecycle)? * Or just a **value object** inside a capture (simpler, since data is small and mostly immutable once pulled)?  Other open points:  * One `Capture` type with a flag `{intraday | eod}`, or split them into two? * Enforce the 5-minute rule at **query time** (compose comparable sets) vs at **write time** (tag cohorts)?  **Success criteria:**  * Users can see product quantities clearly. * They can see *when* the data was captured (at least per source, maybe per product if needed). * Comparisons across sources respect the 5-minute rule.  Would love to hear how you‚Äôd approach this ‚Äî would you go full DDD with aggregates here, or keep it lean with value objects and let the captures/snapshots do the heavy lifting? 	Reddit	11	[]
23	Is Pub/Sub pattern Event-Driven Architecture?	iAmDeBruyne	2025-08-16T12:33:55Z	https://redd.it/1mrrhfk	Is Pub/Sub pattern Event-Driven Architecture? What the most popular ways and models of EDA implementation today ?   Thanks	Reddit	24	[]
24	Is software architecture becoming too over-engineered for most real-world projects?	Inside_Topic5142	2025-08-05T07:49:30Z	https://redd.it/1mi13h4	Every project I touch lately seems to be drowning in layers... microservices on top of microservices, complex CI/CD pipelines, 10 tools where 3 would do the job.  I get that scalability matters, but I‚Äôm wondering: are we building for edge cases that may never arrive?  Curious what others think. Are we optimizing too early? Or is this the new normal?	Reddit	339	[]
25	Handling concurrent state updates on a distributed system	tonyromero	2025-08-02T12:27:45Z	https://redd.it/1mfn9bk	My system includes horizontally scaled microservices named Consumers that reads from a RabbitMQ queue. Each message contains state update on resources (claims) that triggers an expensive enrichment computation (like 2 minutes) based on the fields updates.  To race conditions on the claims I implemented a status field in the MongoDB documents, so everytime I am updating a claim, I put it in the WORKING state. Whenever a Consumer receives a message for a claim in a WORKING state, it saves the message in a dedicated Mongo collection and then those messages are requeued by a Cronjob that reads from that collection.  I know that I cannot rely on the order in which messages are saved in Mongo and so it can happen that a newer update is overwritten by an older one (stale update).  Is there a way to make the updates idempotent? I am not in control of the service that publishes the messages into the queue as one potential solution is to attach a timestamp that mark the moment the message is published. Another possible solution could be to use a dedicated microservice that reads from the queue and mark them without horizontally scale it.  Are there any elegant solution? Any book recommendation that deals with this kind of problems?	Reddit	3	[]
26	Decentralized Module Federation Microfrontend Architecture	Accurate-Screen8774	2025-07-21T10:01:38Z	https://redd.it/1m5czdw	"im working on a webapp and im being creative on the approach. it might be considered over-complicated (because it is), but im just trying something out. its entirely possible this approach wont work long term. i see it as there is one-way-to-find-out. i dont reccomend this approach. just sharing what im doing      how it will be architected:¬†[https://positive-intentions.com/blog/decentralised-architecture](https://positive-intentions.com/blog/decentralised-architecture)  some benefits of the approach:¬†[https://positive-intentions.com/blog/statics-as-a-chat-app-infrastructure](https://positive-intentions.com/blog/statics-as-a-chat-app-infrastructure)  i find that module federation and microfronends to generally be discouraged when i see posts, but it i think it works for me in my approach. im optimisic about the approach and the benefits and so i wanted to share details.   when i serve the federated modules, i can also host the storybook statics so i think this could be a good way to document the modules in isolation.  * cryptography modules - [https://cryptography.positive-intentions.com/?path=/docs/cryptography-introduction--docs](https://cryptography.positive-intentions.com/?path=/docs/cryptography-introduction--docs) * p2p framework - [https://p2p.positive-intentions.com/?path=/docs/e2e-tests-connectionstatus--docs](https://p2p.positive-intentions.com/?path=/docs/e2e-tests-connectionstatus--docs)  this way, i can create microfrontends that consume these modules. i can then share the functionality between apps. the following apps are using a different codebase from each other (there is a distinction between these apps in open and close source). sharing those dependencies could help make it easier to roll out updates to core mechanics.  * p2p chat - [https://chat.positive-intentions.com](https://chat.positive-intentions.com) * p2p file transfer - [https://file.positive-intentions.com](https://file.positive-intentions.com)  the functionality also works when i create an android build with Tauri. this could also lead to it being easier to create new apps that could use the modules created.  im sure there will be some distinct test/maintainance overhead, but depending on how its architected i think it could work and make it easier to improve on the current implementation.  everything about the project is far from finished. it could be see as this is a complicated way to do what npm does, but i think this approach allows for a greater flexibility by being able to separating open and close source code for the web. (of course as javascript, it will always be ""source code available"". especially in the age of AI, im sure its possible to reverse-engineer it like never before.)"	Reddit	0	[]
27	Release cycles, ci/cd and branching strategies	fluffkiddo	2025-07-09T03:23:47Z	https://redd.it/1lv65n3	For all mid sized companies out there with monolithic and legacy code, how do you release?  I work at a company where the release cycle is daily releases with a confusing branching strategy(a combination of trunk based and gitflow strategies). A release will often have hot fixes and ready to deploy features. The release process has been tedious lately  For now, we mainly 2 main branches (apart from feature branches and bug fixes). Code changes are first merged to dev after unit Tests run and qa tests if necessary, then we deploy code changes to an environment daily and run e2es and a pr is created to the release branch. If the pr is reviewed and all is well with the tests and the code exceptions, we merge the pr and deploy to staging where we run e2es again and then deploy to prod.  Is there a way to improve this process? I'm curious about the release cycle of big companies l	Reddit	18	[]
28	How We Refactored 10,000 i18n Call Sites Without Breaking Production	patreon-eng	2025-07-03T17:17:15Z	https://redd.it/1lqs7f8	Patreon‚Äôs frontend platform team recently overhauled our internationalization system‚Äîmigrating every translation call, switching vendors, and removing flaky build dependencies. With this migration, we cut bundle size on key pages by nearly 50% and dropped our build time by a full minute.  Here's how we did it, and what we learned about global-scale refactors along the way:  [https://www.patreon.com/posts/133137028](https://www.patreon.com/posts/133137028)	Reddit	1	[]
29	[R] DES vs MAS in Software Supply Chain Tools: When Will MAS Take Over? (is Discrete Event Simulation outdated)	Hopeful_Yam_6700	2025-07-03T22:33:20Z	https://redd.it/1lr03zd	I am researching software supply chain optimization tools (think CI/CD pipelines, SBOM generation, dependency scanning) and want your take on the technologies behind them. I am comparing Discrete Event Simulation (DES) and Multi-Agent Systems (MAS) used by vendors like JFrog, Snyk, or Aqua Security. I have analyzed their costs and adoption trends, but I am curious about your experiences or predictions. Here is what I found.  Overview:  - Discrete Event Simulation (DES): Models processes as sequential events (like code commits or pipeline stages). It is like a flowchart for optimizing CI/CD or compliance tasks (like SBOMs).  - Multi-Agent Systems (MAS): Models autonomous agents (like AI-driven scanners or developers) that interact dynamically. Suited for complex tasks like real-time vulnerability mitigation.  Economic Breakdown For a supply chain with 1000 tasks (like commits or scans) and 5 processes (like build, test, deploy, security, SBOM):  -DES:    - Development Cost: Tools like SimPy (free) or AnyLogic (about $10K-$20K licenses) are affordable for vendors like JFrog Artifactory.    - Computational Cost: Scales linearly (about 28K operations). Runs on one NVIDIA H100 GPU (about $30K in 2025) or cloud (about $3-$5/hour on AWS).    - Maintenance: Low, as DES is stable for pipeline optimization.  Question: Are vendors like Snyk using DES effectively for compliance or pipeline tasks?  -MAS:    - Development Cost:   Complex frameworks like NetLogo or AI integration cost about $50K-$100K, seen in tools like Chainguard Enforce.   - Computational Cost:   Heavy (about 10M operations), needing multiple GPUs or cloud (about $20-$50/hour on AWS).   - Maintenance: High due to evolving AI agents.  Question: Is MAS‚Äôs complexity worth it for dynamic security or AI-driven supply chains?  Cost Trends I'm considering (2025):  - GPUs: NVIDIA H100 about $30K, dropping about 10% yearly to about $15K by 2035.  - AI: Training models for MAS agents about $1M-$5M, falling about 15% yearly to about $0.5M by 2035.  - Compute: About $10^-8 per Floating Point Operation (FLOP), down about 10% yearly to about $10^-9 by 2035.  Forecast (I'm doing this for work):   When Does MAS Overtake DES?  Using a logistic model with AI, GPU, and compute costs:  - Trend: MAS usage in vendor tools grows from 20% (2025) to 90% (2035) as costs drop.  - Intercept: MAS overtakes DES (50% usage) around 2030.2, driven by cheaper AI and compute.  - Fit: R¬≤ = 0.987, but partly synthetic data‚Äîreal vendor adoption stats would help!  Question: Does 2030 seem plausible for MAS to dominate software supply chain tools, or are there hurdles (like regulatory complexity or vendor lock-in)?  What I Am Curious About  - Which vendors (like JFrog, Snyk, Chainguard) are you using for software supply chain optimization, and do they lean on DES or MAS?  - Are MAS tools (like AI-driven security) delivering value, or is DES still king for compliance and efficiency?  - Any data on vendor adoption trends or cost declines to refine this forecast?  I would love your insights, especially from DevOps or security folks! 	Reddit	5	[]
30	Microservices Architecture Decision: Entity based vs Feature based Services	Faceless_sky_father	2025-06-25T10:58:54Z	https://redd.it/1lk0nrc	Hello everyone , I'm architecting my first microservices system and need guidance on service boundaries for a multi-feature platform  Building a Spring Boot backend that encompasses three distinct business domains:  * **E-commerce Marketplace**¬†(buyer-seller interactions) * **Equipment Rental Platform**¬†(item rentals) * **Service Booking System**¬†(professional services)  # Architecture Challenge  Each module requires similar core functionality but with domain-specific variations:  * Product/service catalogs (with different data models per domain) but only slightly * Shopping cart capabilities * Order processing and payments * User review and rating systems  # Design Approach Options  **Option A: Shared Entity + feature Service Architecture**  * Centralized services:¬†`ProductService`,¬†`CartService`,¬†`OrderService`,¬†`ReviewService , Makretplace service (for makert place logic ...) ...` * Single implementation handling all three domains * Shared data models with domain-specific extensions  **Option B: Feature-Driven Architecture**  * Domain-specific services:¬†`MarketplaceService`,¬†`RentalService`,¬†`BookingService` * Each service encapsulates its own cart, order, review, and product logic * Independent data models per domain  # Constraints & Considerations  * Database-per-service pattern (no shared databases) * Greenfield development (no legacy constraints) * Need to balance code reusability against service autonomy * Considering long-term maintainability and team scalability  # Seeking Advice  Looking for insights for:  * Which approach better supports independent development and deployment? * how many databases im goign to create and for what ? all three productb types in one DB or each with its own DB? * How to handle cross-cutting concerns in either architecture? * Performance and data consistency implications? * Team organization and ownership models on git ?  Any real-world experiences or architectural patterns you'd recommend for this scenario?	Reddit	23	[]
31	How I implemented an Undo/Redo system in a large complex visual application	mlacast	2025-06-20T20:38:11Z	https://redd.it/1lgbjr1	"Hey everyone!  A while ago I decided to design and implement an undo/redo system for [Alkemion Studio](https://alkemion.com), a visual brainstorming and writing tool tailored to TTRPGs. This was a very challenging project given the nature of the application, and I thought it would be interesting to share how it works, what made it tricky and some of the thought processes that emerged during development. (To keep the post size reasonable, I will be pasting the code snippets in a comment below this post)  The main reason for the difficulty, was that unlike linear text editors for example, users interact across multiple contexts: moving tokens on a board, editing rich text in an editor window, tweaking metadata‚Äîall in different UI spaces. A context-blind undo/redo system risks not just confusion but serious, sometimes destructive, bugs.  The guiding principle from the beginning was this:  *Undo/redo must be intuitive and context-aware. Users should not be allowed to undo something they can‚Äôt see.*  **Context**  To achieve that we first needed to define **context**: *where the user is in the application and what actions they can do*.  In a linear app, having a single undo stack might be enough, but here that architecture would quickly break down. For example, changing a Node‚Äôs featured image can be done from both the Board and the Editor, and since the change is visible across both contexts, it makes sense to be able to undo that action in both places. Editing a Token though can only be done and seen on the Board, and undoing it from the Editor would give no visual feedback, potentially confusing and frustrating the user if they overwrote that change by working on something else afterwards.  That is why context is the key concept that needs to be taken into consideration in this implementation, and every context will be configured with a set of predefined actions that the user can undo/redo *within* said context.  **Action Classes**  These are our main building blocks. Every time the user does something that can be undone or redone, an Action is instantiated via an¬†`Action`¬†class; and every Action has an `undo` and a `redo` method. This is the base idea behind the whole technical design.  So for each Action that the user can undo, we define a class with a name property, a global index, some additional properties, and we define the implementations for the `undo` and `redo` methods. (snippet 1)  This Action architecture is extremely flexible: instead of storing global application states, we only store very localized and specific data, and we can easily handle side effects and communication with other parts of the application when those Actions come into play. This encapsulation enables fine-grained undo/redo control, clear separation of concerns, and easier testing.  Let‚Äôs use those classes now!  **Action Instantiation and Storage**  Whenever the user performs an Action in the app that supports undo/redo, an instance of that Action is created. But we need a central hub to store and manage them‚Äîwe‚Äôll call that hub `ActionStore`.  The¬†`ActionStore`¬†organizes Actions into Action Volumes‚Äîterm related to the notion of Action Containers which we‚Äôll cover below‚Äîwhich are objects keyed by Action class names, each holding an array of instances for that class. Instead of a single, unwieldy list, this structure allows efficient lookups and manipulation. Two Action Volumes are maintained at all times: one for done Actions and one for undone Actions.  Here‚Äôs a graph:  [Graph depicting the storage architecture of actions in Alkemion Studio](https://preview.redd.it/07hdo6szm48f1.png?width=2817&format=png&auto=webp&s=a097dcca0c0b558022f31de2ed39ec9f57dbfde8)  **Handling Context**  Earlier, we discussed the philosophy behind the undo/redo system, why having a single Action stack wouldn‚Äôt cut it for this situation, and the necessity for flexibility and separation of concerns.  The solution: a global Action Context that determines which actions are currently ‚Äúvalid‚Äù and authorized to be undone or redone.  The implementation itself is pretty basic and very application dependent, to access the current context we simply use a getter that returns a string literal based on certain application-wide conditions. Doesn‚Äôt look very pretty, but gets the job done lol (snippet 2)  And to know which actions are okay to be undone/redo within this context, we use a configuration file. (snippet 3)  With this configuration file, we can easily determine which actions are undoable or redoable based on the current context. As a result, we can maintain an undo stack and a redo stack, each containing actions fetched from our Action Volumes and sorted by their `globalIndex`, assigned at the time of instantiation (more on that in a bit‚Äîthis property pulls a lot of weight). (snippet 4)  **Triggering Undo/Redo**  Let‚Äôs use an example. Say the user moves a Token on the Board. When they do so, the¬†`""MOVE_TOKEN""`¬†Action is instantiated and stored in the¬†`undoneActions`¬†Action Volume in the `ActionStore` singleton for later use.  Then they hit CTRL+Z.  The ActionStore has two public methods called¬†`undoLastAction`¬†and¬†`redoNextAction`¬†that oversee the global process of undoing/redoing when the user triggers those operations.  When the user hits ‚Äúundo‚Äù, the¬†`undoLastAction`¬†method is called, and it first checks the current context, and makes sure that there isn‚Äôt anything else globally in the application preventing an undo operation.  When the operation has been cleared, the method then peeks at the last authorized action in the¬†`undoableActions`¬†stack and calls its¬†undo¬†method.  Once the lower level¬†undo¬†method has returned the result of its process, the¬†`undoLastAction`¬†method checks that everything went okay, and if so, proceeds to move the action from the ‚Äúdone‚Äù Action Volume to the ‚Äúundone‚Äù Action Volume  And just like that, we‚Äôve undone an action! The process for ‚Äúredo‚Äù works the same, simply in the opposite direction.  **Containers and Isolation**  There is an additional layer of abstraction that we have yet to talk about that actually encapsulates everything that we‚Äôve looked at, and that is containers.  Containers (inspired by Docker) are isolated action environments within the app. Certain contexts (e.g., modal) might create a new container with its own undo/redo stack (`Action Volumes`), independent of the global state. Even the global state is a special ‚Äúhost‚Äù container that‚Äôs always active.  Only one container is loaded at a time, but others are cached by ID. Containers control which actions are allowed via explicit lists, predefined contexts, or by inheriting the current global context.  When exiting a container, its actions can be discarded (e.g., cancel) or merged into the host with re-indexed actions. This makes actions transactional‚Äîlocal, atomic, and rollback-able until committed. (snippet 5)  **Multi-Stack Architecture: Ordering and Chronology**  Now that we have a broader idea of how the system is structured, we can take a look at some of the pitfalls and hurdles that come with it, the biggest one being chronology, because order between actions matters.  Unlike linear stacks, container volumes lack inherent order. So, we manage global indices manually to preserve intuitive action ordering across contexts.  Key Indexing Rules:  * New action: Insert before undone actions in other contexts by shifting their indices. * Undo: Increment undone actions‚Äô indices if they‚Äôre after the target. * Redo: Decrement done actions‚Äô indices if they‚Äôre after the target.  This ensures that:  * New actions are always next in the undo queue. * Undone actions are first in the redo queue. * Redone actions return to the undo queue top.  This maintains a consistent, user-friendly chronology across all isolated environments. (snippet 6)  **Weaknesses and Future Improvements**  It‚Äôs always important to look at potential weaknesses in a system and what can be improved. In our case, there is one evident pitfall, which is action order and chronology. While we‚Äôve already addressed some issues related to action ordering‚Äîparticularly when switching contexts with cached actions‚Äîthere are still edge cases we need to consider.  A weakness in the system might be action dependency across contexts. Some actions (e.g., B) might rely on the side effects of others (e.g., A).  Imagine:  * Action A is undone in *context 1* * Action B, which depends on A, remains in *context 2* * B is undone, even though A (its prerequisite) is missing  We haven‚Äôt had to face such edge cases yet in Alkemion Studio, as we‚Äôve relied on strict guidelines that ensure actions in the same context are always properly ordered and dependent actions follow their prerequisites.  But to future-proof the system, the planned solution is a dependency graph, allowing actions to check if their prerequisites are fulfilled before execution or undo. This would relax current constraints while preserving integrity.  **Conclusion**  Designing and implementing this system has been one of my favorite experiences working on [Alkemion Studio](https://alkemion.com), with its fair share of challenges, but I learned a ton and it was a blast.  I hope you enjoyed this post and maybe even found it useful, please feel free to ask questions if you have any!  This is reddit so I tried to make the post as concise as I could, but obviously there‚Äôs a lot I had to remove, I go much more in depth into the system in my devlog, so feel free to check it out if you want to know even more about the system: [https://mlacast.com/projects/undo-redo](https://mlacast.com/projects/undo-redo)  Thank you so much for reading!"	Reddit	18	[]
32	What happens to SDLC as we know it?	Infinite-Tie-1593	2025-06-17T16:18:59Z	https://redd.it/1ldocnb	There are lot of roles and steps in SDLC before and after coding. With AI, effort and time taken to write code is shrinking.  What happens to the rest of the software development life cycle and roles?  Thoughts and opinions pls?	Reddit	23	[]
33	Semver vs our emotions about changes	pb0s	2025-06-13T11:04:42Z	https://redd.it/1lab8xa	"The ""rules"" for semantic versioning are really simple according to semver.org:  >Given a version number MAJOR.MINOR.PATCH, increment the:  >MAJOR version when you make incompatible API changes  >MINOR version when you add functionality in a backward compatible manner  >PATCH version when you make backward compatible bug fixes  >Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format.  The implications are sorta interesting though. Based on these rules, any new feature that is non-breaking, no matter how big, gets only a minor bump, and any change that breaks the interface, no matter how small, is a major bump. If I understand correctly, this means that fixing a small typo in a public method merits a major bump, for example. Whereas a huge feature that took the team months to complete, which is just added as a new feature without touching any of the existing stuff, does not warrant one.  For simplicity, let's say we're only talking about developer-facing libraries/packages where ""incompatible API change"" makes sense.  On all the teams I've worked on, no one seems to want to follow these rules through to the extent of their application. When I've raised that ""this changes the interface so according to semver, that's a major bump"", experienced devs would say that it doesn't really feel like one so no.  Am I interpreting it wrong? What's your experience with this? How do you feel about using semver in a way that contradicts how we think updates should be made?"	Reddit	19	[]
34	Filtering vs smoothing vs interpolating vs sorting data streams?	denraru	2025-06-12T21:47:23Z	https://redd.it/1l9vzc4	"Hey all!  I'd like to hear from you, what you're experiences are with handling data streams with jumps, noise etc.  Currently I'm trying to stabilise calculations of the movement of a tracking point and I'd like to balance theoretical and practical applications.  Here are some questions, to maybe shape the discussion a bit:  How do you decide for a certain algorithm?  What are you looking for when deciding to filter the datastream before calculation vs after the calculation?  Is it worth it to try building a specific algorithm, that seems to fit to your situation and jumping into gen/js/python in contrast to work with running solutions of less fitting algorithms?  Do you generally test out different solutions and decide for the best out of many solutions, or do you try to find the best 2..3 solutions and stick with them?  Anyone who tried many different solutions and started to stick with one ""good enough"" solution for many purposes? (I have the feeling, that mostly I encounter pretty similar smoothing solutions, especially, when the data is used to control audio parameters, for instance).  PS: Sorry if that isn't really specific, I'm trying to shape my approach, before over and over reworking a concrete solution. Also I originally posted that into the MaxMSP-subreddit, because I hoped handson experiences there, so far no luck =)"	Reddit	5	[]
35	Is submitting WIP as PR an abuse of the PR system?	amkessel	2025-06-05T21:42:14Z	https://redd.it/1l48ka0	I'm a senior dev with 15+ years of experience. However this is my first time really being the tech lead on a team since most of my work has been done solo or as just a non-lead member of a team. So I'm looking for opinions on whether I'm overreacting to something that one of my teammates keeps doing.  I have a relatively newly hired mid-level dev on my team who regularly creates PRs into the develop branch with code that doesn't even compile. His excuse is that these are WIPs and he's just trying to get feedback from the team on it.  My opinion is that the intention of a PR is to submit code that is, as much as can be determined, production ready. A PR is no place to submit WIP.  I'm curious as to what the consensus is? Is submitting WIP as a PR an abuse of the PR system? Or do people think it's okay to use the PR in order to get team feedback? To be fair, I can see how the PR *does* package up the diffs all nice and tidy in one place, so it's a tempting tool for that. But I'm wondering if there's a better way to go about this.  Genuinely curious to hear how people fall on this.  Edit: Thank you all for all of the quick feedback. It seems like a lot of people are okay with a PR having WIP as long as it's marked as a draft. I didn't realize this is a thing, and our source control (Bitbucket) *does* have this feature. So I will work with my guy to start marking his PRs as drafts if he wants to get feedback before submitting as a full-on PR. I think this is a great compromise.  Thanks all for the responses!	Reddit	46	[]
36	Any experience with Advanced/Pilot Development Team?	legokangpalla	2025-05-27T04:01:07Z	https://redd.it/1kwbrto	"So I'm a software engineer whose been mostly working in S.Korea. During my stint with several companies, I've encountered many software team labelled as ""advanced/pilot development teams"". I've encountered this kind of setup on companies that sold packaged software, web service companies, and even on computerized hardware companies.  Basic responsibility of such team is to test new concepts or technologies and produce prototype code before other teams can start to work on main shipping application. At first glance, this kind of setup where a pilot dev team and a main development team working together makes sense as some people might be better at testing and producing code quickly.  This is such a standard setup here, I can't help but think there might be some reason behind this kind of setup. Would love to hear if anyone have experiences with this.  These are just some of my observations:  1. Since pilot team is mostly about developing new things and verifying them, most of maintenance seems fall into hands of main product engineers. But seeing how most software engineers take longer to digest other's code, this setup seems suboptimal. Even worse, I've seen devs re-writing most of pilot software due to maintenance issue.  2. Delivery and maintenance of product requirement is complicated. Product manager or owners have difficulty dividing up task between pilot and main dev team. Certain requirements require technical verification to see if they are possible and finding ways to implement it. But dividing up these tasks between two teams usually is not a clear cut problem. There are conflicts between a pilot team who are more willing to add new technology to solve a problem and main application team who are more focused on maintenance.   3. Code ownership seems impossible to implement as most ownership is given to the main application team.  4. This setup seems to give upper managers more control over resource allocation. There is very direct way to control the trade off between adding new features and maintenance/stability of the code base. By shifting people working on either team to another, there is pretty direct impact on this. I cannot say if this is faster than just having a single team or other team setup, but I can't think of more direct way of controlling man hour allocation.    "	Reddit	7	[]
37	Which communication protocol would be better in manager-worker pattern?	Historical_Ad4384	2025-05-26T03:30:14Z	https://redd.it/1kvienm	Hi,  We are trying to implement the manager-worker (similar to master-slave but no promotion) architecture pattern to distribute work from the manager into various workers where the master and workers are all on different machines.  While the solution fits our use case well, we have hit a political road block within the team when trying to decide the communication protocol that we wish to have between the manager and workers.  Some are advocating for HTTP polls to get notified when the worker is finished due to the relative simplicity of HTTP request-response model while doing away with extra infrastructure at the expense of wasted compute and network resources on the manager.  Others are advocating towards a message broker for seamless communication that does not waste compute and network resources of the manager at the expense of an additional infrastructure.  The only constraint for us is that the workers should complete their work within 23 hours or fail. The manager can end up distributing to 600 workers at the maximum.  What would be a better choice of communication ?  Any help or advice is appreciated	Reddit	21	[]
38	Emotions and Behaviors during Pair Programming - Survey	linver_se_research	2025-05-23T16:40:28Z	https://redd.it/1ktl8xd	Hi! I‚Äôm Linus Ververs, a researcher at Freie Universit√§t Berlin. Our research group has been studying pair programming in professional software development for about 20 years. While many focus on whether pair programming increases quality or productivity, our approach has always been to understand *how* it is actually practiced and experienced in real-world settings. And that‚Äôs only possible by talking to practitioners or observing them at work.  Right now, we're conducting a survey focused on **emotions and behaviors during pair programming**.  If pair programming is a part of your work life‚Äîwhether it's 5 minutes or 5 hours at a time‚Äîyou‚Äôd be doing us a big favor by taking \~20 minutes to complete the survey:  [https://will.understan.de/you/index.php/276389?lang=en](https://will.understan.de/you/index.php/276389?lang=en)  If you find the survey interesting, feel free to share it with your colleagues too. Every response helps!  Thanks a lot!   Linus	Reddit	5	[]
39	To Flag or Not to Flag? ‚Äî Second-guessing the feature-flag hype after a month of vendor deep-dives	Adventurous-Pin6443	2025-05-22T21:30:16Z	https://redd.it/1kszmir	Hey  folks,  I just finished a (supposed-to-be) quick spike for my team:¬†**evaluate which feature-flag/remote-config platform we should standardize on**. I kicked the tires on:  * LaunchDarkly * Unleash (self-hosted) * Flagsmith * ConfigCat * [Split.io](http://Split.io) * Statsig * Firebase Remote Config (for our mobile crew) * AWS AppConfig (because‚Ä¶ AWS ü§∑‚Äç‚ôÇÔ∏è)  # What I love  * Kill-switches instead of 3 a.m. hot-fixes * Gradual rollouts / A‚ÄìB testing baked in * ‚ÄúTurn it on for the marketing team only‚Äù sanity * Potential to separate deploy from release (ship dark code, flip later)  # Where my paranoia kicks in  |**Pain point**|**Why I‚Äôm twitchy**| |:-|:-| |**Dashboards ‚â† Git**|We‚Äôre a¬†**Git-first shop**: every change‚Äîinfra, app code, even docs‚Äîflows through PRs. Our CI/CD pipelines run 24√ó7 and every merge fires audits, tests, and notifications.¬†¬†¬†Vendor UIs bypass that flow.¬†¬†You can flip a flag at 5 p.m. Friday and it never shows up in¬†git log¬†or triggers the pipeline.¬†¬†Now we have two sources of truth, two audit trails, and zero blame granularity.| |**Environment drift**|Staging flags copied to prod flags = two diverging JSONs nobody notices until Friday deploy.| |**UI toggles can create untested combos**|QA ran ‚ÄúA on + B off‚Äù; PM flips B on in prod ‚Üí¬†*unknown*¬†state.| |**Write-scope API tokens in every CI job**|A leaked token could flip prod for every customer. (LD & friends recommend¬†SDK\_KEY¬†everywhere.)| |**Latency & data residency**|Some vendors evaluate in the client library, some round-trip to their edge. EU lawyers glare at US PoPs.¬†*(DPO = Data Protection Officer, our internal privacy watchdog.)*| |**Stale flag debt**|Incumbent tools warn, but cleanup is still manual diff-hunting in code. (Zombie flags, anyone?)| |**Rich config is ‚ÄúJSON strings‚Äù**|Vendors technically let you return arbitrary JSON blobs, but they store it as a¬†*string field*¬†in the UI‚Äîno schema validation, no type safety, and big blobs bloat mobile bundles. Each dev has to parse & validate by hand.| |**No dynamic code**|Need a 10-line rule? Either deploy a separate Cloudflare Worker or bake logic into every SDK.| |**Pricing surprises**|‚Äú$0.20 per 1 M requests‚Äù looks cheap‚Äîuntil 1 M rps on Black Friday. Seat-based plans = licence math hell.|    # Am I over-paranoid?  * Are these pain points legit show-stoppers, or just ‚Äúpaper cuts you learn to live with‚Äù? * How do you folks handle drift + audit + cleanup in the real world? * Anyone moved from dashboard-centric flags to a Git-ops workflow (e.g., custom tool, OpenFeature, home-grown YAML)?¬†¬†Regrets? * For the EU crowd‚Äîdid your¬†**DPO**¬†actually care where flag evaluation happens?  Would love any war stories or ‚Äústop worrying and ship the darn flags‚Äù pep talks.  *Thanks in advance‚Äîmy team is waiting on a recommendation and I‚Äôm stuck between üö¢ and üõë.*	Reddit	5	[]
40	Maintaining code quality with widespread AI coding tools?	raydenvm	2025-05-11T10:49:25Z	https://redd.it/1kjwiso	"I've noticed a trend: as more devs at my company (and in projects I contribute to) adopt AI coding assistants, code quality seems to be slipping.  It's a subtle change, but it's there.  The issues I keep noticing:  * More ""almost correct"" code that causes subtle bugs * The codebase has less consistent architecture  * More copy-pasted boilerplate that should be refactored  I know, maybe we shouldn't care about the overall quality and it's only AI that will look into the code further. But that's a somewhat distant variant of the future. For now, we should deal with speed/quality balance ourselves, with AI agents in help.   So, I'm curious, what's your approach for teams that are making AI tools work without sacrificing quality?  Is there anything new you're doing, like special review processes, new metrics, training, or team guidelines?"	Reddit	46	[]
41	How to Best Visualize Waterfall vs. Agile SDMs with Lego in ~15 Mins? Seeking Better Ideas!	GXRMANIA	2025-04-28T09:55:44Z	https://redd.it/1k9q5bh	"Need your creative input! Currently I visit the course ""**Software Engineering Education**"". I'm planning a short Lego activity to explain Waterfall vs. Agile and would love your thoughts/better ideas. My current idea:  1. **Waterfall Simulation (8min):**    * ""Customer (Me)"" gives detailed, fixed requirements for a small Lego bridge upfront (symmetric, exatcly 3 arches, has to span certain distance, efficient use of bricks)    * ""Dev Team (Groups in the audience)"" builds the entire bridge according to spec, with no customer feedback during the build.    * Final product is presented only at the end. Highlight difficulty/cost of late changes requested by the customer. (e.g. is this ship able to drive below the bridge? No? -> Now you have to change the whole bride; Is the bridge cost efficient? ... ) 2. **Agile Simulation (8min):**    * ""Customer"" gives a high-level goal of the same bridge.     * 1. Sprint: Build the pillars, (is this ship able to drive below the bridge? No? -> Now you NOT have to change the whole bride)    * ...    * After each sprint, the team shows the increment to the customer and can make subtle changes to fit customers needs.     To visually contrast the rigid, plan-heavy nature and late feedback of Waterfall vs. the flexible, iterative build and early/frequent feedback of Agile.     Looking for suggestions to improve this bridge-building scenario, alternative Lego ideas, or potential pitfalls within the 10-15 min timeframe. Thanks!"	Reddit	17	[]
42	Which CS Topic Gave You That ‚ÄúMind-Blown‚Äù Moment?	rayhanmemon	2025-04-27T18:03:49Z	https://redd.it/1k97ewl	I‚Äôm a staff-level software engineer and I absolutely LOVE reading textbooks.  It‚Äôs partially because they improve my intuition for problem solving, but mostly because it‚Äôs so so satisfying to understand how some of these things work.   My current top 4 ‚Äúmost satisfying‚Äù topics/reads:  1. Virtualization, Concurrency and Persistence (Operating Systems, 3 Easy Pieces)  2. Databases & Distributed Systems (Designing Data-Intensive Applications)  3. How the Internet Works (Computer Systems, 6th edition)  4. How Computers Work (The Elements of Computing Systems)  Question for you:  Which CS topic (book, lecture, paper‚Äîanything) was the most satisfying to learn, and did it actually level-up your day-to-day engineering?  Drop your pick‚Äîand why‚Äîbelow. I‚Äôll compile highlights so everyone gets a fresh reading list.   Thanks!	Reddit	73	[]
43	üßäWatercooler Discussions about common Software Automation Topics	basecase_	2025-04-25T21:05:36Z	https://redd.it/1k7t299	Hola friends, the link above is a culmination of about over a years worth of Watercooler discussions gathered from r/QualityAssurance ,¬†r/programming,¬†r/softwaretesting, and our Discord (nearing 1k members now!).  Please feel free to leave comments about ANY of the topics there and I will happily add it to the Watercooler Discussions so this document can be always growing with common questions and answers from all communities, thanks!	Reddit	2	[]
44	Seeking Advice: Designing a High-Scale PostgreSQL System for Immutable Text-Based Identifiers	Pr0xie_official	2025-04-25T00:55:29Z	https://redd.it/1k75w5r	"I‚Äôm designing a system to manage¬†**Millions of unique, immutable text identifiers**¬†and would appreciate feedback on scalability and cost optimisation. Here‚Äôs the anonymised scenario:  **Core Requirements**  1. **Data Model**:    * Each record is a¬†**unique, unmodifiable text string**¬†(e.g.,¬†xxx-xxx-xxx-xxx-xxx). (The size of the text might vary and the the text might only be numbers 000-000-000-000-000)    * No truncation or manipulation allowed‚Äîoriginal values must be stored verbatim. 2. **Scale**:    * Initial dataset:¬†**500M+ records**, growing by millions yearly. 3. **Workload**:    * **Lookups**: High-volume exact-match queries to check if an identifier exists.    * **Updates**: Frequent single-field updates (e.g., marking an identifier as ""claimed""). 4. **Constraints**:    * Queries¬†**do not include metadata**¬†(e.g., no joins or filters by category/source).    * Data must be stored in PostgreSQL (no schema-less DBs).  **Current Design**  * **Hashing**: Use a¬†**16-byte BLAKE3 hash**¬†of the full text as the primary key. * **Schema**:  &#8203;      CREATE TABLE identifiers (         id_hash BYTEA PRIMARY KEY,     -- 16-byte hash         raw_value TEXT NOT NULL,       -- Original text (e.g., ""a1b2c3-xyz"")         is_claimed BOOLEAN DEFAULT FALSE,         source_id UUID,                -- Irrelevant for queries         claimed_at TIMESTAMPTZ       );   * **Partitioning**: Hash-partitioned by¬†id\_hash¬†into 256 logical shards.  **Open Questions**  1. **Indexing**:    * Is a B-tree on¬†id\_hash¬†still optimal at 500M+ rows, or would a BRIN index on¬†claimed\_at¬†help for analytics?    * Should I add a composite index on¬†(id\_hash, is\_claimed)¬†for covering queries? 2. **Hashing**:    * Is a 16-byte hash (BLAKE3) sufficient to avoid collisions at this scale, or should I use SHA-256 (32B)?    * Would a non-cryptographic hash (e.g., xxHash64) sacrifice safety for speed? 3. **Storage**:    * How much space can TOAST save for¬†raw\_value¬†(average 20‚Äì30 chars)?    * Does column order (e.g., placing¬†id\_hash¬†first) impact storage? 4. **Partitioning**:    * Is hash partitioning on¬†id\_hash¬†better than range partitioning for write-heavy workloads? 5. **Cost/Ops**:    * I want to host it on a VPS and manage it and connect my backend API and analytics via pgBouncher    * Any tools to automate archiving old/unclaimed identifiers to cold storage? Will this apply in my case?    * Can I effectively backup my database in S3 in the night?  **Challenges**  * **Bulk Inserts**: Need to ingest 50k‚Äì100k entries, maybe twice a year. * **Concurrency**: Handling spikes in updates/claims during peak traffic.  **Alternatives to Consider?**  ¬∑¬†¬†¬†¬†¬† Is Postgresql the right tool here, given that I require some relationships? A hybrid option (e.g., Redis for lookups + Postgres for storage) is an option however, the record in-memory database is not applicable in my scenario.  * Would a columnar store (e.g., Citus) or time-series DB simplify this?  **What Would You Do Differently?**  * Am I overcomplicating this with hashing? Should I just use¬†raw\_value¬†as the PK? * Any horror stories or lessons learned from similar systems?  ¬∑¬†¬†¬†¬†¬†¬† I read the use of partitioning based on the number of partitions I need in the table (e.g., 30 partitions), but in case there is a need for more partitions, the existing hashed entries will not reflect that, and it might need fixing. ([chartmogul](https://chartmogul.com/blog/how-migrating-our-database-eliminated-data-processing-incidents/)). Do you recommend a different way?  * Is there an algorithmic way for handling this large amount of data?  Thanks in advance‚Äîyour expertise is invaluable!"	Reddit	9	[]
45	A methodical and optimal approach to enforce type- and value-checking in Python while conforming to the functional programming paradigm	kris_2111	2025-04-20T20:21:10Z	https://redd.it/1k3syvn	"Hiiiiiii, everyone! I'm a freelance machine learning engineer and data analyst. Before I post this, I must say that while I'm looking for answers to two specific questions,  the main purpose of this post is not to ask for help on how to solve some specific problem ‚Äî rather,  I'm looking to start a discussion about something of great significance in Python; it is something which,  besides being applicable to Python, is also applicable to programming in general.   I use Python for most of my tasks, and C for computation-intensive tasks that aren't amenable to being done in NumPy or other libraries that support vectorization. I have worked on lots of small scripts and several ""mid-sized"" projects (projects bigger than a single 1000-line script but smaller than a 50-file codebase). Being a great admirer of the functional programming paradigm (FPP), I like my code being modularized. I like blocks of code ‚Äî that, from a semantic perspective, belong to a single group ‚Äî being in their separate functions. I believe this is also a view shared by other admirers of FPP.   My personal programming convention emphasizes a very strict function-designing paradigm.  It requires designing functions that function like deterministic mathematical functions;  it requires that the inputs to the functions only be of fixed type(s); for instance, if  the function requires an argument to be a regular list, it must only be a regular list ‚Äî  not a NumPy array, tuple, or anything has that has the properties of a list. (If I ask  for a duck, I only want a duck, not a goose, swan, heron, or stork.) We know that Python, being a dynamically-typed language, type-hinting is not enforced. This means that unlike statically-typed languages like C or Fortran, type-hinting does not prevent invalid inputs from ""entering into a function and corrupting it, thereby disrupting the intended flow of the program"". This can obviously be prevented by conducting a manual type-check inside the function before the main function code, and raising an error in case anything invalid is received. I initially assumed that conducting type-checks for all arguments would be computationally-expensive, but upon benchmarking the performance of a function with manual type-checking enabled against the one with manual type-checking disabled, I observed that the difference wasn't significant. One may not need to perform manual type-checking if they use linters. However, I want my code to be self-contained ‚Äî while I do see the benefit of third-party tools like linters ‚Äî I want it to strictly adhere to FPP and my personal paradigm without relying on any third-party tools as much as possible. Besides, if I were to be developing a library that I expect other  people to use, I cannot assume them to be using linters. Given this, here's my first question:   **Question 1. Assuming that I do not use linters, should I have manual type-checking enabled?**  Ensuring that function arguments are only of specific types is only one aspect of a strict FPP ‚Äî it must also be ensured that an argument is only from a set of allowed values. Given the extremely modular nature of this paradigm and the fact that there's a lot of function composition, it becomes computationally-expensive to add value checks to all functions. Here, I run into a dilemna:   *I want all functions to be self-contained so that any function, when invoked independently, will  produce an output from a pre-determined set of values ‚Äî its range ‚Äî given that it is supplied its inputs from a pre-determined set of values ‚Äî its domain; in case an input is not from that domain, it will raise an error with an informative error message. Essentially, a function either receives an input  from its domain and produces an output from its range, or receives an incorrect/invalid input and  produces an error accordingly. This prevents any errors from trickling down further into other functions,  thereby making debugging extremely efficient and feasible by allowing the developer to locate and rectify any bug efficiently. However, given the modular nature of my code, there will frequently be functions nested several levels ‚Äî I reckon 10 on average. This means that all value-checks of those functions will be executed, making the overall code slightly or extremely inefficient depending on the nature of value checking.*    While `assert` statements help mitigate this problem to some extent, they don't completely eliminate it. I do not follow the EAFP principle, but I do use `try/except` blocks wherever appropriate. So far, I have been using the following two approaches to ensure that I follow FPP and my personal paradigm,  while not compromising the execution speed: 1. Defining *clone functions* for all functions that are expected to be used inside other functions:       The definition and description of a clone function is given as follows:   	Definition:   	A clone function, defined in relation to some function `f`, is a function with the same internal logic as `f`, with the only exception that it does not perform error-checking before executing the main function code.   	Description and details:   	A clone function is only intended to be used inside other functions by my program. Parameters of a clone function will be type-hinted. It will have the same docstring as the original function, with an additional heading at the very beginning with the text ""Clone Function"". The convention used to name them is to prepend the original function's name ""clone_"". For instance, the clone function of a function `format_log_message` would be named `clone_format_log_message`.   	Example:       ``` 	# Original function 	def format_log_message(log_message: str): 		 if type(log_message) != str: 			raise TypeError(f""The argument `log_message` must be of type `str`; received of type {type(log_message).__name__}."") 		elif len(log_message) == 0: 			raise ValueError(""Empty log received ‚Äî this function does not accept an empty log."") 		 		# [Code to format and return the log message.] 		 	# Clone function of `format_log_message` 	def format_log_message(log_message: str): 		# [Code to format and return the log message.]     ``` 2. Using switch-able error-checking:   	 This approach involves changing the value of a global Boolean variable to enable and disable error-checking as desired. Consider the following example:       ``` 	CHECK_ERRORS = False 	 	def sum(X): 		total = 0 	    	if CHECK_ERRORS: 	        		for i in range(len(X)): 	            		emt = X[i] 	            		if type(emt) != int or type(emt) != float: 	                			raise Exception(f""The {i}-th element in the given array is not a valid number."")  	            		total += emt 	     	else: 	        		for emt in X: 	            			total += emt     ``` 	Here, you can enable and disable error-checking by changing the value of  `CHECK_ERRORS`. At each level, the only overhead incurred is checking the value of the Boolean variable `CHECK_ERRORS`, which is negligible. I stopped using this approach a while ago, but it is something 	I had to mention.  While the first approach works just fine, I'm not sure if it‚Äôs the most optimal and/or elegant one out there. My second question is:   **Question 2. What is the best approach to ensure that my functions strictly conform to FPP while maintaining the most optimal trade-off between efficiency and readability?**    Any well-written and informative response will greatly benefit me. I'm always open to any constructive criticism regarding anything mentioned in this post. Any help done in good faith will be appreciated. Looking forward to reading your answers! :) "	Reddit	11	[]
46	can someone explain why we ditched monoliths for microservices? like... what was the reason fr?	Express-Point-7895	2025-04-19T08:12:48Z	https://redd.it/1k2ppy9	okay so i‚Äôve been reading about software architecture and i keep seeing this whole ‚Äúmonolith vs microservices‚Äù debate.  like back in the day (early 2000s-ish?) everything was monolithic right? big chunky apps, all code living under one roof like a giant tech house.  but now it‚Äôs all **microservices this, microservices that**. like every service wants to live alone, do its own thing, have its own database  so my question is‚Ä¶ **what was the actual reason for this shift?** was monolith THAT bad? what pain were devs feeling that made them go ‚Äúnah we need to break this up ASAP‚Äù?  i get the that there is scalability, teams working in parallel, blah blah, but i just wanna understand the *why* behind the change.  someone explain like i‚Äôm 5 (but like, 5 with decent coding experience lol). thanks!	Reddit	251	[]
47	What are the best books to learn how to think like a software engineer?	TropicSTT	2025-04-18T12:07:55Z	https://redd.it/1k21d3k	i‚Äôm trying to level up not just my coding skills, but the way i *think* about problems, like a real software engineer would. i‚Äôm looking for book recs that can help me build that mindset. stuff around problem-solving, system design, how to approach real-world challenges etc.	Reddit	64	[]
48	CQRS projections idea	PC-Uncle	2025-04-17T05:37:24Z	https://redd.it/1k13h08	"Hi, so I have some programming experience but by no means an expert so apologies if anything I say is naive or uses the wrong terminology.  I want to test an idea out that I'm sure is not new but I don't know how to search for this specifically so I'd appreciate any recommendations for learning resources. Any advice or opinions are greatly appreciated.  I want to use Firestore for the Command side, and then project that data to different Query models that might exist on a sql database, or elasticache, or a graphdb etc.  I don't want to rely on any sort of pub/sub, emitting events, or anything similar.  I want to run a projector that pulls new data in firestore and writes them to the read models.  So here is my idea  Documents in Firestore would be append only.  So say I'm modeling a ""Pub"" (that you drink at).  Has the following mandatory fields.  1. autogenerated firestore document ID field 2. pub\_id: UUID 3. version: ULID (monotonically increasing, sortable) 4. action: ""delete"", ""update"", ""create"" - there is no patch  So anytime I update any of its fields like, say, it's name, I would create a totally new cloned document with a new autogenerated document ID, the same pub\_id, and a new version.  Now, let's say the projector needs to pick up new actions.  It can periodically query the Query model for the single latest version it has recorded.  It then submits a request to Firestore for all any pub documents (so, all different pubs) whose versions come after (in chunks of say 20 at a time).  It can then just take the latest version of each pub and either create, delete, or update (not patch).  So this is not supposed to be event sourcing, and I don't need to be able to rerun projections from the beginning.  I think for my purposes I really only need to get the latest version of things.  Let's say I was modeling a many to one relationship.  For example, a pub crawl that has a list of pubs to visit.  I'd have additional documents: ""PubCrawl"", and ""PubCrawl\_Pub (this would record the pub\_id and pubcrawl\_id)"" I realize this looks like SQL tables!  I would need to do this since I can only easily shallow clone documents in Firestore.  Please let me know what you think!  Thank you!"	Reddit	0	[]
49	what are best Practices for Handling Partially Overridden Multi-Tenant Data in a Relational Database	Unique-You-6100	2025-04-15T18:09:49Z	https://redd.it/1jzvsp3	I'm working on a multi-tenant SaaS application and would like to understand how organizations typically manage tenant-specific data in a relational database, especially in cases where most data is shared across tenants, but some fields vary for specific tenants.  We have an entity called Product with the following example fields:  productName (String)  productType (String)  productPrice (Object)  productDescription (Object)  productRating (Object)  We support around 200 tenants, and in most cases, the data for these fields is the same for all tenants. However, for some fields like productDescription or productPrice, a small subset of tenants (e.g., 20 out of 200) may have custom values, while the remaining tenants use the default/common values.  **Additional considerations:**  We also need to publish this product data to a messaging queue, but not on a per-tenant basis ‚Äî i.e., the outgoing payload is unified and should reflect the right values per tenant.  **One approach I'm considering:**¬†Store a default version of each product. Store tenant-specific overrides only for the fields that actually differ. At runtime (or via a view or service), merge the default + overrides to resolve the final product view per tenant.  Has anyone dealt with a similar use case? I'd love to hear how you've modeled this.	Reddit	9	[]
50	Architecture design feels like the Wild West, how are you making it work?	LeadingFarmer3923	2025-04-13T17:34:04Z	https://redd.it/1jyacze	Saw a stat recently that said \~60% of engineering teams don‚Äôt have a clear process for architecture design. Not super surprising, but kinda wild when you think about how many problems we try to solve after the code is written.  Like, we‚Äôll debate for hours over code formatting or testing libraries...   But when it comes to architecture, it‚Äôs usually just vibes and a Google Doc from 2021.  Some teams do it right:  * C4 model + Structurizr to diagram systems * ADRs in Git to track decisions * Miro or Excalidraw for whiteboarding * Even GPT-4 or Claude for bouncing ideas  Others? Slack threads, tribal knowledge, and praying someone remembers why you picked Kafka over Redis pub/sub.  And honestly, there‚Äôs no perfect system.   Architecture is hard. There are always tradeoffs.   But not having any process? That‚Äôs how you end up rewriting half your backend 9 months in.  So I‚Äôm curious how are you designing architecture in your team right now?   What tools are you using? Any process that‚Äôs actually worked?	Reddit	25	[]
51	Need Feeback on my reverse dutch auctioning platform architecture	Gothicsword0987	2025-04-10T06:03:11Z	https://redd.it/1jvp43v	We‚Äôve developed a Dutch auction system, and here is its architecture:  We are using a message broker service as an intermediary to scale our auction server‚Äôs WebSocket connections. Our requirement is slightly different: we will have a maximum of 10 ongoing auctions but an unlimited number of auction participants.  We are estimating 10K concurrent web socket connections That‚Äôs why we have separated the services into the Auction Distributor and the Auction Processor.  **Auction Processor**  * Contains all the core business logic related to the auction. * Responsible for triggering the **price\_update** event to provide timely updates to clients subscribed to a room. * Handles processing of the **place\_bid** event sent by clients.  **Auction Distributor**  * Does not contain core business logic. * Responsible for forwarding events to clients via the maintained socket connections. * Must scale appropriately in cases of heavy traffic.  https://preview.redd.it/2k3uptxvlxte1.png?width=2765&format=png&auto=webp&s=38d57025738193cca7b418e7ccca80a2680a51fa  Any Feedbacks on improving the design would be appreciated.      Also right now we're using Redis Pub/Sub. However, that is turning out to be quite expensive so please suggest an alternative preferably an azure service for this.   	Reddit	4	[]
52	any suggestions for a monthly computer science magazine (printed)?	snowy-pandu	2025-04-07T10:17:30Z	https://redd.it/1jtg8op	looking for general computer science trends & interesting innovations as a professional software engineer.   not a fan of digital one as I am trying to reduce my screentime :)  budget friendly suggestions are preferred.	Reddit	7	[]
53	What SDLC Paradigm Did You Use in Your Project?	Educational-Term9051	2025-04-06T04:39:54Z	https://redd.it/1jsk6ru	I‚Äôm a student currently working on a research activity for our Software Engineering class, and I‚Äôd really appreciate your insights. üòä  I‚Äôm looking to gather input from software developers, project managers, or engineers about the software lifecycle paradigms you've used in your past or current projects.  If you have a few minutes to spare, I‚Äôd love to hear your answers to these quick questions:  1. What type of software did you develop? (e.g., mobile app, enterprise system, game, etc.) 2. Which software development paradigm did your team follow? (e.g., Agile, Waterfall, Spiral, etc.)  3. Why did you choose that particular paradigm? (e.g., client requirement, team familiarity, project scale, etc.)  Your input would be super helpful and will be used strictly for educational purposes. Thank you in advance to anyone willing to share their experience!  I'm hoping to gather a few short responses from professionals or experienced developers about the types of software they developed, the SDLC paradigm they used (Agile, Waterfall, Spiral, etc.), and why they chose that approach. This will help me understand how and why different models are applied in real-world scenarios.	Reddit	9	[]
54	"""Service"" layer becoming too big. Do you know another architecture with one more layer ?"	Glittering-Thanks-33	2025-04-01T23:51:03Z	https://redd.it/1jp7y1a	"Hi  In my team, we work on several projects using this classical architecture with 3 layers: Controller/Service/Repository.  Controllers contains endpoints, handle http responses Services contain the business logic, transform the daga Repositories retrieves the data from db  For the Controllers and Repositories it works very well: we keep these files very clean and short, the methods are straightforward.  But the issue is with the Services, most of our services are becoming very big files, with massive public methods for each business logic, and lots of private helper methods of course.  We are all already trying to improve that, by trying to extract some related methods to a new Service if the current one becomes too big,  by promoting Helper or Util classes containing reusable methods, etc.  And the solution that worked best to prevent big files: by using linger rules that limit the number of methods in a single file before allowing the merge of a pull request.  But even if we try, you know how it is... Our Services are always filled to the top of the limit, and the projects are starting to have many Services for lot of sub-logic. For example:  AccountService which was enough at the beginning is now full so now we have many other services like CurrentAccountService, CheckingAccountService, CheckingAccountLinkService, CheckingAccountLinkToWithdrawService, etc etc...  The service layer is becoming a mess.   I would like to find some painless and ""automatic"" way to solve this issue.  My idea would be to introduce a new kind of layer, this layer would be mandatory in the team and would permit to lighten the Service layer.  But what could this layer do ? Would the layer be between Controller and Service or beween Service and Repository ?  And most important question, have you ever heard of such architecture in any framework in general, with one more layer to lighten the Service layer ?  I don't want to reinvent the wheel, maybe some well tested architecture already exists.  Thanks for your help"	Reddit	46	[]
55	How is a PKI working for identifying clients accessing a service	PaulFEDSN	2025-03-29T12:37:20Z	https://redd.it/1jmkd4z	Hi all,      I'm asking this question to improve my understanding on a project.      The project was running for several years in a closed environment (closed network).   Still for security reasons the actual service requests form a client to the server (most HTTP based, SOAP alike) have been signed with certificates.   The certificates have been issued form a non-public/local root certificate (form the same server/service) to the clients - so these client certificates had the certificate chain to the (local) root + the Client ID included.   The server as well was using the certificate (or a derived one) to sign the responses - so the clients could as well validate the responses for authenticity (as they got a trust-store with the root certificate (public key)).      With this setup (everything controlled by same trusted entity/provider) the clients could verify that responses are authentic and the server could verify that the requests are coming form a authentic client + identify them via the ID to perform authorization to several services.      Now if this project should move to a public PKI, how would/could this work?   Clear for me the public root will issue the certificates as different trust anchor.   \- Still the Service should provide its own public key (in a Trust-store) so the clients know the responses are from that very specific server (and not a different one that got form same PKI CA a certificate) - this might not be of that a big issue if HTTPS is used, as here the domain name would ensure this as well.   \- The clients can no not be identified any more, as the public PKI will not encode the client IDs (as known to the service) into the certificate.      How would it work that the clients could be identified?   Only think I could think of is, that the clients have to provide the public key to the service, that has to hold internal a mapping to identify the users.      Do I miss anything there? Is there another way?	Reddit	7	[]
56	Agile is an excuse for poor planning?	Inconnu	2025-03-28T13:05:03Z	https://redd.it/1jlthaq	I am a backend dev with 5 yr of exp. Recently, I was tasked to plan out a new project and I said let‚Äôs figure out the data model. I sat with the client and put together about 100 tables within half a working day. Everyone is disagreeing with this method because it ‚Äòhalts‚Äô dev time. I have had the grief of maintaining a few projects that are taking years because of this pure agile mindset I feel. We kept doing table migrations that could‚Äôve been avoided if we planned upfront instead of starting with 1 table and scaling up to 50. Tbh these should‚Äôve been shipped out within a year imo  Please tell me I‚Äôm not crazy. I‚Äôm not sure where the beef is.   Edit: I‚Äôm well aware 100 tables is a lot for that time period *typically*. I should‚Äôve clarified that the clients have data modelling exp and knew the system in and out. Plus a lot of those tables were very simple. Apart from two minor revisions, we pretty much had it down from this session.  I still believe at least a week should be used to get down as much of the data model down before starting dev work.   Edit: Yes, the model was reviewed after the half day by others. We identified it was the simplest design in terms of reducing complex queries, preventing null values and optimizing storage.   Edit: Apart from adding nice-to-haves, the core features of the system will **not** change.	Reddit	167	[]
57	How big should a PR be?	Inconnu	2025-03-28T18:59:49Z	https://redd.it/1jm19v7	"I work in embedded and my team prefers small PRs. I am struggling with the ""small PR"" thing when it comes to new features.  A full device feature is likely to be 500-1000 lines depending on what it does. I recognize this is a ""big"" PR and it might be difficult to review. I don't want to make PRs difficult to review for my team, but I am also not sure how I should otherwise be shipping these.  Say I have a project that has a routing component, a new module that handles the logic for the feature, unit tests, and a clean up feature. If I ship those individually, they will break in the firmware looking for pieces that do not yet exist.  So maybe this is too granular of a question and it doesn't seem to bother my team that I'll disappear for a few weeks while working on these features and then come back with a massive PR - but I do know in the wider community this seems to be considered unideal.  So how would I otherwise break such a project up?  Edit: For additional context, I do try to keep my commit history orderly and tidy on my own branch. If I add something for routing, that gets its' own commit, the new module get its' own commit, unit tests for associated modules, etc etc  Edit 2: Thank you everyone who replied. I talked to my manager and team about this and I am going to meet with someone next week to break the PR into smaller ones and make a goal to break them up in the future instead of doing one giant PR. "	Reddit	54	[]
58	Is it possible to transparently inject DPoP (RFC 9449) into an HTTP request without buffering the complete request?	choeger	2025-03-23T13:02:51Z	https://redd.it/1jhxphm	"So, I am looking at building a proxy/relay service that's purpose is to transparently inject Bluesky authentication into an HTTP request.  Essentially, the client requests a resource from the service, using a propietary authentication method, and the service removes the propietary credentials, adds the Bluesky (oauth 2.1) credentials, and otherwise forwards the request as-is. Obviously, to keep the service lightweight, it is best to implement it as a streaming forwarder: Read request headers, modify them, forward headers, read body chunks, forward body chunks.  But I stumble upon the requirement of DPoP nonces, as laid out in RFC 9449. The RFC says that:  > The client will typically retry the request with the new nonce value supplied upon receiving a use_dpop_nonce error with an accompanying nonce value.  So from my understanding that means, the proxy/relay *has* to buffer the full request in order to be able to transparently retry it. There's nothing like a HEAD or OPTIONS request laid out in the RFC that allows me to pre-flight the request to validate the nonce.  I *could* toy around with empty bodies as a pre-flight attempt, but is there any rule that says the DPoP nonce must be sent out on bad requests? Also, that's probably going to hurt the quota and is not very nice to the other end.  Is there anything that I am missing here? Any kind of ""would you mind to tell me the next DPoP nonce, please"" method?"	Reddit	0	[]
59	Any experience with temporal databases?	Imaginary-Corner-653	2025-03-20T09:16:01Z	https://redd.it/1jfk16e	Hi  I'm looking at different ways to facilitate an entity journaling mechanism as well as keeping track of different branches for certain entities.  I've stumbled across the temporal extentions for postgresql https://wiki.postgresql.org/wiki/Temporal_Extensions  However, without ever having worked with anything like this I'm struggling to overview the implications.  How will my storage size requirements change with this extension?  Does extension actually save me implementation overhead in the backend? Are typical ORM frameworks fit to adapt it?  Is this potential overkill?  Happy for any input by someone who's been there. 	Reddit	2	[]
60	Is Object-Oriented Software Engineering: A Use Case Driven Approach by Ivar Jacobson still relevant?	BluejVM	2025-03-18T00:22:35Z	https://redd.it/1jdr015	Is this book still relevant to modern software engineering? Does it focus solely on OOP, or is there additional content covered as well?	Reddit	4	[]
61	Software Engineering Handbooks	bringitdown	2025-03-12T23:52:43Z	https://redd.it/1j9x9l1	"Hi folks, a common problem in many software practices is curating a body of knowledge for software engineers on common practices, standards etc.      Whether its Code Review etiquette, Design Priniciples, CI / CD or Test Philosopy.  I found a few resources from companies that publish in some detail how they codify this or aspects of it   *  [https://handbook.gitlab.com/handbook/](https://handbook.gitlab.com/handbook/) * [https://dropbox.github.io/dbx-career-framework/](https://dropbox.github.io/dbx-career-framework/) * [https://www.atlassian.com/blog/atlassian-engineering/handbook](https://www.atlassian.com/blog/atlassian-engineering/handbook)¬†  Anyone aware of other similar resources out there?   I am fully aware of the myriad of books, medium articles etc - am more looking for the - ""hey we've taken all that and here's our view of things.""  "	Reddit	6	[]
62	Can somebody really explain what is the meaning: agile is an iterative process that build the product in increment	Hornitar	2025-03-12T06:17:35Z	https://redd.it/1j9byxs	I thought these two were different?   Incremental model, more upfront planning but divide process so each increment is like a mini waterfall. E.g., painting the mona lisa one part to completion at a time  Iterative is where you had an initial vague refinement that is slowly refined through sequence of iterations. E.g., rough sketch > tracing > outlining > color > highlighting  From what I‚Äôve gathered, an increment in Agile is the sum of all the features implemented from the backlog in a sprint. So how is this an iterative process???  My professor tells me that Agile is an iterative process that deliver the product in increment? What does this mean? Does it mean each feature or backlog item we are trying to implement goes through an iterative process of refinining requirement. Then the sum of all completed feature is an increment?  Edit: thanks y‚Äôall passed my software engineering class with an A-	Reddit	25	[]
63	TDD on Trial: Does Test-Driven Development Really Work?	Aer93	2025-03-10T08:40:24Z	https://redd.it/1j7tcfy	I've been exploring¬†**Test-Driven Development (TDD)**¬†and its practical impact for quite some time, especially in challenging domains such as 3D software or game development. One thing I've noticed is the significant lack of clear, real-world examples demonstrating TDD‚Äôs effectiveness in these fields.  Apart from the well-documented experiences shared by the developers of¬†**Sea of Thieves**, it's difficult to find detailed industry examples showcasing successful TDD practices (please share if you know more well documented cases!).  On the contrary, influential developers and content creators often openly question or criticize TDD, shaping perceptions‚Äîparticularly among new developers.  Having personally experimented with TDD and observed substantial benefits, I'm curious about the community's experiences:  * **Have you successfully applied TDD in complex areas like game development or 3D software?** * **How do you view or respond to the common criticisms of TDD voiced by prominent figures?**  I'm currently working on a humorous, Phoenix Wright-inspired parody addressing popular misconceptions about TDD, where the different popular criticism are brought to trial. Your input on common misconceptions, critiques, and arguments against TDD would be extremely valuable to me!  Thanks for sharing your insights!	Reddit	126	[]
64	Message queue with group-based ordering guarantees?	desgreech	2025-03-09T00:47:37Z	https://redd.it/1j6ug0v	I'm currently looking to improve the durability of my cross-service messaging, so I started looking for a message queue that have the following guarantees:  * Provides a message type that guarantees consumption order based on grouping (e.g. user ID) * Message will be re-sent during retries, triggered by consumer timeouts or nacks * Retries does not compromise order guarantees * Retries within a certain ordered group will not block consumption of other ordered groups (e.g. retries on user A group will not block user B group)  I've been looking through a bunch of different message queue solutions, but I'm shocked at how pretty much none of the mainstream/popular message queues matches any of the above criterias.  I've currently narrowed my choices down to two:  * Pulsar     It checks most of my boxes, except for the fact that nacking messages can ruin the ordering. It's a known [issue](https://github.com/apache/pulsar/issues/23480), so maybe it'll be fixed one day.  * RocketMQ    As far as I can tell from the docs, it has all the guarantees I need. But I'm still not sure if there are any potential caveats, haven't dug deep enough into it yet.  But I'm pretty hesitant to adopt either of them because they're very niche and have *very little* community traction or support.  Am I missing something here? Is this really the current state-of-the-art of message queues?	Reddit	14	[]
65	Software Documentation Required	Educational_Cup_9360	2025-03-07T18:05:02Z	https://redd.it/1j5toez	Hi everyone,  I'm looking for software documentation of an open-source project to support my thesis research. Ideally, it should be consolidated into a single document (maximum 100 pages), covering small enterprise applications or legacy systems. Most documentation I've found is scattered across multiple files or resources, making it challenging to analyze effectively.  The documentation should ideally include:  * An overview describing the system's purpose and functionality. * A breakdown of internal and external components, including their interactions and dependencies. * Information on integrations with third-party APIs or services. * Details about system behavior and specific functionalities.  If anyone can recommend a project with clear, well-organized, centralized documentation meeting these criteria, I'd greatly appreciate it!  Thanks in advance!	Reddit	22	[]
66	The Outbox Pattern is doing a queue in DB	RaphaS9	2025-03-06T12:56:05Z	https://redd.it/1j4ttgl	I've been wondering about using an external queue saas (such as gcp pubsub) in my project to hold webhooks that need to be dispatched.   But I need to guarantee that every event will be sent and have a log of it in DB.  So, I've come across the Dual Write problem and it's possible solution, the Outbox Pattern.   I've always listened people say that you should not do queues in DB, that polling is bad, that latency might skyrocket with time, that you might have BLOAT issues (in case of postgres).   But in those scenarios that you need to guarantee delivery with the Outbox Pattern you are literally doing a queue in db and making your job two times harder.  What are your thoughts on this?  	Reddit	27	[]
67	API Gateway for Mixed Use Cases: Frontend Integration and API-as-a-Service	artypple	2025-02-18T18:17:31Z	https://redd.it/1ishwq0	"In my current project, we have multiple backend microservices, namely Service A, Service B, and Service C, all deployed on Kubernetes. Our frontend application interacts with these services using JWTs for authentication, with token authentication and authorization handled at the backend level.  I am considering adding an API Gateway to our system (such as KrakenD or Kong) for the following reasons:  1. **Unified Endpoint:**¬†Simplify client interactions by providing a single URL for all backend services. 2. **API Composition:**¬†Enhance performance by aggregating specific API calls for the frontend.  Recently (and suddenly), we decided to offer our ""API as a Service"" to customers, limited to Service A and Service B (without Service C), using API keys for authentication.  However, I am now faced with a few considerations:  1. Is API Gateway by this new scenario still good idea?¬†Is it advisable to use a single API Gateway for both: our frontend and external customers (using API keys), or should i separate them with different Gateways? 2. The potential load from API key clients is uncertain, but I have concerns that it may overwhelm our small pods faster than the autoscaler can manage and our frontend will be down.  I seek advice on whether an API Gateway remains a good idea under these circumstances and how to best address these potential issues. I also appreciate any experiences and advice around managing APIs for our frontend and api-customers."	Reddit	8	[]
68	How Do You Keep Track of Service Dependencies Without Losing It?	whoisziv	2025-02-11T01:46:59Z	https://redd.it/1imm4pa	"Debugging cross-service issues shouldn‚Äôt feel like detective work, but it often does. Common struggles I keep hearing:  * **""Every incident starts with ‚Äòwho owns this?‚Äô""** * **""PR reviews miss hidden dependencies, causing breakages.""** * **""New hires take forever to understand our architecture.""**  Curious‚Äîhow does your team handle this?  * How do you track which services talk to each other? * What‚Äôs your biggest frustration when debugging cross-service issues? * Any tools or processes that actually help?  Would love to hear what‚Äôs worked (or hasn‚Äôt) for you."	Reddit	17	[]
69	"Is the ""O"" in SOLID still relevant, or just a relic of the past?"	Large-Style-8355	2025-02-07T09:35:34Z	https://redd.it/1ijqgpb	"Disclaimer: I assume the following might be controversial for some - so I ask you to take it what it is - my current feeling on a topic I want to hear your honest thoughts about.  An agency let me now that a freelance customer would obsess about the ""SOLID Pattern"" \[sic\] in their embedded systems programming. I looked into my languages wikipedia and this is what I read about the ""O"" in the SOLID prinziple:  * The Open-Closed Principle (OCP) states that software modules should be **open for extension but closed for modification** (Bertrand Meyer, *Object-Oriented Software Construction*). * Inheritance is an example of OCP in action: it extends a unit with additional functionality **without altering its existing behavior**.  I'm a huge fan of stable APIs - but at this moment a lightning stroke me from the 90s. I suddenly remembered huge legacies of OO inheritance hierarchies where a dev first had to put in extreme amount of time and brain power to find out how the actual functionality is spread over tons of old and new code in dozens or even hundreds of base and sub-classes. And you never could change anything old, outdated, because you knew you could break a lot of things. So we were just adding layers after layers after layers of new code on top of old code. I once heard Microsoft had its own ""Programming Bible"" (Microsoft Press) teaching this to any freshman. I heard stories that Word in the 2000s and even later had still code running written in the 80is. This was mentioned as one of the major reasons even base functionality like formatted bullet lists were (and still can be) so buggy.  So when I read about the ""O"" my impression as a life long embedded /distributed system programmer, architect and tech lead is its an outdated, formerly hyped pattern of an outdated formerly overly hyped paradigm which was trying to solve an issue, we are now solving completely different: You can break working things when you have to change or enhance functionality. In modern times we go with extensive tests on all layers and CI/CD and invite devs to change and break things instead of being extremely conservative and never touch anything working. In those old times code bases would get more and more complex mainly because you couldn't remove or refactor anything. Your only option was to add new things.  When I'm reading this I've got so a strong relief that I was working in a different area with very limited resources for so a long time that I just never had to deal with that insanity of complexity and could just built stuff based on the KISS principle (keep it simple, stupid). Luckily my developments are running tiny to large devices, even huge distributed systems driving millions of networked devices.  Thanks for sharing your thoughts on the ""O"" principle, if its still fully or partly valid or is there just ""Times they are changin""?     UPDATE:   I got a couple of invites to project and roles in embedded C++ - and all were in a way into the SOLID principle. I had like 3 multi-stage interviews at orgs having a heavy C++ embedded stack. One of my friends, a life long embedded C dev and a outstanding one, was working in such an environment for 2 years - and hated it so much.  Tons of architecture, components, layers, bits and pieces and even a dev who is part of creating new C++ standards. But the product is not working at all, first integration is to be done in a year or so.... I was working in such an environment in project for 8 months-ish and hated it as well. Hell, I'm so glad I'm back in embedded C (Zephyr based) now. Most of C++ I've seen the past 20 years seems like insanity to me..."	Reddit	41	[]
70	How Do Experienced Developers Gather and Extract Requirements Effectively?	RecommendationDry178	2025-02-04T23:52:48Z	https://redd.it/1ihv24b	"Hey everyone,  I‚Äôm a college student currently studying software development, and I‚Äôll be entering the industry soon. One thing I‚Äôve been curious about is how experienced developers and engineers handle requirements gathering from stakeholders and users.  From what I‚Äôve learned, getting clear and well-defined functional and non-functional requirements is crucial for a successful project. But in the real world, stakeholders might not always know what they need, or requirements might change over time. So, I wanted to ask those of you with industry experience:  	1.	How do you approach gathering requirements from stakeholders and users? Do you use structured 1-on-1 Calls, Written documents or something else?  	2.	How do you distinguish between functional and non-functional requirements? Do you have any real-world examples where missing a non-functional requirement caused issues?  	3.	What‚Äôs the standard format for writing user stories? I‚Äôve seen the typical ‚ÄúAs a [user], I want to [action] so that [outcome]‚Äù format‚Äîdoes this always work well in practice?  	4.	Have you encountered situations where poorly defined requirements caused problems later in development? How did it impact the project?  	5.	Any advice for someone new to the industry on how to effectively gather and document requirements?  I‚Äôd love to hear your insights, real-world experiences, or best practices. Thanks in advance!"	Reddit	30	[]
71	An Idea to Make API Hacking Much Harder	Formal-Luck-4604	2025-02-04T10:11:39Z	https://redd.it/1ihdphe	I‚Äôve been thinking about an interesting way to make API security **way more painful** for attackers, and I wanted to throw this idea out there to see what others think. It‚Äôs not a fully baked solution‚Äîjust something I‚Äôve been brainstorming.  One of the first things hackers do when targeting an API is **figuring out what endpoints exist**. They use automated tools to guess common paths like `/api/users` or `/api/orders`. But what if we made **API endpoints completely unpredictable and constantly changing**?  Here‚Äôs the rough idea:   üîπ Instead of using predictable URLs, we generate **random, unique endpoints** (`/api/8f4a2b7c-9d3e-47b2-a99d-1f682a5cd30e`).   üîπ These endpoints **change every 24 hours (or another set interval)**, so even if an attacker discovers one, it won‚Äôt work for long.   üîπ When a user's **session expires**, they log in again‚Äîand along with their new token, they get the **updated API endpoints** automatically.  For regular users, everything works as expected. But for hackers? **Brute-forcing API paths becomes a nightmare.**  Obviously, this isn‚Äôt a standalone security measure‚Äîyou‚Äôd still need **authentication, rate limiting, and anomaly detection**. But I‚Äôm curious: **Would this actually be practical in real-world applications? Are there any major downsides I‚Äôm not considering?**	Reddit	45	[]
72	Track changes made by my update api?	swiftlydealt	2025-02-01T09:30:31Z	https://redd.it/1if20ms	 I have an update API which can delete/add a list of ranges (object with a lower limit and upper limit), from existing list of ranges corresponding to a flag stored in the DDB. We have an eligibility check for a certain number to be present in those ranges or not. (5 is in \[1,3\]\[5,10\], while not in \[1,3\]\[7,10\]).  These ranges are dynamic as the API can be called to modify them as the day ago, and the eligibility can shift from yes to no or vise verse. We want to have a design that helps us check why the eligibility failed for some instance, basically store the change somehow everytime the API is executed.  Any clean pointers for approaches?  FYI: The one approach I have is without changing code in API flow, and have a dynamo db stream with a lambda dumping data to an s3 on each change.  	Reddit	1	[]
73	Why Aren't You Idempotent?	EspressoNess	2025-01-30T21:16:01Z	https://redd.it/1idwcmy	https://lightfoot.dev/why-arent-you-idempotent/  An insight into the many benefits of building idempotent APIs.	Reddit	7	[]
74	Composition Over Inheritance Table Structure	Unable_Original_3403	2025-01-27T15:20:46Z	https://redd.it/1iba5pg	I‚Äôve read that composition is generally preferred over inheritance in database design, so I‚Äôm trying to transition my tables accordingly.  I currently have an inheritance-based structure where User inherits from an abstract Person concept.  If I switch to composition, should I create a personalDetails table to store attributes like name and email, and have User reference it?  Proposed structure:  * personalDetails: id, name, email * User: id, personal\_details\_id (FK), user\_type  Does this approach make sense for moving to composition? Is this how composition is typically done?  edit: i think mixin is the better solution.	Reddit	10	[]
75	In what part of the software engineering process do I choose a software development methodology?	Inconnu	2025-01-21T17:58:03Z	https://redd.it/1i6n7qj	I'm making a generic software engineering process to follow every time i wanna make a software, and one thing i haven't figured out is the methodology part, is the impact of a methodology too great on the process and order of steps that it's better to have a different process for each methodology? or can methodology be chosen somewhere during the process? for example planning(before design) or design stage, how would you do it?	Reddit	31	[]
76	What Is the Best Validation Logic for an Internal API Gateway in Trading Systems?	Enough_Client7938	2025-01-20T11:34:36Z	https://redd.it/1i5ncxy	# Context:  To briefly describe our system, we are preparing a cryptocurrency exchange platform similar to Binance or Bybit. All requests are handled through APIs. We have an **External API Gateway** that receives and routes client requests as the first layer, and an **Internal API Gateway** that performs secondary routing to internal services for handling operations such as order management, deposits, withdrawals, and PnL calculations.  # Problem:  There is no direct route for external entities to send requests to or access the **Internal API Gateway**. However, authorized users or systems within permitted networks can send requests to the Internal API Gateway. Here lies the problem:  We want to **prohibit any unauthorized or arbitrary requests** from being sent directly to the Internal API Gateway. This is critical because users with access to the gateway could potentially exploit it to manipulate orders or balances‚Äîan undesirable and risky scenario.  Our goal is to ensure that **all valid requests originate from a legitimate user** and to reject any requests that do not meet this criterion.  I assume this is a common requirement at the enterprise level. Companies operating trading systems like ours must have encountered similar scenarios. What methodologies or approaches do they typically adopt in these cases?  # Additional Thoughts:  After extensive brainstorming, most of the ideas I‚Äôve considered revolve around encryption. Among them, the most feasible approach appears to involve **public-private key cryptography**, where the user signs their requests with a private key. While this approach can help prevent man-in-the-middle (MITM) attacks, it also introduces a significant challenge:  * If the server needs to store the user's private key for this to work, this creates a single point of failure. If a malicious actor gains access to these private keys stored on the server, the entire security system could be compromised. * On the other hand, if users are solely responsible for managing their private keys, the system risks becoming unusable if a user loses their key.  Are there any better alternatives to address this challenge? How do enterprise-grade systems handle such scenarios effectively?	Reddit	7	[]
77	Framework abstraction vs Framework deployment	riotinareasouthwest	2025-01-16T12:09:41Z	https://redd.it/1i2mkzx	Hi all. I have a problem reaching a conclusion how to model in the design a common scenario in my company and hope you can help me out here.  We are using different software frameworks in our projects. They are not the usual frameworks you may think about, the ones web related. These frameworks have specifications and different suppliers provide their own implementation.   Due to cybersecurity requirements, the design has to specify clearly which components come from a supplier, so all the components implementing the framework will need to be part of the supplier package.   On the other hand, I don't want the architects on the projects to dedicate time into defining the framework model, as this looks like repeating once and again the same activity and that will lead to different modeling and generate errors.   I want so to have a standard model of the framework and use that in the projects design. And now comes the problem: from one side, the framework components will be defined in a design file (we use Enterprise Architect)  inside a package; on the other side, I need to deploy these components into a project design file and put them inside the supplier package.   I want as well to use a reference rather than copy/pasting the component, to avoid possible modifications of the component model done on the project side, so I end up with one component element that has to be part of two different packages.   I know this is wrong so... how would you be doing this?	Reddit	2	[]
78	"Is there any term in software engineering more ambiguous than ""software design""?"	bkovitz	2025-01-15T18:02:58Z	https://redd.it/1i222pp	"Let's just look at ""software design"" in the sense of the thing a software designer makes, not the process of designing it. I have some observations and some questions.  There's a famous article by Jack Reeves, ""[What Is Software Design](https://www.developerdotstar.com/mag/articles/reeves_design.html)"" (_C++ Journal,_ 1992), which says that the source code _is_ the design. He points out that engineering creates a document that fully specifies something to be manufactured or constructed. That specification is the design.  In software, that specification is the source code. The compiler is the ""manufacturer"": it converts the source code into the bit patterns that are the actual software. (But what about interpreted code?)  Most people, though, distinguish between software design and source code. In software, when we speak of a design, we usually mean to omit information, *not* to fully describe the thing to be produced (or already produced). Is a ""software design"" a sort of outline of the software, like an outline of an essay‚Äîa hazy pre-description, roughly listing the main points?  If a ""software design"" is hazy by definition, then how can we tell when we're done making one? How can we test if the source code matches the design?  Some say that requirements is ""what"" the system does and design is ""how"" it does it. What's the difference, though? Consider a shopping cart on an e-commerce web site: is that _what_ the software does or _how_ the software lets the user place an order? It's both, of course. Alan Davis debunks the what/how distinction in more detail on [pp. 17‚Äì18](https://archive.org/details/softwarerequirem0000davi/page/16/mode/2up) of _Software Requirements: Objects, Functions, and States_ (1993).  What things does a ""software design"" describe?  * The modules, classes, subroutines, and data structures to be expressed in source code, and how they communicate‚Äîwhat information they send each other and when they send it. And C++ templates, too, right? And macros in Lisp. And threads. And exception-handling. And‚Ä¶ Is there anything expressed in source code that is _not_ software design?  * APIs.  * State-transition tables.  * Screens, dialogs, things to be displayed in a graphical user interface.  * Communication protocols. Is [SMTP](https://en.wikipedia.org/wiki/Simple_Mail_Transfer_Protocol) a software design?  * The mathematical rules according to which the effector outputs are to relate to the sensor inputs in a control system, like a controller for a washing machine or a guided missile.  * Data-storage formats, i.e. how information is to be represented by bits in files. Are ASCII and Unicode software designs?  * Database tables.  * The ""architecture"": modules etc. as above, plus how processing is allocated among servers and clients, load balancers, microservices, sharding, etc.  * Is inventing a new algorithm ""software design""?  * Are the syntax and semantics of a computer language a ""software design""?  * Are use cases requirements or design? [Googling](https://bit.ly/4fYEzcz) suggests that there are many opposing and complex opinions about this.  * Have I left anything out?  If you go to a web-design firm or a company where GUIs are their forte, do they distinguish ""software design"" from ""software requirements""? When Norman-Nielsen Group ""designs software"", do they start with a long list of ""shall"" statements (""requirements"") and then methodically work out a ""software design""? They seem to take very seriously that you should understand ""the problem"" separately from ""the solution"", but I'm not sure how much of the above corresponds to how they understand the term ""software design"".  [Another way](https://www.wirfs-brock.com/PDFs/CreatingSustainableDesigns.pdf) to distinguish software design has been advanced by Rebecca Wirfs-Brock: design is what goes beyond correctness to cover the qualities that make the source code habitable for the people who have to live with it and maintain it‚Äîeverything from the organization of modules and subroutines to how consistently things are named.  Yet another understanding of ""software design"", inspired by Michael Jackson, distinguishes _[domains](https://archive.org/details/practicalsoftwar00kovi/page/38/mode/2up),_ in which you can describe anything that you want to exist, but fixing, in any way you choose, the types of subjects and predicates that you will limit your descriptions to. Whatever you want in the problem domain or the solution domain, or in the interface domain where they interact, design it as you please. On this interpretation of ""design"", degree of haziness does not distinguish design from requirements or implementation; you can describe each domain completely and precisely.   Do you know of other writings or have other opinions that involve different understandings of what ""software design"" means? I'd love to hear them. Or, if you know of another term in software engineering that's as or more ambiguous, I'd love to hear that, too."	Reddit	13	[]
79	Principles For A Robust Software Design:	Only_Dragonfruit_366	2025-01-13T08:48:30Z	https://redd.it/1i090g3	Principles For A Robust Software Design  (How To Optimize A Software Design) Ever felt overwhelmed by the intricacies of software design? Yes, it can be as tough as it sounds. But fear not! We're here to demystify the process and offer clarity. Join us-TechCreator.co, as we explore key strategies to enhance your digital creations, ensuring they are not only functional but also user-friendly.  First we need to know what is software designing.  Software designing is actually done before implementation. It is planning and defining how a software will work, which includes both documented and undocumented concepts.  It is predefined specifications which is then translated into actual code.    Here we have some principles to build a robust software design for your client.   Always have two or more approaches and compare the trade-offs   Comparison is important. If we don‚Äôt compare, we won‚Äôt know which approach is better. We always should have a healthy discussion with the team to discuss if there is any other better aspects of the design to consider. If more people are concerned, may be there can be a better quality of a solution.  Modularity  Modularity means breaking down a system into smaller, independent units that can be developed, tested and maintained separately. If it is done at early stages, a developer will find it easy to bring changes to one module without affecting others. Simply, modularity allows developers to reuse code across different projects, reducing development time and increasing code quality.   Low coupling  In software engineering, low coupling means that how different modules, classes and components within a system interact and go along with each other. Simply we can say that low coupling means that components are loosely connected and work independently. Such process makes systems simpler, more flexible and robust. The opposite of  low-coupling is high coupling.    Abstraction  Abstraction is also one of the principles for elevated software design. Abstraction is the process of removing unnecessary from a system and focus on what is important. We can also call it object-oriented programming. It improves productivity, reduces complexity and increases efficiency. In short it is the process of simplifying complex reality by modeling classes of objects or systems in a high-level manner while ignoring irrelevant details.  Design Patterns Besides the fundamentals of software design, we also need to know, understand, and practice the well-known design patterns described clearly in the book ‚ÄúDesign Patterns: Elements of Reusable Object-Oriented Software‚Äù by the Gang of Four (i.e., Erich Gamma et al).  In this book, there are three types of design patterns: Creational ‚Äî builder, factory method, abstract factory, prototype, singleton Structural ‚Äî adapter, flyweight, proxy, composite, decorator‚Ä¶ Behavioral ‚Äî strategy, mediator, observer, template, chain of responsibility, etc. I have nothing to write here except to recommend that you read the book and practice those patterns in the meanwhile.  Continuous Integration and Delivery Software design also needs to focus on continuous integration and delivery. This means that software is constantly being tested and integrated into the production environment. By automating these processes, firms turn down the time and cost of software quality improvement.    Conclusion   There is no complete formula for good designs. Just follow fundamental practices and you will be alright. But understanding all of them and then applying them to real problems is really challenging, even for senior engineers. Having a good mindset helps you to focus on the right things to learn, and to accumulate valuable experiences and skills along the way. From my point of view, I can sum up important fundamentals that make good designs for most of the software (but not all): ‚Äúwell-designed abstractions, high cohesive classes/modules, loose coupling dependencies, composition over inheritance, domain-driven, good design patterns.‚Äù  To know more about web development or to avail our services visit our website: TechCreator https://www.techcreator.co/  	Reddit	10	[]
80	What to do with rate limiting service?	DressIndependent4722	2025-01-10T15:54:06Z	https://redd.it/1hy64u3	"We need to talk to some external services that might have rate limit, for example, they might return an error if we send more requests over a threshold within a period of time. How to handle such cases? I think the best way is to retry, optionally with a backoff, but most of people on my team agree that we should rate limit on our (client) side. There are two types of reasons: 1) retries will waste network resources and increase costs; 2) we should be a ""polite"" citizen. I'm wondering how many people out here think the same way.  A funny thought is: when the server throws error, one would ask, why didn't our own rate limiter kick in because that means ours isn't working. When our client side rate limiter errors, one would wonder, if we hadn't our own rate limiter, would this request have had gone through?"	Reddit	9	[]
81	If not UML what?	pmz	2025-01-07T20:24:06Z	https://redd.it/1hvzjnz	Is UML considered deprecated? if yes, then what is the modern counterpart? Maybe C4? What do you guys use?	Reddit	28	[]
82	Source Code Handover Document?	Inconnu	2025-01-08T13:36:31Z	https://redd.it/1hwj8pl	Context : We outsourced a mobile app development. The app is developed and now we took over the source code. However, there is no source code documentation. I will be taking over the source code alone in my team. I started learning flutter but ofc the source code they shared is massive and complex. Now I personally feel I need a document explaining the source code. Asked gpt for a basic structure and it suggested to ask for things like  api int, project struc,state management,custom widgets, ext library and changes made in them. Is it normal to ask for such details or I have to go through every file and understand it by my self. I am going to inform my manager and request a proper Document but I needed opinion on this since I am a fresher. Do I have to go through the source code and understand each and everything by myself or documents are normal for source code? Because if it is normal, I can ask my manager to ask the team to prepare one. Ofc he might also be aware whether it's normal or not but I needed a third opinion.  Thanks for ur help.  I do know how to read new codebase. I also learned dart and flutter with state management but the code base is really complex. Ofc it would take time to understand it.	Reddit	10	[]
83	SRE production readiness checklist	Weak-Appointment-566	2025-01-03T23:28:54Z	https://redd.it/1hsyzm4	We are new SRE team in online shopping platform. Stack consists of Spring boot as BE, 50 microservices on on premise kubernets clusters, react based front and mobile apps. Spring services mostly provides APIs for mobile and web apps. syncronous and asyncronous(kafka) communication happens amongmicroservices. Business logics sits heavily on Spring boot, we use PostgreSQL as database. There are separate devops team for ci/cd and other processes.Our job is to bring SRE culture to organization and improve reliability a lot for. As initial step we agreed to have discussions with development teams and formalize spring template per best practieses and apply it across org. It is called Productions readiness (PRR)or operation readiness(ORR) checks in some companies. What would you add to template(checklist document) as requirement,checklist from development team. ?	Reddit	2	[]
84	Standard Documentation 	chxckbxss	2025-01-03T08:50:28Z	https://redd.it/1hshbrm	BPMN and UML are examples of documentation standards that can be understood worldwide, so why do practitioners come up with their own (inconsistent, incoherent, incomplete) diagrams that require consumers to decipher them?  	Reddit	12	[]
85	Testing strategies in a RAG application	ourss__	2025-01-02T12:27:03Z	https://redd.it/1hrrnyg	"Hello everyone,  I've started to work with LLMs and RAGs recently. I'm used to ""traditional software testing"" with test frameworks like pytest or Junit, but I am a bit confused about testing strategies when it comes to generative AI. I am wondering several things, and I don't find a lot of resources or methodologies. Maybe I'm just not looking for the right thing or do not have the right approach.  For the end-user, these systems are a kind of personification of the company, so I believe that we should be extra cautious about how they behave.  Let's take the example of a RAG system designed to make legal guidance for a very specific business domain.  * Do I need to test all [unwanted behaviors](https://developsense.com/large-language-model-syndromes) inherent to LLMs? * Should I make unit tests with the [Langchain approach](https://docs.smith.langchain.com/evaluation/tutorials/rag#overview) to test that my application behaves as expected? Are there other approaches? * Should I write tests to mitigate risks associated with user input like prompt injections, abusive demands, and more? * Are there other major concerns related to LLMs?"	Reddit	5	[]
86	How to clearly estimate timeline and demonstrate contribution with ambiguities?	TemporaryHeight2164	2024-12-29T07:01:38Z	https://redd.it/1hopmyz	 Hi all,  Posting it here given this question has strongly block my mental health. Wanted to seek for some professional advice by getting your stories shared.  As a mid level software engineer, I feel there are always tremendous blockers and ambiguities on my project that blocks my timeline. And every small task that I don‚Äôt know the detailed implementation plan can be the last straw.  Let's take my recent project as an example.   I need to touch multiple APIs in different servers plus front end UI changes plus multiple schemas in an internal DB. During design phrase, I draw a system diagram with all the involved components plus all the API names and the code logics to be changed to support the project. But what I missed and eventually blocked me were:   1. The permissions needed to grant access to talk to the server. This part sucks given I even do not know we need these until we started e2e testing and it needed a 30 days release schedule. I do feel pride of myself given I finally debugged the permission issue and set it up by myself. But when everyone comes to me and ask me about a timeline on how and when to fix it, before I got the answer, I can only say I don‚Äôt know. This is a bad feeling and I don‚Äôt know how to overcome it.  2. The unit tests. Our codebase in the front end did not have any unit test covered but the front end code owner wanted some unit tests which means I need to create unit tests to cover a huge code file. This definitely took extra time which was a surprise and took me time to ramp up to the testing infrastructure on the front end. I feel I did not demonstrate my contribution well in this case. And what was shown is I delayed my implementation for several days to check in the code changes.   3. Back and forth code location changes. There are many reviewers in the project which had contradicted opinion about my project. And I was forced to move the codes from one place to another. Then I was given the feedback that I need to align the codes before write them up. But the reviewers were in my design review and was OK about my proposal. But when it came to the implementation level, given they are in the helper functions, the reviewers had a second opinion about which helper functions to put the codes.  I felt super bad on this project given I did a hard work to make all of these happen but my manager and PM are only focusing on the delay of timeline.  So I feel I definitely need a better way to communicate about the parts that I don‚Äôt know but block my project original designed timeline. I deserve better appreciation on how hard I worked to make everything happen. But these parts are not well demonstrated and presented.	Reddit	37	[]
87	Lean Team, Big Bugs: How Do You Handle Testing Challenges?	No-Manufacturer4818	2024-12-25T00:42:45Z	https://redd.it/1hlpccj	Hey folks, just wanted to share something we‚Äôve been struggling with at my startup‚Äîtesting. It‚Äôs honestly such a pain. We‚Äôre always trying to move fast and ship features, but at the same time, bugs slipping through feels like a disaster waiting to happen. Finding that balance is hard.  We‚Äôre a small team, so there‚Äôs never enough time or people to handle testing properly. Manual testing takes forever, and writing automated tests is just...ugh. It‚Äôs good when it works, but it‚Äôs such a time suck, especially when we‚Äôre iterating quickly. It feels like every time we fix one thing, we break something else, and it‚Äôs this never-ending cycle.  We‚Äôve tried a bunch of things‚ÄîCI/CD pipelines, splitting testing tasks across the team, and using some tools to automate parts of it. Some of it works okay, some doesn‚Äôt. Recently stumbled across this free tool (it‚Äôs called TestSprite or something), and it‚Äôs been pretty decent for automating both frontend and backend tests in case you are also looking for a free resource or tool...  I‚Äôd love to know‚Äîhow do you all deal with testing when you‚Äôre tight on resources? Any tools, hacks, or strategies that have worked for you? Or is this just one of those ‚Äòwelcome to startup life‚Äô things we all have to deal with? Would really appreciate hearing what‚Äôs worked for others!	Reddit	18	[]
88	Wanted: thoughts on class design for Unit Testing	Over-Use2678	2024-12-20T18:00:35Z	https://redd.it/1hio964	As background, I'm a Software Engineer with a couple decades of experience and a couple of related college degrees in software. However, I've only started to appreciate the value of unit tests in the last 5 years or so. Having worked for companies which only gave lip service to Unit tests didn't help. That being said, I've been attempting to write unit tests for most applications I've been working on. Especially libraries which will both be shared and might be altered by other employees. For the record, I'm using C#, Moq, and XUnit frameworks for the moment and don't have plans to change them. But as I'm implementing things, I'm running into a design problem. I believe this is not a problem unique to C# - I'm sure it's been addressed in Java and other OOP languages.  I have some classes in a library where the method being used encompasses a lot of functionality. These methods aren't God methods, but they're pretty involved with trying to determine the appropriate result. In an effort to honor the Single Responsibility principle, I break up the logic into multiple private functions where it is appropriate. For example, evaluation of a set of objects might be one private method and creation of supporting objects might be in another private method. And those methods really are unique to the class and do not necessarily warrant a Utility class, etc. I'm generally happy with this approach especially since the name of the method identifies its responsibility. A class almost always implements an interface for Dependency Inversion purposes (and uses the built-in Microsoft DI framework). The interface exposes only public methods to the class.   Now we get to Unit Tests. If I keep my classes how they are, my Unit Tests can get awkward. I have my UT classes at a one per library class method. Meaning that if my library class has 5 public methods exposed in the interface, the UT libraries have 5 classes, each of which tests only one specific method multiple times. But since the private methods aren't directly testable and I go to break up the library's methods into a bunch of private methods, then the corresponding Unit Test will have a boatload of tests in it because it will have to test both the public method AND all of the private methods that might be called within the public method.   One idea I've been contemplating is making the class being tested have those private methods become public but not including them in the interface. This way, each can be unit tested directly but encapsulation is maintained via the lack of signature in the interface.   Is this a good idea? Are there better ones? Should I just have one Unit Test class test ALL of the functionality?   Examples are below. Keep in mind each UnitTest below would represent many unit tests (10+) for each portion.   **Current**      public interface ILibrary     {         int ComplexFunction();     }          public class LibraryVersion1 : ILibrary     {        public int ComplexPublicFunction()         {            // Lots of work.....            int result0 = // Results of work in above snippet                 int result1 = Subfunction1();            int result2 = Subfunction2();                  return result1 + result2 + result0;        }             private int Subfunction1()         {              // Does a lot of specific work here            return result;        }        private int Subfunction2()         {              // Does a lot of specific work here            return result;        }     }          public class TestingLibraryVersion1()     {          [Fact]          public void Unit_Test1_Focused_On_Area_above_Subfunction_Calls() { .... } // times 10+          [Fact]          public void Unit_Test2_Focused_on_Subfunction1() { .... } // times 10+          [Fact]          public void Unit_Test3_Focused_on_Subfunction2() { .... } // times 10+     }  **Proposed**      public interface ILibrary     {         int ComplexFunction();       }          public class LibraryVersion2 : ILibrary     {        public int ComplexPublicFunction()         {            // Lots of work.....            int result0 = // Results of work in above snippet                 int result1 = Subfunction1();            int result2 = Subfunction2();                  return result1 + result2 + result0;        }             public int Subfunction1()         {              // Does a lot of specific work here            return result;        }        public int Subfunction2()         {              // Does a lot of specific work here            return result;        }     }          public class TestingLibraryVersion2()     {          [Fact]          public void Unit_Test1_Focused_On_Area_above_Subfunction_Calls() { .... } // times 10              }          public class TestingSubfunction1()     {              [Fact]          public void Unit_Test2_Focused_on_Subfunction1() { .... } // times 10     }          public class TestingSubfunction2()     {              [Fact]          public void Unit_Test2_Focused_on_Subfunction1() { .... } // times 10     }       	Reddit	19	[]
89	Question about Memento Pattern.	Muhammad-Ali-1	2024-12-19T20:14:52Z	https://redd.it/1hi0ljc	Hi everyone.   I was studying Memento Pattern, and what I understood is:   We use it whenever we need to store and retrieve previous states of object.  The good thing about Memento is that it actually allows to encapsulate the data inside the object we want to save.  In the example below, I don't get how the \`History\` can access any details from the object we want to save.  What I don't get is why can't we use generics instead.  I hope someone can help me get what am I missing here.  Also, If there some article or any source to help me understand. I really did searched but couldn't point the problem.      public final class History <T> {         private List<T> dataHistory = new ArrayList<T>();              T getData() {             return dataHistory.get(dataHistory.size() - 1);         }              void setData(T newData) {             dataHistory.add(newData);         }              void undo() {             dataHistory.remove(dataHistory.size() - 1);         }     }	Reddit	5	[]
90	A tsunami is coming	Inconnu	2024-12-17T23:32:27Z	https://redd.it/1hgmru9	"TLDR: LLMs are a tsunami transforming software development from analysis to testing. Ride that wave or die in it.  I have been in IT since 1969. I have seen this before. I‚Äôve heard the scoffing, the sneers, the rolling eyes when something new comes along that threatens to upend the way we build software. It happened when compilers for COBOL, Fortran, and later C began replacing the laborious hand-coding of assembler. Some developers‚Äîmyself included, in my younger days‚Äîwould say, ‚ÄúThis is for the lazy and the incompetent. Real programmers write everything by hand.‚Äù We sneered as a tsunami rolled in (high-level languages delivered at least a 3x developer productivity increase over assembler), and many drowned in it. The rest adapted and survived. There was a time when databases were dismissed in similar terms: ‚ÄúWhy trust a slow, clunky system to manage data when I can craft perfect ISAM files by hand?‚Äù And yet the surge of database technology reshaped entire industries, sweeping aside those who refused to adapt. (See: Computer: A History of the Information Machine (Ceruzzi, 3rd ed.) for historical context on the evolution of programming practices.)  Now, we face another tsunami: Large Language Models, or LLMs, that will trigger a fundamental shift in how we analyze, design, and implement software. LLMs can generate code, explain APIs, suggest architectures, and identify security flaws‚Äîtasks that once took battle-scarred developers hours or days. Are they perfect? Of course not. Just like the early compilers weren‚Äôt perfect. Just like the first relational databases (relational theory notwithstanding‚Äîsee Codd, 1970), it took time to mature.  Perfection isn‚Äôt required for a tsunami to destroy a city; only unstoppable force.  This new tsunami is about more than coding. It‚Äôs about transforming the entire software development lifecycle‚Äîfrom the earliest glimmers of requirements and design through the final lines of code. LLMs can help translate vague business requests into coherent user stories, refine them into rigorous specifications, and guide you through complex design patterns. When writing code, they can generate boilerplate faster than you can type, and when reviewing code, they can spot subtle issues you‚Äôd miss even after six hours on a caffeine drip.  Perhaps you think your decade of training and expertise will protect you. You‚Äôve survived waves before. But the hard truth is that each successive wave is more powerful, redefining not just your coding tasks but your entire conceptual framework for what it means to develop software. LLMs' productivity gains and competitive pressures are already luring managers, CTOs, and investors. They see the new wave as a way to build high-quality software 3x faster and 10x cheaper without having to deal with diva developers. It doesn‚Äôt matter if you dislike it‚Äîhistory doesn‚Äôt care. The old ways didn‚Äôt stop the shift from assembler to high-level languages, nor the rise of GUIs, nor the transition from mainframes to cloud computing. (For the mainframe-to-cloud shift and its social and economic impacts, see Marinescu, Cloud Computing: Theory and Practice, 3nd ed..)  We‚Äôve been here before. The arrogance. The denial. The sense of superiority. The belief that ‚Äúreal developers‚Äù don‚Äôt need these newfangled tools.  Arrogance never stopped a tsunami. It only ensured you‚Äôd be found face-down after it passed.  This is a call to arms‚Äîmy plea to you. Acknowledge that LLMs are not a passing fad. Recognize that their imperfections don‚Äôt negate their brute-force utility. Lean in, learn how to use them to augment your capabilities, harness them for analysis, design, testing, code generation, and refactoring. Prepare yourself to adapt or prepare to be swept away, fighting for scraps on the sidelines of a changed profession.  I‚Äôve seen it before. I‚Äôm telling you now: There‚Äôs a tsunami coming, you can hear a faint roar, and the water is already receding from the shoreline. You can ride the wave, or you can drown in it. Your choice.    Addendum  My goal for this essay was to light a fire under complacent software developers. I used drama as a strategy. The essay was a collaboration between me, LibreOfice, Grammarly, and ChatGPT o1. I was the boss; they were the workers. One of the best things about being old (I'm 76) is you ""get comfortable in your own skin"" and don't need external validation. I don't want or need recognition. Feel free to file the serial numbers off and repost it anywhere you want under any name you want."	Reddit	935	[]
91	Imports vs. dependency injection in dynamic typed languages (e.g. Python)	makeevolution	2024-12-13T15:35:07Z	https://redd.it/1hddipp	Over my experience, what I found is that, instead of doing the old adage DI is the best since our classes will become more testable, in Python, due to it being very flexible, I can simply import dependencies in my client class and instantiate there. For testability concerns, Python makes it so easy to monkeypatch (e.g. there's a fixture for this in Pytest) that I don't really have big issues with this to be honest. In other languages like C#, importing modules can be a bit more cumbersome since it has to be in the same assembly (as an example), and so people would gravitate more towards the old adage of DI.  I think the issue with Mocking in old languages like Java comes from the compile time and runtime nature of it, which makes it difficult if not impossible to monkeypatch dependencies (although in C# there's like modern monkeypatching possible nowadays https://harmony.pardeike.net/, but I don't think it's that popular).  How do you find the balance? What do you do personally? I personally like DI better; it keeps things organized. What would be the disadvantage of DI over raw imports and static calls?	Reddit	10	[]
92	Opinions on CRUDdy by Design	murarajudnauggugma	2024-12-12T01:40:31Z	https://redd.it/1hc8t25	This talk was authored by Adam Wathan back in 2017 at Laracon US, a Laravel Convention. My senior showed me this concept, which I believe is quite powerful. I know its a laravel convention but the concept could be applied on any other frameworks. It simplifies controllers, even though it may create more of them. I'd like to hear your thoughts.  anyway here's the link to the video: [CRUDdy by Design](https://www.youtube.com/watch?v=MF0jFKvS4SI)	Reddit	1	[]
93	Does Scrum actually suck, or are we just doing it wrong?	Own-Substance-9386	2024-12-11T00:03:28Z	https://redd.it/1hbezji	I just read this [article,](https://thenewstack.io/scrum-sucks-because-youre-doing-it-wrong/) and it really made me think about all the hate Scrum gets. A lot of the problems people have with it seem to come down to how it‚Äôs being used (or misused). Like, it‚Äôs not supposed to be about micromanaging or cramming too much into a sprint‚Äîit‚Äôs about empowering teams and delivering value.  The article does a good job of breaking down how Scrum can go off the rails and what it‚Äôs actually meant to do. Honestly, it gave me a fresh perspective.  Curious to hear how others feel about this‚Äîis it a broken system, or are we just doing it wrong? 	Reddit	155	[]
94	Using 5 Whys to identify root causes of issues	Inconnu	2024-12-08T09:57:42Z	https://redd.it/1h9eto0	"The 5 Whys technique is a simple problem-solving method used to identify the root cause of an issue by repeatedly asking ""Why?""‚Äîtypically five times or until the underlying cause is found. Sakichi Toyoda, founder of Toyota Industries, developed the 5 Whys technique in the 1930s. It is part of the Toyota Production System.  Starting with the problem, each ""why"" digs deeper into the contributing factors, moving from surface symptoms to the root cause. For example, if a machine breaks down, asking ""Why?"" might reveal that it wasn‚Äôt maintained properly, which might be traced back to a lack of a maintenance schedule. The technique helps teams focus on fixing the core issue rather than just addressing symptoms.  [Introduction to 5 Whys](https://www.mindtools.com/a3mi00v/5-whys)      I don‚Äôt use 5 Whys nearly as much as I should since it irritates stakeholders, but every time I have, the results have been excellent. What has been your experience? Do you use similar techniques to find and fix core issues rather than address symptoms?  "	Reddit	7	[]
95	Eliciting, understanding, and documenting non-functional requirements	Inconnu	2024-12-06T13:07:57Z	https://redd.it/1h7zx30	Functional requirements define the ‚Äúwhat‚Äù of software. Non-functional requirements, or NFRs, define how well it should accomplish its tasks. They describe the software's operation capabilities and constraints, including availability, performance, security, reliability, scalability, data integrity, etc. How do you approach eliciting, understanding, and documenting nonfunctional requirements? Do you use frameworks like TOGAF (The Open Group Architecture Framework), NFR Framework, ISO/IEC 25010:2023, IEEE 29148-2018, or others (Volere, FURPS+, etc.) to help with this process? Do you use any tools to help with this process? My experience has been that NFRs, while critical to success, are often neglected. Has that been your experience?	Reddit	12	[]
96	How to run compute queries optimally?	Certain-Training-265	2024-12-03T18:38:51Z	https://redd.it/1h5t2xm	I am solving a problem where I have a very large dataset with unstructed data.  This would be usually accessed a lot to get customer info and analysing trends from different groups.  I need to make this access optimal.  Realtime data based analytics is not a requirement. We would usually query and validate data across weeks or months. What are the best ways to access data from databases to compute queries optimally?  	Reddit	1	[]
97	Goal-Oriented Requirements Engineering (GORE)	Inconnu	2024-12-01T14:19:00Z	https://redd.it/1h433wa	Goal-Oriented Requirements Engineering (GORE) is an approach to requirements engineering that focuses on identifying, analyzing, and refining stakeholders' goals into detailed system requirements. Please tell me about your experiences using GORE in your projects‚Äîwhat methodologies (e.g., KAOS, i\*, GRL) and tools (e.g., OpenOME, jUCMNav, Enterprise Architect) have you used, and how effective have they been in aligning requirements with stakeholders' objectives? Did using GORE improve the clarity of requirements and overall project success?	Reddit	10	[]
98	Composite SLA/SLOs	mvr_01	2024-11-26T18:55:32Z	https://redd.it/1h0i2fz	I have been thinking about how I have always read that to compute the composite availability when depending on two parallel services we multiply their availabilities. E.g. [Composite Cloud Availability | Google Cloud Blog](https://cloud.google.com/blog/products/devops-sre/composite-cloud-availability)  I understand this comes from probability theory, where assuming two services are independent:      A = SLA of service A     B = SLA of service B     P(A and B) = P(A) * P(B)   However, besides assuming independence, this treats SLAs like probabilities, which they are not.  Instead, to me what would make sense is:      A = SLA of service A     B = SLA of service B     DA = Maximum % of downtime over a month of A = (100 - A)     DB = Maximum % of downtime over a month of B =  (100 - B)     Worst case maximum % of downtime over a month of A or B = 100 - DA - DB = 100 - (100 - A) - (100 - B) = A + B - 100  For example:      Example 1          99.41 * 99.71 / 100 = 99.121711     vs     99.41 + 99.71 - 100 = 99.12               Example 2          75.41 * 98.71 / 100 = 74.437211     vs     75.41 + 98.71 - 100 = 74.12  I see that the results are similar, but not the same. Playing with GeoGebra I can see they are only similar when at least one of the availabilities is very high.  [SLA B = 99.99, X axis is availability of A, availability X\*B \(red\) vs X+B-100 \(green\)](https://preview.redd.it/857dwwbyaa3e1.png?width=927&format=png&auto=webp&s=a7171b028a1b1c70818db5c8019459b1a7ff1f9e)  [SLA B = 95.3, X axis is availability of A, availability X\*B \(red\) vs X+B-100 \(green\)](https://preview.redd.it/zw4btva2ba3e1.png?width=922&format=png&auto=webp&s=746f98f29cdbd6b7f91af2b70b147a26f86a9572)  **Why do we multiply instead of doing it as I suggest? Is there something I am missing? Or its simply done like this for simplicity?**	Reddit	1	[]
99	Is this algo any good?	search_for_theDIVINE	2024-11-23T09:25:41Z	https://redd.it/1gxv007	  I thought of this idea for a data structure, and I'm not sure if it's actually useful or just a fun thought experiment. It's a linked list where each node has an extra pointer called prev_median. This pointer points back to the median node of the list as it was when the current node became the median.  The idea is to use these prev_median pointers to perform something like a binary search on the list, which would make search operations logarithmic in a sorted list. It does add memory overhead since every node has an extra pointer, but it keeps the list dynamic and easy to grow like a normal linked list.  Insertion and deletion are a bit more complex because you need to update the median pointers, but they should still be efficient. I thought it might be useful in situations like leaderboards, log files, or datasets where quick search and dynamic growth are both important.  Do you think something like this could have any real-world use cases, or is it just me trying to reinvent skip lists in a less elegant way? Would love to hear your thoughts...  	Reddit	12	[]
100	Software Requirements Specification in the context of FDA guidance	ntwiles	2024-11-18T20:23:18Z	https://redd.it/1gud2ln	We're working on documenting an FDA De Novo pre-market submission, one requirement of which is a software requirements specification (SRS) document. We're creating this new for the filing, for already existing software. Until now we've been working from a design control matrix (DCM) as our source of truth. No one on our small team is very experienced with writing SRS.  So far I understand that the SRS normally has a highly abstracted list of functional requirements, which the DCM would derive from, the DCM being responsible for defining more explicit and verifiable requirements. Then of course there's the (also required) software design specification (SDS) which goes into implementation details.  The FDA though seems to be asking for very well defined requirements *within* the SRS. The following comes from their guidance in[ this document](https://www.fda.gov/media/73141/download):  >The software requirements specification document should contain a written definition of the software functions. It is not possible to validate software without predetermined and documented software requirements. Typical software requirements specify the following:  >\- All software system inputs;   \- All software system outputs;   \- All functions that the software system will perform;   \- All performance requirements that the software will meet, (e.g., data throughput, reliability, and timing);   \- The definition of all external and user interfaces, as well as any internal software-to-system interfaces;   \- How users will interact with the system;   \- What constitutes an error and how errors should be handled;   \- Required response times;   \- The intended operating environment for the software, if this is a design constraint (e.g., hardware platform, operating system);   \- All ranges, limits, defaults, and specific values that the software will accept; and   \- All safety related requirements, specifications, features, or functions that will be implemented in software.  This leads me to believe that they expect the SRS to be much more granular than it normally would be. Reading this, I would think that if I were documenting a requirement for (say) user authentication, I would need to explicitly define all expected API responses, their status codes, their bodies, and also constraints on both the user and password request (input) fields, and potentially even details on the method by which the authentication happens. It also sounds like it would need to be more exhaustive than normal, covering *all* functions of the software, not just the broad requirements.  That's fine if that's the case, it just doesn't line up with my initial understanding of the SRS as an abstract document of functional requirements that's normally intended to be written prior to any work having started.   Many of these details I feel like will be dependent on our specific implementation choices, which I feel would belong in the SDS instead.  What I'm thinking of doing so far is exactly what I've described above, very detailed requirements, providing references to relevant design outputs where applicable for traceability. With that in mind, any input would be hugely appreciated.	Reddit	12	[]
101	Beyond Code: Finding Meaning in an Industry That Never Stops Changing	eightOrchard	2024-11-16T04:07:10Z	https://redd.it/1gse11z	Wrote down a useful revelation I had. Here is the full write up. ‚Äî‚Äî‚Äî  Software is short lived. The world of software moves fast and even great code quickly goes out of date. This is a problem because the constant change would at times rob me of my job satisfaction. There is something inherently comforting in knowing your work lasts.  The planting  This normally was not top of mind for me. I thought I was satisfied with my day to day work. But that was called into question when I had to plant a tree. The work was not as cognitively taxing as writing software. But the air was hot and humid and the actual digging was slow and laborious. The planting directions that came with the tree were specific on the dimensions of the hole and the composition of the soil mix. Getting the hole to meet the specs was more taxing than I care to admit.  I was not alone in this endeavor. I had my spouse there to compliment my failing cognitive abilities as my physical energy waned. She would keep the soil mixture precise and keep me on track to finish before dusk. It was hard work but probably good for my body to move after sitting at a desk all day. Upon completion of the hole I triumphantly picked up this thin arborvitae from the grass and stuck it into the ground with the zest of an explorer planting his flag into a newly discovered land. We straightened the trunk and layered the earth back over the root bulb. A job well done.  The epiphany   As I stood back with my spouse admiring our work a rush of satisfaction ran over me. It was unexpected. I took a moment to reflect on why I was feeling this way. I realized this tree could be there for the next 50 years. I can look out at it every day and watch it grow tall. My friends and family will probably play in it. It will be in the backdrop of our lives for a long time. That thought was satisfying.  The Change  I can‚Äôt plant a physical tree every day. But how can I get this feeling more, especially from my work? I try to focus on things that will last. The software probably won‚Äôt, but the trust I build with a customer after solving their problem can. The relationship that can be born out of that trust can persist as long as I hold up my end. Teaching another engineer to solve a problem is rewarding. But knowing that problem can be gone from their life forever is a type of tree. I try to focus on the lasting outcomes I can provide instead of the fleeting software changes. So plant trees that last, they are there if you look. Your mental health may thank you. 	Reddit	8	[]
102	Guide to The Software Engineering Body of Knowledge v4	Upstairs_Ad5515	2024-11-13T11:58:08Z	https://redd.it/1gqabse	SWEBOK V4.0 is the newest edition of the internationally acclaimed Software Engineering Body of Knowledge. This guide, crafted by top experts and rigorously reviewed by industry professionals, is designed to be a dynamic and evolving resource. It has been made available for public review and feedback, maintaining its 20-year tradition as the definitive and most trusted reference for software engineering professionals.  [https://ieeecs-media.computer.org/media/education/swebok/swebok-v4.pdf](https://ieeecs-media.computer.org/media/education/swebok/swebok-v4.pdf)	Reddit	2	[]
103	Seeking Best Practices for Efficient Logging and Auditing in a Small Team Environment	trojonx2	2024-11-13T06:37:14Z	https://redd.it/1gq5xwb	I'm working on enhancing the logging and auditing system for our application, and I'm looking for technology-agnostic **best practices** to guide our implementation.  **Context:**  - We have a SQL Server database following a header-detail pattern. - The header tables include a primary key `TransactionID` and columns like `CreatedBy`, `ModifiedBy`, along with their respective timestamps. - The detail tables reference `TransactionID` as a foreign key. - Currently, whenever a user clicks the save button, we update the `ModifiedBy` and `ModifiedDate` in the header table, regardless of whether any actual data changes occurred. - This means we only know **who last saved** and **when**, but not **what was changed** or **who made previous changes**.    **Example:**    - **User X** changes the quantity in a detail table. We store User X in `ModifiedBy` in the header table .   - Later, **User Y** presses the save button without making any changes; his ID gets saved in `ModifiedBy` in the header table .   - When management wants to know who changed the quantity, they first reach out to User Y and then have to investigate further to find the actual person who made the change.  - **Team Size:**   - 2 co-founders acting as DBAs (one is the CTO involved in SQL Server development).   - Myself, with less than 1 year of T-SQL experience.   - A junior developer.  **Our Requirements:**  - Clients need to know **who made specific data changes** and **what those changes were**.   - They want user-friendly and easy-to-understand log reports.   - We generate all reports using stored procedures. - We need to **log data-level changes**, not just save actions. - The solution must have **minimal performance impact**; we can't afford heavy overhead. - We prefer **not** to introduce new systems like NoSQL databases or complex logging frameworks due to resource constraints. - The solution should be **simple to implement and maintain** given our team's size and experience.  Any insights, experiences, or suggestions would be greatly appreciated!	Reddit	4	[]
104	Is there a clear understanding of the difference between Software Engineering and Software Development in our field?	BoxyLemon	2024-11-05T23:17:37Z	https://redd.it/1gkj0kf	I‚Äôm curious about the community's perspective on the distinction between software engineering and software development. Do most people in IT differentiate between these roles, or do they often view them as interchangeable? I‚Äôd love to hear from those with experience in both, and what you see as the core differences in responsibilities and skills.	Reddit	63	[]
105	Do you actually use DDD at work ?	FluidBreath4819	2024-11-01T14:18:25Z	https://redd.it/1gh56e6	I wonder if you go anemic or light DDD ? I use to go anemic with service class when i see i will look like a CRUD. But down the road, new requirements happen to be new business rule. And I am like : may be light DDD should be my go to architecture.  If you look at it, anemic is just aggregate root you stripped behaviour from.   Last job, some senior dev choose to go to anemic. We end up with DTOs for controllers, DTO for service, entities from repositories. Lot of transfer that made me think if they knew what they were doing.   I usually have one layer of DTOs that is shared by controllers and services. I don't usually go further than that.  But after some thinking, i wondering if light DDD should be favored instead of anemic models ?	Reddit	21	[]
106	Is separating sprint work from O&M good process? And is there a name for that process?	Syresiv	2024-10-29T10:55:16Z	https://redd.it/1geqtz9	"At a previous job in my career, our process separated sprint work from operations and maintenance (O&M).  Sprint work was new features, O&M was for bugs that weren't designated as critical (those were just ""all hands until it's done""). The process was that sprint work was always highest priority, O&M was for if you had time before the end of sprint or while things were being tested. We'd also deliberately underload some devs on sprint work so they'd have time to hit the O&M work.  O&M and sprint work also ultimately merged into different git branches, never to meet until the release sprint (the sprint dedicated to preparing for release).  I was pretty junior at the time and didn't fully comprehend why we did things this way. But it seems to fit with something my current manager wants.  Is this actually a good process, or are there showstopping flaws that young syresiv missed?  And is there a name for this specific process?"	Reddit	12	[]
107	Thoughts on DRY	Consistent-View-1956	2024-10-25T19:45:33Z	https://redd.it/1gc05y5	"I am frustrated with DRY being such a salient ""principle"" in Software Engineering literature. I have worked with several engineers (mostly mid to entry-level) that keep focusing on code duplication. They seem to believe that if they can reduce the amount of redundant code, then they can make the code base better. More often than not, I have seen this approach lead to poor abstractions that violate SRP and are not open for extension. I keep trying to tell my co-workers that some code duplication is okay. Especially if the classes are likely to diverge from one another throughout the lifetime of the code base. I can understand why people do this. It's much easier to get rid of duplicate code rather than write coherent abstractions that are testable and open for extension. I can understand duplication being valuable as a metric. I can understand treating reduced duplication as a side effect from focusing on what actually matters - writing code that can scale with the company, is testable, and that does not make your co-workers want to bash their head against a wall.      Am I crazy? What are your thoughts? Have you had similar struggles and if so, how have you addressed those?"	Reddit	62	[]
108	UML Use Case Diagrams: Can a specialized actor have no associations?	fallendionysus	2024-10-17T22:28:43Z	https://redd.it/1g60kwq	"Hello everyone! I hope you're doing well.  I was told that one of the rules of use case diagrams is that every actor should have at least one association with a use case, and no exceptions were mentioned.   What if the actor is a specialized actor (inherited from parent actor)? For example, actor A has two children, B and C. A is associated with some use cases, and so is B. Can C be there without being associated with any use cases?  I understand why it should be there - removing it will not reflect the requirements, and it IS associated with a use case through A. But I'm also under the impression that we can't have actors without any associations. Is this an exceptional case where we are allowed to ""break"" the rule?  Thank you and sorry if my question is stupid - I am trying to learn \^\^"	Reddit	8	[]
109	How exceptions would be represented in UML (use case scenarios, activity diagrams and sequence diagrams)? 	toughtbot	2024-10-17T13:58:09Z	https://redd.it/1g5p5n4	I heard this idea that even exception like DB connection failure, network exceptions should be represented in usecase scenarios. If so, how would they be translated in to activity diagrams or sequence diagrams.   This is in a academic setting and I know UML is not that heavily used in certain parts of the software industry. I'm asking for practical experience where this is applied irl. 	Reddit	4	[]
110	Misapplied Agile Frameworks: Anyone Else Stuck in a Death March?	mateosegundo	2024-10-11T11:34:52Z	https://redd.it/1g15w4x	I work at a mid-stage startup attempting a customized version of Ryan Singer‚Äôs ShapeUp framework.  I‚Äôve seen this before: delivery slows down, someone introduces a new agile framework hoping it‚Äôll fix everything, and they modify it so much it loses its original purpose.  Now, the team is stuck in a weird non-collaborative death-march cycle. Engineers are measured by the number of tickets they complete, which is ironic since ShapeUp specifically discourages breaking projects into endless tasks. Speed has overtaken quality, and morale is in the basement.   We‚Äôve got one manager with 30 direct reports, an introverted CTO, a VP of engineering in Europe, and most of the team in South America, which makes everything complicated. Yes, frameworks are important, but these issues are about lack of leadership and experience IMHO.  Anyone else dealing with a similar silver bullet framework that‚Äôs been misapplied?	Reddit	16	[]
111	How do you design and document a systems authorization (RBAC, ABAC) rules?	vampatori	2024-10-07T14:13:14Z	https://redd.it/1fy645e	I'm working on a project that has a bit more complex authorization than normal - I have roles, attribute-based roles, and some attribute rules with priority overrides.  So I want to properly spend the time designing and documenting it all.  I've had a look to see if there are any standard notations or diagrams used, but nothing is coming up - everything I've found has been tied to a specific authorization solution.  Before I start creating my own notation, I wondered what is usually done for this?	Reddit	7	[]
112	What‚Äôs wrong with the Server Side Public License?	DuckDatum	2024-10-07T13:43:22Z	https://redd.it/1fy5kl7	nutty lunchroom squeeze caption observation advise teeny doll wise like   *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*	Reddit	9	[]
113	Survey for Research Paper: The Impact of AI on the Software Development Job Market	Pitiful-Lie-1129	2024-10-03T20:52:51Z	https://redd.it/1fvf6j2	"Hi everyone,  I‚Äôm currently in my final year of an apprenticeship as an electronics technician, and I‚Äôm writing a research paper on **""The Impact of Artificial Intelligence on the Job Market for Software Developers.""**  To gather data for my research, I've created an anonymous survey. It takes about **5-10 minutes** to complete and covers topics like the influence of AI on your daily work, changes in required skills, and potential future developments in the software industry.  If you work in software development, I‚Äôd be very grateful if you could take the time to fill out the survey. Your input will be incredibly valuable for my work!  [https://forms.office.com/e/r8a1jSaaw0](https://forms.office.com/e/r8a1jSaaw0)  Thank you so much for your help"	Reddit	14	[]
114	Managing Complexity in a Cloud Migration - by Lee Atchison, software architect & cloud strategist	Inconnu	2024-10-02T17:09:58Z	https://redd.it/1fuihqi	Lift & shift worked for small, simple applications. The vast majority of big, complex, mission-critical software systems still run on-prem because migrating them requires making changes - small AND big - to reap the cloud benefits --> [Managing Complexity in a Cloud Migration | Software Architecture Insights](https://softwarearchitectureinsights.com/article/managing-complexity-in-a-cloud-migration)	Reddit	0	[]
115	When does it make sense to shift SQL query complexity to code?	weakassdick	2024-09-28T07:08:41Z	https://redd.it/1fr70ty	"My co-worker and I have been having a very minor disagreement over when it‚Äôs appropriate to abandon ship on continuing to build out a SQL query and instead write code to bridge the gap. He thinks that I‚Äôm prematurely optimizing by keeping it in SQL land for as long as possible. My intention really isn‚Äôt to optimize at all - I‚Äôm just using the right tool for the right job as this is exactly what SQL is good at.  So, without any context about the exact thing he and I were in disagreement on, when do you think is the right time to move complexity out of a query and into code?  edit:  Thanks for the great replies and discussion everyone! Some things that I should have probably made more clear in the original post:  We are using an ORM, so when I say ""move to code"", I mean to move out of the SQL space entirely and use code to massage data. A simple example is looping through the data to filter out values that don't match a certain criterion vs. another filter in the query  The query is already in place but it's evolving/becoming more complex as our constraints change. I'm at a very very small startup and we're building the plane as we're flying it. I can say, though, that it's less a matter of business logic and more a matter of db structure evolving which adds layers to the query  I'm doing my best to leave detailed comments in the ORM code to make crystal clear what's happening, though some should be self-explanatory if you know SQL  The query goes something like this (in English):  I need to fetch all messages that are part of an active campaign and have a ""scheduled"" status  We only want to select one scheduled message per message group (filtered via a DISTINCT ON clause)  Within each subgroup, we need to respect the preferred language of the user, which may not be available. If it isn't available, fallback to English. These are in the form of an ORDER BY clause that determine which entity is selected by the DISTINCT ON.  Hopefully this gives you all a rough idea of what we're grappling with here."	Reddit	67	[]
116	How to go about documenting requirements for an existing application?	Practical-Seesaw-891	2024-09-25T02:19:33Z	https://redd.it/1forjx5	"My team is doing a rewrite of our legacy app which requires feature parity (yes, I know it's a bad idea), so this question is a pertinent pain point to us.  But I'm sure it comes up in any legacy system.  Many years of features being added, but all those features are scattered across thousands of tickets, or undocumented if they predate our ticketing system, and there's no central source that actually knows the requirements.  What we've generally been doing is to start with what our business users and BAs know the system does already, and copy that behavior into the new system.  Then do some QA + user testing, and find out \~20% of the requirements were missed.  Implement those, another \~2% of requirements were still missed, and keep repeating.  This seems like a pretty terrible way to go about this, and it turns most features into many sprints of back-and-forth.  The main thing I can think of doing is just having developers do a ""code audit"" and read through all of the relevant code and compile documents/spreadsheets of all the various business rules.   Our code is formulaic enough that you could get a lot of these documents started with some careful regex searches.  But even still, there would be a lot of error-prone manual code-reading, and my napkin math says this process would take many man-months of developer time.  (The ""business rules"" part of our codebase is something like 10-20k lines of code, duplicated a thousand times with minor variations for each of our products.  Even restricting that down to code actively in use would be \~1 million LoC which seems an enormous headache for our team of \~10 devs.)  I'm sure testing will be mentioned.  We currently don't have any automated testing or test infrastructure on the legacy system, so it would be a big investment to start now.  Plus engineering leadership wants the rewrite to eventually replace the legacy system, so there won't be any leadership buy-in on testing.  Even if we got the system under test though, that doesn't seem to directly lead to any requirements documentation.  My thought on getting the system under test would be to go with coarse-grained approval tests, which don't capture specific requirements.  And if we wanted feature tests on old code, that would need to be a whole 'nother huge undertaking.  Let me know if anyone has insights on this.  I'm sure it's a common problem, but we really seem to be struggling here."	Reddit	20	[]
117	transactions for distributed architecture	Darth_Salad	2024-09-23T14:58:25Z	https://redd.it/1fnjswn	Recently I have been looking into implementing atomicity in transactions for distributed architecture (both the api server and db), can anyone share some good resources as to how to go about implementing rollbacks and atomicity for transactions if the db itself doesn't provide actual atomicity (Scylla DB in this case).      I came across the SAGA patterns for orchestration and choreography based saga but still need some more real world examples and samples to better know this stuff before I start implementing.  much appreciated	Reddit	3	[]
118	calibrating tasks estimations	maks_piechota	2024-09-23T12:32:46Z	https://redd.it/1fnh9l5	Lately, I‚Äôve been digging into better ways to measure software development performance. I‚Äôm talking about stuff like:  * Going beyond basic Scrum story points to actually measure how well teams are doing, and * Figuring out whether new tech in the stack is actually speeding up delivery times (instead of just sounding cool in meetings).  That‚Äôs when I came across Doug Hubbard‚Äôs AIE (Applied Information Economics) method, and it honestly changed the way I look at things.      One of the biggest takeaways is that you can *calibrate* people‚Äôs estimations. Turns out, about 95% of experts aren‚Äôt calibrated and are usually overconfident in their estimates.  As someone who has always doubted the accuracy of software development task estimates, this was a huge revelation for me. The fact that you can train yourself to get better at estimating, using a scientific method, kind of blew my mind.  Looking back on my 10-year dev career, I realized no one ever actually taught me *how* to make a good estimate, yet I was expected to provide them all the time.  I even ran a calibration test based on Hubbard‚Äôs method (shoutout to ChatGPT for helping out), and guess what? I wasn‚Äôt calibrated at all‚Äîjust as overconfident as the book predicted.  Now I‚Äôm starting formal calibration training, and I‚Äôm really curious to see how it‚Äôll affect my own work and the way my team estimates tasks.  What about you? Do you think you‚Äôre calibrated? Did you even know this was a thing?	Reddit	3	[]
119	Api Design	More-Ad-5258	2024-09-22T20:22:08Z	https://redd.it/1fmzulw	"In my web app, I have three main pages:  1. **All School Page** 2. **Single School Page** (where users can select classrooms) 3. **Classroom Page** (each classroom contains multiple devices of different types)  The **Device Table** has the following structure:      -id     -type  I already have an API to get all devices in a classroom:  * **Endpoint**: `/GET /classroom/{classroomId}/devices` * **Sample Response**:        [   { ""id"": 1, ""type"": ""projector"" },   { ""id"": 2, ""type"": ""smartboard"" } ]   Each device can be one of several types, and their telemetry data varies. For example:  * **Projector** devices have telemetry fields like:    * `brightness`    * `lampHours` * **Smartboard** devices have telemetry fields like:    * `touchSensitivity`    * `screenResolution`  The telemetry data is stored as JSON, and I have an external API that can fetch telemetry data for these devices based on time ranges. My goal is to design APIs that fetch telemetry efficiently.  # Possible Approaches:  # 1. Fetch the devices along with telemetry  * **Endpoint**: `/GET /classroom/{classroomId}/devices` * **Sample Response**:        [           {            ""id"": 1,            ""type"": ""projector"",            ""telemetry"": { ""brightness"": 100, ""lampHours"": 4 }         },           {            ""id"": 2,            ""type"": ""smartboard"",            ""telemetry"": { ""touchSensitivity"": 20, ""screenResolution"": 48 }         }      ]   * **Pros**:    * I need to apply an algorithm to fetch telemetry in a date range and process it, which could raise performance concerns.    * The devices may not display quickly on the frontend if telemetry calculations take too long. * **Cons**:    * Straightforward.    * Little extra processing required on the frontend.  # 2. Separate Telemetry API  * **Endpoint**: `/devices/{deviceId}/telemetry` * **Sample Response**:        { ""brightness"": 100, ""lampHours"": 4 }   In this approach:  1. The frontend first fetches all devices via `/GET /classroom/{classroomId}/devices`. 2. Then, subsequent requests are made for each device's telemetry using `/devices/{deviceId}/telemetry`.  * **Pros**:    * Devices can be displayed immediately on the frontend, without being delayed by telemetry fetching. * **Cons**:    * Multiple requests are sent to the server, which may cause overhead.  Do you guys have any suggestion?"	Reddit	7	[]
120	Seeking Advice on Simplifying Our Branching Strategy for a Medium-Sized Company.	sina_a_m	2024-09-18T22:32:36Z	https://redd.it/1fk2vba	Hello everyone,  I'm currently working at a company with three teams, all working on a monolithic application. I wanted to hear about your experiences with branching strategies and what has worked well for your tech teams.  So far, our branching strategy involved four permanent branches (which, in hindsight, seems like too many). We had a production branch, a pre-production branch for hotfixes, a develop branch for testing, and a pre-develop branch. The idea was to first merge feature branches into pre-develop, delete the original branch, and then merge everything from pre-develop all the way up to production.  However, this process became too slow for delivering new features. Another issue we encountered was when one team was ready to push to production, but another team still had code to write or bugs to fix. This created bottlenecks and forced us to wait for others.  We recently switched to a new branching strategy, but I still find it a bit complicated, and I'm wondering if there are simpler options we haven‚Äôt considered.  Our current setup has just two permanent branches: production and develop (for integration tests). The flow is:  - Pull from production and keep the feature branch. - Develop the code and push it. - Spin up a test server for that branch and test the feature there  - Merge the same branch into develop for integration testing. - If everything checks out, merge the branch into production.  I would love to hear about your experiences with branching. Are there other strategies that you‚Äôve found more efficient?  Looking forward to your insights!	Reddit	12	[]
121	Why do many prefer error as value over exceptions? Said another way, why do people like C style error handling?	MikeUsesNotion	2024-09-11T16:09:19Z	https://redd.it/1feb20n	When I started using a language where exceptions were the primary way intended to handle errors (C#), I thought they were great. No more if statements scattered around the code after every function call.  I understand these days the idea is to use an error object instead of a simple integer result code, but there's no reason you couldn't return a struct in C and do the same thing.  I don't understand why people don't like exceptions. I shudder when I think about going back to result validation after every function call. Why do people want to go back to cluttering up the code?  Also, how often are people doing fine grained error recovery? I mean actual recovery, not just using a default value if a request or some other operation failed. The vast majority of the time (I'd say 95%+), your line of processing is now dead and the error should just go up the chain to a higher handler.	Reddit	62	[]
122	Requirements Gathering	teknodram	2024-09-11T01:32:45Z	https://redd.it/1fdw6aj	I am a software engineer of 3-4 years experience, and I feel that I struggle with gathering and clarifying requirements when talking to clients, colleagues, or stakeholders. I find it difficult to ask the right questions and fully understand the project scope without explicit instructions. However, when someone provides clear directions, I have no issues implementing the solution.   Can anyone provide actionable advice on how I can improve my requirement-gathering skills, particularly in the context of client communication and user story creation? Additionally, are there any books, videos, or other resources you would recommend to help me enhance this aspect of my career?	Reddit	20	[]
123	Do you define SRS?	TheRakeshPurohit	2024-09-09T17:16:59Z	https://redd.it/1fcrx7c	so I have been thinking about people in the industry. those who are creating software requirement specifications, dataflow diagram, user flow diagrams, and module driven approach, functional, non functional requirement,  then defining user personas and what not.   do mncs and startups and other enterprise companies in the IT industry. follow this pattern before developing a software for a client or product?	Reddit	3	[]
124	Question about strategy pattern	Personal_Math_1618	2024-09-06T16:03:11Z	https://redd.it/1fafz6s	A few months ago, I learned about best practices in software engineering and various design patterns in university. Concepts like cohesion and coupling, the Single Responsibility Principle, etc., were emphasized repeatedly.  Currently, I‚Äôm practicing by creating class diagrams for hypothetical programs, and I‚Äôve come across a question I‚Äôm not sure how to answer.   Let‚Äôs say there‚Äôs a certain value that needs to be computed, and depending on the situation, there are different algorithms to calculate this value. In most cases, I only need two values: `int a` and `int b`. So, the method signature in the interface would look like this:   int calculateValue(int a, int b)   Based on the specific algorithm, these two values would be processed in some way. However, let‚Äôs say there‚Äôs one special case where the algorithm also needs a third parameter: `int c`.  Of course, I could modify the interface method signature to this:   int calculateValue(int a, int b, int c)   But in doing so, I‚Äôd be passing the parameter `c` to all classes implementing the interface, even when they don‚Äôt need it. This feels wrong because, in our course, we were taught that only the necessary parameters should be passed to a function or method‚Äînothing more, nothing less. So, is it justifiable to pass the third parameter to all classes that don‚Äôt actually need it?  Moreover, what if I extend the program later, and a new algorithm requires an additional field for its calculations? Changing the interface header again would violate the Open-Closed Principle.  Or is the issue more fundamental, and do I need to completely rethink my design approach?  Thank you in advance for your help!	Reddit	21	[]
125	Long variable names	mbrseb	2024-09-05T23:13:49Z	https://redd.it/1f9xoi6	TLDR: is sbom_with_vex_as_cyclone_dx_json too long?    I named a variable in our code sbom_with_vex_as_cyclone_dx_json.   Someone in the code review said that I should just call it sbom_json, which I find confusing since I do not know whether the file itself is in the  cyclone_dx or spdx format and whether it contains the vex information or not.   He said that a variable name should never be longer than 4 words.   In the book clean code in the appendix (page 405) I also found a variable being quite long: LEAP_YEAR_AGGREGATE_DAYS_TO_END_OF_PRECEDING_MONTH  I personally learned in university that this is acceptable since it is better to be descriptive and only in older languages like Fortran the length of a variable meaningfully affects the runtime speed.    The same thing with this variable of mine:  maximum_character_length_of_dependency_track_description_field=255   I could have used 255 directly but I wanted to save the information why I am using this number somewhere and I did not want to use a comment.   I can understand that it is painful to read but you do not have to read it if you use intellisense and copy paste. I want to force the reader to take his time here if he tries to read the variable name because it is complicated.   I just merged my code without changing it to his feedback.   What do you think about it? Am I the a√ó√óh√óle?   	Reddit	76	[]
126	Modern Architecture and management.	venquessa	2024-09-05T12:12:35Z	https://redd.it/1f9iuu0	"Do you guys/gals who are doing any form of micro-service architecture plan and report at the granularity of the service?  I have been in several projects recently where the work items (Jira) ultimately span half a dozen or more services.  For some reason this seems like it takes all the hardship of ""systems integration"" and places it onto individual developers.  To complete the ticket the developer might have open changes in 6 or 7 services.  In order to raise a ""Pull request"" they have to raise 6 or 7.  Rather than monitor one pipeline and merge incoming changes to one build/deploy branch they have to monitor 6 or 7.  When the work is accepted they have to fight and merge all 6 or 7 in the correct order, while there are another 2 teams all trying to do the same in ""master"".  It would seem more practical to try and split the work items on a ""per service"" basis.  While practically impossible to achieve completely, but still worth trying, the premise of ""Single service = single developer"" per ""SOW"".  What are your thoughts?  Is this not one of the mainstay advantages of micro-service architecture - that the service level is small enough for a single developer to work within.  Encapsulating, dividing and isolating complexity to make that so.  This then facilitates parallel development across services to achieve a ""SOW complete"".  I suppose the downsides are going to be in designing your micro-services and architecture to easily facilitate this.  Work items coming in from upstream will need to be broken down by seniors into a set of service tickets and those service tickets sequenced such that the feature branches can be advanced and sync up for releases."	Reddit	21	[]
127	How you share technical knowledge? 	Inconnu	2024-09-04T07:31:00Z	https://redd.it/1f8llwb	At my company we struggle to share technical knowledge between different projects, I personally believe there's a heavy element of the company culture involved but I'm curious how other companies incentivise that, and what tools can be helpful. internal Forums, communication tools such as Zoom, MS Teams, internal Stack overflow? what do you use in your company that you feel that works well? Thank you	Reddit	24	[]
128	Methodologies/frameworks for documenting	AlmightySp00n	2024-09-03T17:43:41Z	https://redd.it/1f8369i	So in my job i have to document all 8 current projects by the end of the year, they are all functional and there is information about them, but its mostly scattered and redundant like a bunch of digital post-it notes.  My team uses confluence so i have to use it as well, my question is, are there any methodologies/frameworks/design patterns i could follow to do it? I need to pitch a format for the docs soon so it can be approved and i can start working on them.   (I volunteered for this, so im not precisely having a bad time, this needed to be done eventually but i want to do it right, this is not a case of a abuse of power or nothing of the sort)	Reddit	4	[]
129	How do you design test?	AVerySoftArchitect	2024-08-31T16:27:31Z	https://redd.it/1f5ojff	A question for test engineer. How do design the test cases? Assuming you have a functional requirement like : the system shall send an email to the customer as purchase confirmation.  What your approach? Any material to study? Thanks 	Reddit	15	[]
130	 Are OWASP Code Review Guide and IEEE Checklists Enough for a Code Review Process?	Bulky_Connection8608	2024-08-30T18:27:04Z	https://redd.it/1f4zi62	I'm currently developing a code review process for a client and had a question about code review standards and checklists. If you've done code reviews in the past, I'd love to hear your thoughts. Specifically, do you think the following checklists are sufficient:  * OWASP Code Review Guide * IEEE Standard for Software Reviews and Audits  Or should the client consider creating their own custom code review checklist?  How does your team handle this? What checklist do you use?	Reddit	5	[]
131	Unit test question	framptal_tromwibbler	2024-08-28T23:53:48Z	https://redd.it/1f3llwm	"Hi my colleague and I are having a debate about something and I wanted to get other opinions.  Suppose I have a class Foo.  And in this class there is some hash like this (this is php but whatever):  `private const PRODUCT_CODE_TO_THUMBNAIL = [`  `'abc' => 'p1.jpg',`  `'def' => 'p2.jpg',`  `'ghi' => 'p3.jpg',`  `];`  Then elsewhere in the code this hash is used to, say, create a response that has a list of products in it with the appropriate thumbnail. E.g. some JSON like:  `{`  `""products"": [`   `""product"": ""abc"",`  `""thumbnail"": ""p1.jpg""`  `]`  `}`  Okay, now lets say we've got a Unit test class FooTest, and we want to have a test that makes sure that the thumbnail in a response is always the appropriate one for the product.  E.g. we'd want to make sure product 'abc' never ends up with a thumbnail other than 'p1.jpg'.  Question: is it better to:  1) make PRODUCT\_CODE\_TO\_THUMBNAIL accessible from the from FooTest, so both the code and the test are using the same source of truth or...  2) Give FooTest it's own copy of PRODUCT\_CODE\_TO\_THUMBNAIL and use that as the expected value.  My colleague does not like having two sources of truth like in option 2.  But I like option 2 for the following reason:  Let's say somebody changes a thumbnail value in PRODUCT\_CODE\_TO\_THUMBNAIL to an incorrect value.  If both are using the same source of truth, this would not get caught and the test failed to do its job.  So by giving FooTest its own copy, basically we are taking a snapshot of the 'source of truth' as it is today. If it ever changes (either on purpose or by accident) we will catch it. If it was by accident the test did its job. If on purpose, it just means we have to update the test.   I suppose it could matter how often that value might be expected to change.  If it happens often, then having to update the unit test might become a hassle.  But in my particular case, it would not be expected to change often, if ever even. "	Reddit	21	[]
132	Why do we focus on tickets but not requirements?	ivan-osipov	2024-08-25T18:43:46Z	https://redd.it/1f10qku	"Recently, I faced a reality that left me shocked. We started exploring what Allure Test Ops can do and how it could be integrated into our development process so that this tool moves from the category of ""Testers' Spellbook"" to the category of ""Just another tool alongside GitLab / Jira / etc., which everyone uses daily."" Btw, I really like this tool itself (not ad). I've watched many YouTube videos with ideas on how to rethink the separation between manual and automated testing to make something more natural, and allure contributes to this to the fullest. So, what surprised me?  Test cases related with tickets but not requirements! To explain my pain, let me ask first, what quality are we concerned about? From what I see in the market, one thing is obvious - ticket quality (!!!). All integrations are built on the idea that everything strives to be linked specifically to a Jira ticket, as if it were the source of knowledge about the product, **though it isn't**. When working on a product, what primarily concerns us is **the quality of meeting the product's requirements**. It‚Äôs the requirements that capture expectations, and **""success"" is precisely hitting your client's expectations**. So, what is the role of the ticket then?  In my view, features, bugs, and any other types of **issues** that one might encounter **are like the diff** between the old state of requirements and the new state of requirements (as in Git), or a discovered non-compliance with current requirements. It turns out that by changing or validating requirements, we create tickets, and moreover, by keeping requirements up-to-date, we can generate tickets semi-automatically as a consequence of changes/validations of expectations. Even though Requirements Management tools (such as Requirement Yogi) have long existed, I hardly see any integrations with them (except perhaps from Jira).  It seems that development is doomed to ""bad requirements"" simply because the process starts with a derivative component of them - tickets. We only fully realize the sum total of the requirements when we rewrite the product's specification, which, generally speaking, resembles reverse engineering of something you already had access to - absolute madness.  Why do we focus so much on tickets but not on requirements?"	Reddit	30	[]
133	Benchmarks for cost per line of code	SeriousDabbler	2024-08-26T03:23:30Z	https://redd.it/1f1c9va	Are there any resources out there for averages of cost  per line of code. I've heard some numbers but without any context. Would like to understand how we compare to the industry   Edit: Thanks to those who've posted already. For some context I'm not intending to use this information raw but was interested if it even existed. Yes I'm aware that SLOCs are not a good way of measuring developer or team performance, but I understand that this kind of thing used to be measured. I was hoping that there is some of this data recorded somewhere in studies or journals. Just looking for links or books thanks  Some context about me: I've been a software developer for 2 decades	Reddit	13	[]
134	Static Analysis on different platforms 	Mikeylikesit123	2024-08-24T06:40:15Z	https://redd.it/1ezx3r1	Does static analysis have to be done on the same platform that software compilation is targeting? I have software that is intended to compile on rhel9, but (for reasons) I am interested in scanning that software on a rhel7 machine, is that a valid static analysis scan? I can use the bdf or compile command json that compilation on rhel9 yields, I can also set the SA tool to use the same version of GCC that would be used in the rhel9 machine. My question is, do you lose validity in your SA scan if you aren‚Äôt doing it in the same environment that the software would be compiled in (but choosing the same compiler tool chain). Thanks for any insight!!	Reddit	5	[]
135	Do You All Really Think Scrum Is Useless? [Scrum Master Q]	HollisWhitten	2024-08-16T04:28:41Z	https://redd.it/1etdlzn	"In a Scrum Master role at a kinda known large-sized public firm, leading a group of about 15 devs.  I cannot for the life of me get anyone to care about any of the meetings we do.  Our backlog is full of tickets - so there is no shortage of work, but I still cannot for the life of me get anyone to ""buy in""  Daily Scrum, Sprint planning, and Retrospectives are silent, so I'm just constantly begging the team for input.  If I call on someone, they'll mumble something generic and not well thought out, which doesn't move the group forward in any way.  Since there's no feedback loop, we constantly encounter the same issues and seemingly have an ever-growing backlog, as most of our devs don't complete all their tickets by sprint end.  While I keep trying to get scrum to work over and over again, I'm wondering if I'm just fighting an impossible battle.  Do devs think scrum is worth it? Does it provide any value to you?  -- edit --  For those dming and asking, we do scrum like this (nothing fancy):  [How We Do Scrum ](https://thedigitalprojectmanager.com/projects/pm-methodology/scrum-ceremonies-made-simple/?utm=oam)"	Reddit	394	[]
136	What does proper software project management look like?	Tristana_mid	2024-08-16T09:32:24Z	https://redd.it/1etipep	A little bit of background: I'm a recent grad and just joined my company only to find out my team's approach to project management or development in general is absolutely broken - or at least this is what I think. I'll name a few:  1. Tickets/tasks are logged in a spreadsheet and people rarely update it. 2. Roadmap/timeline/prioritization is unclear. The manager is non-technical and only cares about pushing out cool features to kiss leadership's ass and couldn't care less about how broken the codebase is under the hood. The so-called tech lead, i.e. someone who's 1 year more experienced than me in the team, just 'vibe about' the tasks and basically prioritize/assign them arbitrarily. 3. Requirements are unclear. A super vague requirement would be given to me and I'm alone to figure out the rest. 4. No code review, no testing, no standard whatsoever. Terrible code gets merged into main which ends up breaking the system all the time and causing us to fire fight all the time. 5. Scrum / sprint concepts are non-existent. 6. Manual deployment with no notification. Someone would push something to Prod and the rest of the team would have no idea about it. 7. And many more.... These are just some of the things I feel are broken based on my shallow understanding of what a good workflow should be like.   Although I'm new to the team & the industry, I want to do something to improve the situation but don't know where to start. What PM/dev tools do you use? What does a proper team's PM/dev workflow looks like? What does a sprint look like? This will obviously be a long process, what should I start with, maybe Jira?  Any advice or resources will be appreciated! Again, I'm just starting out and I don't have a clear grasp of many of the concepts like scrum, project planning, etc., so perhaps I didn't articulate these problems clearly - please go easy on me!  	Reddit	15	[]
137	Specification for a system comprised of multiple components	R0dod3ndron	2024-08-16T13:55:00Z	https://redd.it/1etmshy	Suppose that I would like to create a software and hardware solution where the whole system comprises of the following components:  * device 1 * device 2 * device 3 * mobile application * web server  I am wondering what does the specification for the whole system should look like? Should I gather or the requirements in a single specification? Should I create a specification per component? What if e.g. device 1 integrates with device 2, device 2 with device 3, but the devices 1 and 3 have nothing common?  If one big specification, then there will be e.g. functional requirements applicable only for e.g. web server or device 1 and device 2. If separate documents then I will have to somehow point in one document to the other one.  What would you recommend based on your experience?	Reddit	4	[]
138	How Netflix Uses Throttling to Prevent 4 Big Streaming Problems	SnooMuffins9844	2024-08-15T16:06:08Z	https://redd.it/1esw2pq	It would be¬†**really difficult**¬†to find someone who has never heard of Netflix¬†before.  With around¬†**240 million paid subscribers,**¬†Netflix has to be the world's most¬†**popular streaming service**. And it‚Äôs well deserved.  Wherever you are in the world, no matter the time or device, you can press play on any piece of Netflix content and¬†**it will work**.  Does that mean the¬†**Netflix**¬†never has issues? Nope, things go wrong¬†**quite often**. But they guarantee you'll always be able to watch your favorite show.  Here's how they can do that.  # What Goes Wrong?  Just like with many other services, there are many things that could affect a¬†**Netflix user's streaming experience**.  1. **Network Blip:**¬†A user's network connection temporarily goes down or has another issue. 2. **Under Scaled Services:**¬†Cloud servers have not scaled up or do not have enough resources (CPU, RAM, Disk) to handle the traffic. 3. **Retry Storms:**¬†A backend service goes down, meaning client requests fail, so it retries and retries, causing requests to build up. 4. **Bad Deployments:**¬†Features or updates that introduce bugs.  This is not an exhaustive list, but remember that the main purpose of¬†**Netflix**¬†is to¬†**provide great content to its users**. If any of these issues prevent a user from doing that, then Netflix is not¬†**fulfilling its purpose**.  Considering most issues affect Netflix's¬†**backend services**. The solution must '*shield*' content playback from any potential problems.  https://preview.redd.it/ljnqv20w2uid1.png?width=3665&format=png&auto=webp&s=17201cdbf1f15ce2efeb5955fdd0171f0ed74745  ***Sidenote: API Gateway***  *Netflix has*¬†***many backend services,***¬†*as well as many clients that all communicate with them.*  *Imagine all the connection lines between them; it would look a lot like spaghetti.*  *An*¬†***API Gateway***¬†*is a server that sits between all those clients and the backend services. It's like a traffic controller routing requests to the right service. This results in cleaner, less confusing connections.*  It can also check that the client has the¬†authority¬†to make requests to certain services and¬†monitor requests, more about that later.  # The Shield  If Netflix had a problem and¬†**no users were online**, it could be resolved quickly without anyone noticing.  But if there's a problem, like not being able to favorite a show, and someone tries to use that feature, this would¬†**make the problem worse**. Their attempts would send more requests to the backend, putting¬†**more strain**¬†on its resources.  It¬†**wouldn't make sense**¬†to block this feature because Netflix doesn‚Äôt want to scare its users.  But what they could do is ‚Äò*throttle*‚Äô those requests using the¬†**API Gateway**.  https://preview.redd.it/urh0bft03uid1.png?width=3591&format=png&auto=webp&s=174d07d1248e7e50f9f93b2283d1f70b86d398ea  ***Sidenote: Throttling***  *If you show up at*¬†***a popular restaurant***¬†*without booking ahead, you may be asked to*¬†***come back later***¬†*when a table is available.*  *Restaurants can only provide a*¬†***certain number of seats at a time***\*, or they would get overcrowded. This is how throttling works.\*  *A service can usually handle only a*¬†***certain number of requests at a time***\*. A request threshold can be set, say\*¬†***5 requests per minute***\*.\*  *If 6 requests are made in a minute, the 6th request is either*¬†***held for a specified amount of time***¬†*before being processed (rate limiting) or rejected.*  # How It Worked  Because Netflix's API Gateway was¬†**configured to track**¬†CPU load, error rates, and a bunch of other things for all the backend services.  It knew¬†**how many errors**¬†each service had and¬†**how many requests**¬†were being sent to them.  So if a service was getting a¬†**lot of requests**¬†and had¬†**lots of errors**, this was a good indicator that any further requests would need to be throttled.  ***Sidenote: Collecting Request Metrics***  *Whenever a request is sent from a client to the API Gateway, it*¬†***starts collecting metrics***¬†*like response time, status code, request size, and response size.*  *This happens*¬†***before the request***¬†*is directed to the appropriate service.*  *When the service sends back a response, it goes through the gateway, which*¬†***finishes collecting metrics***¬†*before sending it to the client.*  https://preview.redd.it/z92293t24uid1.png?width=3591&format=png&auto=webp&s=b44b9495518d073c86ef137b1a0afc1c91420101  Of course, there are some services that if throttled, would have more of an¬†**impact on the ability to watch**¬†content than others. So the team¬†**prioritized**¬†requests based on:  1. **Functionality**: What will be affected if this request is throttled? If it's important to the user, then it's¬†**less likely**¬†to be throttled. 2. **Point of origin**: Is this request from a user interaction or something else, like a cron job? User interactions are¬†**less likely**¬†to be throttled. 3. **Fallback available**: If a request gets throttled, does it have a reasonable fallback? For example, if a trailer doesn‚Äôt play on hover, will the user see an image? If there's a good fallback, then it's¬†**more likely**¬†to be throttled. 4. **Throughput:**¬†If the backend service tends to receive a lot of requests, like logs, then these requests are¬†**more likely**¬†to be throttled.  Based on these criteria, each request was given a score between¬†**0 and 100**¬†before being routed. With¬†**0 being high priority**¬†(less likely to be throttled) and¬†**100 being low priority**¬†(more likely to be throttled).  The team implemented a¬†**threshold number,**¬†for example 40, and if a request's score was above that number, it would be throttled.  This threshold was determined by the¬†**health of all the backend services**¬†which again, was monitored by the API Gateway. The worse the health,¬†**the lower the threshold**¬†and vice versa.  There are no hard numbers in the¬†[original article](https://netflixtechblog.com/keeping-netflix-reliable-using-prioritized-load-shedding-6cc827b02f94)¬†on how much resource, or time this technique saved the company (which is a shame).  But the¬†**gif below**¬†is a recording of what a potential user would experience if the backend system was recovering from an issue.  https://i.redd.it/td13rba94uid1.gif  As you can see, they were able to¬†**play their favorite show without interruption,**¬†oblivious to what was going on¬†**in the background**.  # Let's Call It  I could go on, but I think this is a good¬†**place to stop**.  The team must have put a huge amount of effort into getting this across the line. I mean, the API gateway is written in Java, so bravo to them.  If you want¬†**more information**¬†about this there's plenty of it out there.  I recommend reading the¬†[original article](https://netflixtechblog.com/keeping-netflix-reliable-using-prioritized-load-shedding-6cc827b02f94), watching¬†[this video](https://www.youtube.com/watch?v=TmNiHbh-6Wg), and reading¬†[this article](https://blog.quastor.org/p/netflix-implements-load-shedding-1)¬†as well.  But if you don't have time to do all that and are enjoying these¬†**simplified summaries**, you¬†[know what to do](https://newsletter.betterstack.com/).	Reddit	1	[]
139	Books on Waterfall	WarpingZebra	2024-08-15T15:13:34Z	https://redd.it/1esuumx	Hey everyone,  I want to understand where software methodologies came from. How did they develop over time? What were the problems back then? How did programmers solve these challenges in the 1970s and before, etc.     Can anyone recommend great books about waterfall or even the time before waterfall? History books or how-to books would be amazing.     Thanks :>	Reddit	9	[]
140	Are there any special patterns or good practices that minimize the risks of manual SQL updates?	halt__n__catch__fire	2024-08-12T07:13:45Z	https://redd.it/1eq5fpm	"I know we have ORM and migrations to avoid the manual handling of databases and, perhaps, I am too old-fashioned and/or have been way too out of the loop the last couple of years as I left the software industry and embraced an academic career. However, an old nightmare still haunts me to this day: running an update without its where clause or realizing that a delete instruction removed an unexpectedly humongous amount of rows.  Keeping our hands off production databases is highly desirable, but, sometimes, we have to run one script or two to ""fix"" things. I've been there and I assume many of you did it too. I'll also assume that a few of you have gone through moments of pure terror after running a script on a massive table and realizing that you might have fucked something up.  I remember talking to a colleague once about the inevitability of running potentially hazardous SQL instructions or full scripts on databases while feeling helpless regarding what would come from it. We also shared some thoughts on what we could do to protect the databases (and ourselves) from such disastrous moments. We wanted to know if there were any database design practices and principles specially tailored to avoid or control the propagation of the bad effects of faulty SQL instructions.  It's been a while since that conversation, but here are a few things we came up with:  1. Never allowing tables to grow too big - once an important table, let's call it T, reaches a certain amount of rows, older records are rotated out of T and pushed into a series of ""catalog"" tables that have the same structure of T; 2. (Somehow) still allow the retrieval of data from T's ""catalog"" - selecting data from T would fetch records from T and from its ""catalog"" of older records; 3. Updating/Deleting T would NOT automatically propagate through all of its ""catalog"" - updating or deleting older records from T would be constrained by a timeframe that spans from T to an immediate past of its ""catalog"" tables; 4. Modifying the structure of T would NOT automatically propagate through all of its ""catalog"" - removing, adding, and modifying T's data fields would also be constrained by a timeframe that spans from T to an immediate past of its ""catalog"" tables.  And a few others I can't remember. It's been a while since that conversation. We didn't conduct any proof of concept to evaluate the applicability of our ""method"" and we were unsure about a few things: would handling the complexity of our ""approach"" be too much of an overhead? Would making the manual handling of databases safer be a good justification for the overhead, if any?  Do you know of any approach, method, set of good practices, or magic incantation, that goes about protecting databases from hazardous manual mishandling?"	Reddit	8	[]
141	"Did you guys know that Uncle Bob is planning on writing a 2nd Edition of ""Clean Code""?"	The_Axolot	2024-08-11T00:04:05Z	https://redd.it/1ep4n68	https://x.com/unclebobmartin/status/1820484490395005175  I'm kinda hyped, even though I'm not a huge fan of the advice or the refactorings.	Reddit	140	[]
142	How Instagram Saved 90% of Computing Power & Improved Video Quality	SnooMuffins9844	2024-08-08T15:32:29Z	https://redd.it/1en62rn	With¬†**2.5 billion active users**,¬†**Instagram**¬†is one of the most popular social media platforms in the world.  And¬†**video**¬†accounts for¬†**over 80%**¬†of its total traffic.  With those numbers, it's difficult to imagine how much¬†**computation time and resources**¬†it takes to upload, encode and publish videos from all those users.  But Instagram managed to¬†reduce that time by 94% and also¬†**improve their video quality**.  Here's how.  # The Process from Upload to Publish  Here are the typical steps that take place whenever a user uploads a video on Instagram:  1. **Pre-processing:**¬†Enhance the video‚Äôs quality like color, sharpness, frame rate, etc. 2. **Compression/Encoding:**¬†Reduce the file size 3. **Packaging:**¬†Splitting it into smaller chunks for streaming  For this article, we will focus on the¬†**encoding**¬†and¬†**packaging**¬†steps.  ***Sidenote: Video Encoding***  *If you were to record a 10-second 1080 video on your phone without any compression, it would be around*¬†***1.7 GB***.  *That‚Äôs a lot!*  *To make it smaller your phone uses something called a*¬†***codec***, that compresses the video for storage using¬†***efficient algorithms***.  *So efficient that it will get the file size down to*¬†***35MB***, but it's in a format that not designed to be read by humans.  *To watch the encoded video, a*¬†***codec***¬†*needs to decompress the file to pixels that can be displayed on your screen.*  *The compression process is called*¬†***encoding***\*, and the decompression process is called\*¬†***decoding***.  ***Codecs***¬†*have improved over time so there are*¬†[*many of them out there*](https://developer.mozilla.org/en-US/docs/Web/Media/Formats/Video_codecs#common_codecs)*. And they‚Äôre stored in most devices, cameras, phones, computers, etc.*  Instagram generated¬†**two types**¬†of encodings on upload:¬†**Advanced Encoding**¬†(AV1), and¬†**Simple**¬†**Encoding**¬†(H.264).  [Screenshot of video from the original article](https://preview.redd.it/7etfqjqhzfhd1.jpg?width=772&format=pjpg&auto=webp&s=70b1fadae1d662d54b5d1982670cde1dcfd67a1e)  **Advanced encoding**¬†produces videos that are small in size with¬†**great quality.**¬†These kind of videos only made up¬†**15% of Instagram‚Äôs total watch time**.  **Simple encoding**¬†produces videos work on¬†**older devices,**¬†but used a¬†**less efficient method of compression**, meaning the video are small with not great quality.  To make matters worse, simple encoding alone took up more than¬†**80% of Instagram's computing resources**.  # Why Simple Encoding Is Such a Resource Hog  For¬†**Simple encoding**, a video is actually encoded in¬†**two formats**:  * **Adaptive bit rate (ABR)**: video quality will change based on the user's¬†**connection speed.** * **Progressive**: video quality¬†**stays the same**¬†no matter the connection. This was for older versions of Instagram that¬†**don't support ABR.**  Both¬†**ABR**¬†and¬†**Progressive**¬†created multiple encodings of the same video in different¬†**resolutions and bit rates**.  But for¬†**progressive**, the video player will only play one encoded video.  While for¬†**ABR**¬†those videos are split into¬†**small 2-10 second chunks**, and the video player will change which chunk is played based on the user‚Äôs internet speed.  [It‚Äôs unknown how many videos were produced so 8 is a rough guess](https://preview.redd.it/lsuayeinzfhd1.png?width=5940&format=png&auto=webp&s=d683a04ee913c7a1c49fccf7a49b48e60823e948)  ***Sidenote: Bit rate***  *When a video is encoded, it stores binary data (1s and 0s) for each frame of the video, the more information each frame has, the higher its*¬†***bit rate***.  *If I recorded a video of a still pond the*¬†***compression algorithm***¬†*will notice that most pixels stay blue, and store them with*¬†***less data***¬†*to keep the pixels the same.*  *If I had a recording of a*¬†***fast-flowing waterfall***¬†*and the compression algorithm kept pixels the same, the video would look odd.*  *Since pixels change a lot between frames it needs to*¬†***store more information***¬†*in each frame.*  ***Bit rate***¬†*is measured in*¬†***megabits per second (mbps)***¬†*since this is how much data is sent to the video player.*  *On YouTube the average bitrate for a 1080 video is*¬†***8Mbps***¬†*which is*¬†***1Mb***¬†*of transmitted data every second.*  If you had to guess which specific process was taking up the most resources, you'd correctly guess¬†**adaptive bit rate**.  This is not only due to creating multiple video files, but also because the additional¬†**packaging step**¬†involves¬†**complex algorithms**¬†to figure out how to¬†**seamlessly switch between different video qualities**.  # The Clever Fix  Usually, progressive encoding creates just one video file. But because Instagram was¬†**creating multiple files**¬†with the same codec as ABR (H.264).  They realized they could use the¬†**same files for progressive and ABR**¬†eliminating the need to create two sets of the same videos.  https://preview.redd.it/o84508otzfhd1.png?width=4911&format=png&auto=webp&s=a3f6d4c6b3ffc89e7d24de1bb3b9ff1c38ea62fe  If you compare the image above to the previous image, you‚Äôll see that¬†**4 videos**¬†are now created during the encoding stage¬†**instead of 8**.  The team were able to use¬†**the same progressive files**¬†for the packaging stage of ABR which wasn‚Äôt as efficient as before resulting in¬†**poorer compression**.  But they did save¬†**a lot of resources**.  Instagram claims the old ABR process took¬†**86 seconds**¬†for a¬†**23-second video**.  But the¬†**new**¬†ABR process, just packaging, took¬†**0.36 seconds**, which is a whopping¬†**99% reduction**¬†in processing time.  With this much reduction Instagram could dedicate more resources to the¬†**advanced encoding process**, which meant more users could see¬†**higher quality videos**. How?  Because simple encoding¬†**took longer**¬†in the old process and used¬†**more resources**, there wasn‚Äôt enough to always create advanced videos.  With the new process, there was enough resource to run¬†**both types of encoding**, meaning both can be published and more users would see¬†**higher quality videos**.  This resulted in an increase in views of advanced encoded video¬†**from 15% to 48%**.  [Image from original article](https://preview.redd.it/zo9kjcqwzfhd1.jpg?width=1157&format=pjpg&auto=webp&s=746017c9f57784ae541540cea7ef9e790c7ffcaa)  ***Sidenote: Encoding vs Transcoding***  *This is an optional side note for the video experts among you.*  *The word*¬†***transcoding***¬†*isn't used in this article, but technically it should have been.*  ***Encoding***¬†*is the process of compressing an uncompressed video into a smaller format.*  ***Transcoding***¬†*is the process of changing a video from one encoded format to the same, or another format.*  *Because all devices (phones, cameras) have a*¬†***codec***\*, when a video is recorded it is automatically encoded.\*  *So even before you upload a video to*¬†***Instagram***¬†*it is already encoded, and any further encoding is called*¬†***transcoding***.  *But because the*¬†[*original article*](https://engineering.fb.com/2022/11/04/video-engineering/instagram-video-processing-encoding-reduction/)¬†*mostly uses the term*¬†***encoding***¬†*and it‚Äôs is such a catch-all term used in the industry, I decided to stick with it.*  # Wrapping Things Up  After reading this you may be thinking,¬†**how did the team not spot this obvious improvement?**  Well, small issues on a small scale are often¬†**overlooked**. Small issues on a large scale¬†**no longer remain small issues**, and I guess that's what happened here.  Besides, Instagram was always a¬†**photo app**¬†that is now focusing more on video, so I assume it's a learning process for them too.  If you want to read¬†**more about their learnings,**¬†check out the¬†[Meta Engineering Blog](https://engineering.fb.com/tag/instagram/).  But if you enjoyed this¬†**simplified version**, be sure to¬†[subscribe](https://newsletter.betterstack.com/).	Reddit	7	[]
143	ISO a tool for communicating software design intent and/or architecture. I...think?	fotostach	2024-08-07T23:49:28Z	https://redd.it/1emog4t	"Hi all,   I'm new here (long time lurker, never poster) and I have a problem that I could use some coaching through.  First, a little background: I'm a self-taught software developer and business owner. I recently sold my company that (along with a hardware product) has a decently large web application that I have written completely by myself. I need to turn these codebases over to the buyers teams, but I'm struggling to find the most efficient way of doing so. Essentially, I'm not sure how to communicate at a high level what subsystems there are, what they do, how they interact, etc. I'd like to give them a ""blueprint"" that documents what the system architecture is and how it *should* work so they can better understand and contribute to it.   With that, I've been looking for a tool that I can use to create a ""document of record"" of sorts. Basically,  a flowchart? a network diagram? a word doc? a...something?? that can serve as a living document for system design and help us define our stack, components, and interfaces. Or that's what I think I need anyhow.   I'm also wondering is how the pros handle this problem. As a self-taught solo dev, I've always worked by myself and in doing so I've probably committed every software engineering sin in the book (including not always documenting my work!). How do more experienced teams communicating system design? When new developers on board your teams, how do you familiarize them? I suppose I'm more interested in how small/medium teams operate, as I know larger organizations have PMs, etc., to help with this problem.  Lemme know your thoughts. TIA!   "	Reddit	8	[]
144	Is this a use case diagram, DFD, or system arch diagram?	Striking-Warning9533	2024-08-08T02:27:18Z	https://redd.it/1ems2bm	https://preview.redd.it/pl6jub614chd1.png?width=809&format=png&auto=webp&s=44d16761be183bc8284abab34043d2f8977efef3  	Reddit	2	[]
145	Better ways to store assembleable data	shepshep7	2024-07-31T17:11:27Z	https://redd.it/1egpmk6	0  I have a large database of components that are grouped by series.  examples are the AB series, the R2H series... Within each series, some components can be altered to become other components. This is governed by the part number.  example: There are part numbers in the AB series AB12.01-4HU AB22.01-4HU AB08.01-4HU AB12.01-2HF AB22.01-6TR AB08.01-4HL  for a given part, as long as this prefix is the same AB\_\_.\_\_, the letters on the end can transform. U can become F, R and L, but not the other way around. R can become L and L can become R I have this mapped in an array indexed on the position of the part number after the prefix:          'AB__.__-' = [             0 = [             2 = [2, 4],             4 = [4],             6 = [6]           ],           1 = [           'H' = ['H']           ],           2 = [             'U' = ['U', 'F', 'R', 'L'],             'F' = ['F'],             'R' = ['R', 'L'],             'L' = ['L', 'R']           ]         ]       The assembler I built takes components we have, grouped by prefix, and then iterates through each letter position and adds possible components to a buildable table.  Every day I run this assembler on the components present in the database, to build a list of the components currently buildable. This is computationally expensive and I wonder if there is a better way of doing things. Also, there are some configurations which do not neatly fit into this system and would benefit from being able to manually add some configurations. Additionally, there are some components which require the presence of TWO or MORE base components, and this current setup doesn't allow for that. I have code written that does this but it's even worse.  I know that I could run all of these calculations just one time and store the possible combinations so that given a component I could retrieve all components buildable by that component, but I am unsure of the best table structure. any insight or advice would be helpful.  A table structure I am thinking of could be: components table: id, part\_number, series  buildable\_components = base\_component\_id, buildable\_component\_id, build\_type {'manual' || 'autobuilt'}  and then if I make changes to the configuration I could run the builder one time to rebuild the database and leave the manual entries alone.  This doesn't solve the multiple base models needed issue though     Thank You	Reddit	4	[]
146	How to not satisfy both design principles	quanta0806	2024-07-30T17:24:31Z	https://redd.it/1efw6m5	Hello everyone, I'm reading the first chapter of the book head first design pattern about Strategy Pattern. In this chapter, through out the Duck program, two design principles are mentioned: **Program to an interface, not an implementation (1)** and **Favor composition over inheritance (2)**. I challenged myself by finding modification to the class diagram so that (1) statisfies but (2) doesn't and vice versa but it was really hard. If there aren't any modifications, so could I imply that these two design principles are mutually dependent ?  https://preview.redd.it/ywt984egcofd1.png?width=1278&format=png&auto=webp&s=54a16f83bebf35fbbc81165b75d6346d361312c9  	Reddit	5	[]
147	Identify provider architecture ideas	dealdow	2024-07-30T02:23:49Z	https://redd.it/1effk38	Hello, everyone. Working on a project focused on corporate governance. It has many directions/applications (compliance, telecommunications, etc) but the core is similar - you create an organisation account and add your employees. These apps are alreay built (React frontend apps of a single monorepo and separate backends) with their own custom separate auth systems based on JWT. Now we need to develop a single unidentified way to log in once and be able to use any of the apps (similarly to Atlassian). I am considering building an IdP backend service with own database storing businesses and their users, will be responsible to generate JWT token with a private key. Then, the app backends can verify these JWTs via a public key. What do you think about this kind of topology? Are there any better ways to implement it, possibly using some common standards like OpenID?	Reddit	9	[]
148	While working with databases. How do you document database?	Vodkius	2024-07-29T13:47:29Z	https://redd.it/1eexglg	Hello all software lovers,     Currently we have an old system. We were requested the get ER model of database and comment all tables and attributes. Since I'm a lazy person as everyone else I started to look for a tool which could make my life easier to do such task. Since now I'm thinking to stay with SchemaSpy since it has what I need, analyses whole database, provides relationship and ER diagram you can see comments on attributes and tables.     I was thinking what do you guys use for database documentation? Is SchemaSpy would be enough or are there any other tools which could ease this process?	Reddit	12	[]
149	Looking to introduce an IDP at work	Deeelaaan	2024-07-20T09:07:33Z	https://redd.it/1e7prmy	Just started a new job recently where they use ReTool to build internal applications for workflows, operations, etc. Not sure if anyone is familiar with ReTool but it's not really developer friendly. Non-technical employees such as operations and analytics folks are also able to build apps in ReTool which results in some engineering resources dedicated to fixing bugs in said applications. The general consensus at work is that everyone pretty much hates it. Super fun.  At my last job we had this service that basically acted as an IDP which I'm looking to propose eventually at new my new job. We were able to build react applications that were deployed within this service which basically enabled us to have a catalog of applications that we would use on a daily basis to handle a number of operations; both technical and non-technical.  Now for the actual question: any suggestions on which route to go for proposing an IDP? I've heard of both internal developer platforms and internal developer portals. What's the difference?? Ideally I'm looking to propose spending some resources on building some internal platforms that would allow us to build tools with code rather than drag and drop components/functionality. I've lightly looked into Port and Humanitec but unsure of the pros/cons of using either. Just looking for some general input on this.	Reddit	3	[]
150	What happened to RISD?	richb201	2024-07-19T15:09:07Z	https://redd.it/1e73civ	would the software world be alot less complex if RISD had been the mindset?	Reddit	8	[]
151	Environments best practice	Environmental_Age_34	2024-07-18T03:42:05Z	https://redd.it/1e5zkdg	In my work, we had a dev, preprod and production environment and QA team test on preprod environment. we had also 3 data sources for each environments. now we add a new environment ( Test ) Should we build a new data source for test environment or connect the test environment on preprod data source? what is the best practice in general for environments?	Reddit	5	[]
152	Microservices / modules - do you check references validity?	trustmePL	2024-07-16T16:29:04Z	https://redd.it/1e4q2rw	Consider examples like this: - user places an order with some items IDs. In the ordering context, we do not know if the ids are really connected to ‚Äûour‚Äù products. Do you call the catalog (or whatever owns products) to check the products in order? - user creates an ‚Äûevent‚Äù (like a concert or conference etc) which takes place at PLACE and is organised by some organisation(s). Both places and organisations are owned by other contexts. Do you check if all references are correct?  Share your approaches and experience with them. 	Reddit	5	[]
153	50 Years of Software Engineering: Insights from Tony Wasserman - ACM TechTalk	Upstairs_Ad5515	2024-07-14T21:01:48Z	https://redd.it/1e3a4fj	[https://www.youtube.com/watch?v=9ZjSuAmNVwk&ab\_channel=SanFranciscoBayACM](https://www.youtube.com/watch?v=9ZjSuAmNVwk&ab_channel=SanFranciscoBayACM)	Reddit	5	[]
154	"Shouldn't an ""N+1"" problem really be called ""1+N"""	OppositeFar3205	2024-07-14T19:41:07Z	https://redd.it/1e387d6	OK hear me out.  We're all familiar with the N+1 problem. If you are requesting a list of books and you fetch the author for every book your fetching you get an expensive request of the list of books (the **1** request) and then the author for every book (the **N** request)...   Logically would make sense to then call it **1 + N** - one request for the books, then n for every book author. I understand algebraically you refactor so that the variable comes first. But this ain't math class. This is a concept we want all engineers to understand thoroughly, so why not be explicit and clear? 	Reddit	24	[]
155	Designing a support ticketing system	Party-Welder-3810	2024-07-09T15:12:40Z	https://redd.it/1dz22mv	"**Intro**  I'm about to start a project and I'd appreciate some input from the good people of Reddit. I'm not doing this by myself but I'm the most experience developer on the team which is why I'm request support here.  The project is a sub project of another project so some of the technologies are predefined. The parent project consist of a restful backend and web based frontend.  The backend is implemented in Go and depends on the following services: Postgresql, Redis and RabbitMQ.  The frontend is a standard web client implemented in React.  I'm not limited to the above technologies but, as an example, I'd rather not introduce Kafka since we're already using RabbitMQ.  **Domain**  The task is to implement a customer support ticket system where multiple agents will handle incoming tickets associated with different topics.  If possible, once an agent has responded to a ticket, the following messages from the customer should be handled by the same agent.  But the above might not always be possible for two reasons  1. The agent might have too long a queue of pending messages and therefor be too busy to handle more messages 2. The agent might be unavailable for various reasons such as their shift ending, their internet connection failing or even leaving the company.  **Algorithm**  I've tried to come up with an algorithm for implementing the above  \* The client sends a message - Simply sending a post request to the backend  \* The message is enqueued on a (global) message queue  \* Sort agents by queue length - shortest to longest  \* Eliminate agents who have a queue length greater than... x?  \* Prioritize agents who have most recently interacted with the sender of the message  \* Assign message to the agents (local) queue  **Issues**  \* If a new agent enters the pool of agents with zero queue length but no previous interaction with clients. How to ""allow"" this agent to start working?  \* If an agent have interacted with more clients than other agents. With the above algorithm the more ""experienced"" agent will be unfairly prioritized. How to equalize the agent queues?  \* If an agent logs off, the messages in its local queue needs to be assigned to other agents. Once the messages have been reassigned, the local queue should be sorted so the newly assigned messages doesn't get a lower priority compared to other pending message.  \* How to come up with a good number for x in the algorithm? When is a queue too long? What if all agents have long queues? Ideally this number should be calculated dynamically at runtime."	Reddit	10	[]
156	Is the separation of back-end from front-end an old approach?	_seeking_answers	2024-07-08T09:03:20Z	https://redd.it/1dy2i69	Hi everyone, I‚Äôm studying software engineering at university (close to the end of it). My university professor and I were talking about how the company, I work for, manages some aspects of their main software (they sell a SaaS solution). At some point he told me that ‚Äúfront-end and back-end are something old. You should tell it to your company‚Äù but he didn‚Äôt tell me what the ‚Äúnew‚Äù is. To be honest I don‚Äôt have the clueless idea of what he‚Äôs talking about‚Ä¶  Regarding development, our front-end is separated from back-end but developers are full-stack developers with traversal competencies. I‚Äôve even told him we embrace agile methodology and scrum framework, so I don‚Äôt really know what he was talking about.  Do you have any idea, could you help me understanding what his point was? 	Reddit	31	[]
157	Usual build and run ratio	bioinfornatics	2024-07-02T20:07:20Z	https://redd.it/1dtsh4y	Dear community,  I am looking for references regarding the typical ratio of build vs. run costs in the context of a global IT budget.  I've found various optimization strategies and methodologies online, but I would like to understand what is practically achievable. Specifically, I am interested in factual data or studies that detail how organizations typically balance their spending between development (build) and maintenance/operations (run).  Thanks in advance for your help!	Reddit	3	[]
158	Tools used for Requirement Engineering	Left_Newspaper8520	2024-07-01T17:23:44Z	https://redd.it/1dsvp29	Hi Redditors! Are you using a tool to deal with requirements within your distributed software development? We're conducting a survey as part of our thesis.  **About Us:**  We are master‚Äôs students in Software Engineering at Blekinge Institute of Technology, Karlskrona, Sweden, currently working on our thesis.  **Why Your Input Matters:**  Whether you're an experienced developer or just starting out, your input can make a real difference. Take a few moments to share your experiences and help improve Requirement Management Tools for teams like yours.  **Join the Conversation:**  Click the link below to start the survey and be a part of the conversation:  [https://docs.google.com/forms/d/e/1FAIpQLSepiIIY9z-fq\_HiAi40OGumnupe7vstyMxJM6VtiNbnQZQKjw/viewform?usp=sf\_link](https://docs.google.com/forms/d/e/1FAIpQLSepiIIY9z-fq_HiAi40OGumnupe7vstyMxJM6VtiNbnQZQKjw/viewform?usp=sf_link)  Let's work together to enhance communication and collaboration in distributed software development teams!	Reddit	2	[]
159	Morescient GAI for Software Engineering (Extended Version)	Marcus Kessel	2024-06-07T07:38:33Z	http://arxiv.org/abs/2406.04710v2	"The ability of Generative AI (GAI) technology to automatically check, synthesize and modify software engineering artifacts promises to revolutionize all aspects of software engineering. Using GAI for software engineering tasks is consequently one of the most rapidly expanding fields of software engineering research, with over a hundred LLM-based code models having been published since 2021. However, the overwhelming majority of existing code models share a major weakness - they are exclusively trained on the syntactic facet of software, significantly lowering their trustworthiness in tasks dependent on software semantics. To address this problem, a new class of ""Morescient"" GAI is needed that is ""aware"" of (i.e., trained on) both the semantic and static facets of software. This, in turn, will require a new generation of software observation platforms capable of generating large quantities of execution observations in a structured and readily analyzable way. In this paper, we present a vision and roadmap for how such ""Morescient"" GAI models can be engineered, evolved and disseminated according to the principles of open science."	Arxiv	0	['Colin Atkinson']
160	Cognitive Biases in Software Engineering: A Systematic Mapping Study	Rahul Mohanani	2017-07-12T19:05:19Z	http://arxiv.org/abs/1707.03869v3	One source of software project challenges and failures is the systematic errors introduced by human cognitive biases. Although extensively explored in cognitive psychology, investigations concerning cognitive biases have only recently gained popularity in software engineering (SE) research. This paper therefore systematically maps, aggregates and synthesizes the literature on cognitive biases in software engineering to generate a comprehensive body of knowledge, understand state of the art research and provide guidelines for future research and practise. Focusing on bias antecedents, effects and mitigation techniques, we identified 65 articles, which investigate 37 cognitive biases, published between 1990 and 2016. Despite strong and increasing interest, the results reveal a scarcity of research on mitigation techniques and poor theoretical foundations in understanding and interpreting cognitive biases. Although bias-related research has generated many new insights in the software engineering community, specific bias mitigation techniques are still needed for software professionals to overcome the deleterious effects of cognitive biases on their work.	Arxiv	0	['Iflaah Salman', 'Burak Turhan', 'Pilar Rodriguez', 'Paul Ralph']
161	Software Engineering in Civic Tech: A Case Study about Code for Ireland	Antti Knutas	2019-04-08T14:53:37Z	http://arxiv.org/abs/1904.04104v1	Civic grassroots have proven their ability to create useful and scalable software that addresses pressing social needs. Although software engineering plays a fundamental role in the process of creating civic technology, academic literature that analyses the software development processes of civic tech grassroots is scarce. This paper aims to advance the understanding of how civic grassroots tackle the different activities in their software development processes. In this study, we followed the formation of two projects in a civic tech group (Code for Ireland) seeking to understand how their development processes evolved over time, and how the group carried out their work in creating new technology. Our preliminary findings show that such groups are capable of setting up systematic software engineering processes that address software specification, development, validation, and evolution. While they were able to deliver software according to self-specified quality standards, the group has challenges in requirements specification, stakeholder engagement, and reorienting from development to product delivery. Software engineering methods and tools can effectively support the future of civic technologies and potentially improve their management, quality, and durability.	Arxiv	0	['Victoria Palacin', 'Giovanni Maccani', 'Markus Helfert']
162	Text and Team: What Article Metadata Characteristics Drive Citations in Software Engineering?	Lorenz Graf-Vlachy	2022-04-12T18:39:11Z	http://arxiv.org/abs/2204.06033v1	Context: Citations are a key measure of scientific performance in most fields, including software engineering. However, there is limited research that studies which characteristics of articles' metadata (title, abstract, keywords, and author list) are driving citations in this field. Objective: In this study, we propose a simple theoretical model for how citations come to be with respect to article metadata, we hypothesize theoretical linkages between metadata characteristics and citations of articles, and we empirically test these hypotheses. Method: We use multiple regression analyses to examine a data set comprising the titles, abstracts, keywords, and authors of 16,131 software engineering articles published between 1990 and 2020 in 20 highly influential software engineering venues. Results: We find that number of authors, number of keywords, number of question marks and dividers in the title, number of acronyms, abstract length, abstract propositional idea density, and corresponding authors in the core Anglosphere are significantly related to citations. Conclusion: Various characteristics of articles' metadata are linked to the frequency with which the corresponding articles are cited. These results partially confirm and partially go counter to prior findings in software engineering and other disciplines.	Arxiv	0	['Daniel Graziotin', 'Stefan Wagner']
163	Nmag micromagnetic simulation tool - software engineering lessons learned	Hans Fangohr	2016-01-27T14:46:56Z	http://arxiv.org/abs/1601.07392v2	We review design and development decisions and their impact for the open source code Nmag from a software engineering in computational science point of view. We summarise lessons learned and recommendations for future computational science projects. Key lessons include that encapsulating the simulation functionality in a library of a general purpose language, here Python, provides great flexibility in using the software. The choice of Python for the top-level user interface was very well received by users from the science and engineering community. The from-source installation in which required external libraries and dependencies are compiled from a tarball was remarkably robust. In places, the code is a lot more ambitious than necessary, which introduces unnecessary complexity and reduces main- tainability. Tests distributed with the package are useful, although more unit tests and continuous integration would have been desirable. The detailed documentation, together with a tutorial for the usage of the system, was perceived as one of its main strengths by the community.	Arxiv	0	['Maximilian Albert', 'Matteo Franchin']
164	Software Engineering for Collective Cyber-Physical Ecosystems	Roberto Casadei	2024-06-07T09:28:22Z	http://arxiv.org/abs/2406.04780v1	"Today's distributed and pervasive computing addresses large-scale cyber-physical ecosystems, characterised by dense and large networks of devices capable of computation, communication and interaction with the environment and people. While most research focusses on treating these systems as ""composites"" (i.e., heterogeneous functional complexes), recent developments in fields such as self-organising systems and swarm robotics have opened up a complementary perspective: treating systems as ""collectives"" (i.e., uniform, collaborative, and self-organising groups of entities). This article explores the motivations, state of the art, and implications of this ""collective computing paradigm"" in software engineering, discusses its peculiar challenges, and outlines a path for future research, touching on aspects such as macroprogramming, collective intelligence, self-adaptive middleware, learning, synthesis, and experimentation of collective behaviour."	Arxiv	0	['Gianluca Aguzzi', 'Giorgio Audrito', 'Ferruccio Damiani', 'Danilo Pianini', 'Giordano Scarso', 'Gianluca Torta', 'Mirko Viroli']
165	An Exploratory Study of V-Model in Building ML-Enabled Software: A Systems Engineering Perspective	Jie JW Wu	2023-08-10T06:53:32Z	http://arxiv.org/abs/2308.05381v4	Machine learning (ML) components are being added to more and more critical and impactful software systems, but the software development process of real-world production systems from prototyped ML models remains challenging with additional complexity and interdisciplinary collaboration challenges. This poses difficulties in using traditional software lifecycle models such as waterfall, spiral, or agile models when building ML-enabled systems. In this research, we apply a Systems Engineering lens to investigate the use of V-Model in addressing the interdisciplinary collaboration challenges when building ML-enabled systems. By interviewing practitioners from software companies, we established a set of 8 propositions for using V-Model to manage interdisciplinary collaborations when building products with ML components. Based on the propositions, we found that despite requiring additional efforts, the characteristics of V-Model align effectively with several collaboration challenges encountered by practitioners when building ML-enabled systems. We recommend future research to investigate new process models, frameworks and tools that leverage the characteristics of V-Model such as the system decomposition, clear system boundary, and consistency of Validation & Verification (V&V) for building ML-enabled systems.	Arxiv	0	[]
166	What Does a Software Engineer Look Like? Exploring Societal Stereotypes in LLMs	Muneera Bano	2025-01-07T06:44:41Z	http://arxiv.org/abs/2501.03569v1	Large language models (LLMs) have rapidly gained popularity and are being embedded into professional applications due to their capabilities in generating human-like content. However, unquestioned reliance on their outputs and recommendations can be problematic as LLMs can reinforce societal biases and stereotypes. This study investigates how LLMs, specifically OpenAI's GPT-4 and Microsoft Copilot, can reinforce gender and racial stereotypes within the software engineering (SE) profession through both textual and graphical outputs. We used each LLM to generate 300 profiles, consisting of 100 gender-based and 50 gender-neutral profiles, for a recruitment scenario in SE roles. Recommendations were generated for each profile and evaluated against the job requirements for four distinct SE positions. Each LLM was asked to select the top 5 candidates and subsequently the best candidate for each role. Each LLM was also asked to generate images for the top 5 candidates, providing a dataset for analysing potential biases in both text-based selections and visual representations. Our analysis reveals that both models preferred male and Caucasian profiles, particularly for senior roles, and favoured images featuring traits such as lighter skin tones, slimmer body types, and younger appearances. These findings highlight underlying societal biases influence the outputs of LLMs, contributing to narrow, exclusionary stereotypes that can further limit diversity and perpetuate inequities in the SE field. As LLMs are increasingly adopted within SE research and professional practices, awareness of these biases is crucial to prevent the reinforcement of discriminatory norms and to ensure that AI tools are leveraged to promote an inclusive and equitable engineering culture rather than hinder it.	Arxiv	0	['Hashini Gunatilake', 'Rashina Hoda']
167	A Mosaic of Perspectives: Understanding Ownership in Software Engineering	Tomi Suomi	2025-05-20T11:27:33Z	http://arxiv.org/abs/2505.14220v2	Agile software development relies on self-organized teams, underlining the importance of individual responsibility. How developers take responsibility and build ownership are influenced by external factors such as architecture and development methods. This paper examines the existing literature on ownership in software engineering and in psychology, and argues that a more comprehensive view of ownership in software engineering has a great potential in improving software team's work. Initial positions on the issue are offered for discussion and to lay foundations for further research.	Arxiv	0	['Petri Ihantola', 'Tommi Mikkonen', 'Niko M√§kitalo']
168	Developers Perception of Peer Code Review in Research Software Development	Nasir U. Eisty	2021-09-22T18:40:05Z	http://arxiv.org/abs/2109.10971v1	Background: Research software is software developed by and/or used by researchers, across a wide variety of domains, to perform their research. Because of the complexity of research software, developers cannot conduct exhaustive testing. As a result, researchers have lower confidence in the correctness of the output of the software. Peer code review, a standard software engineering practice, has helped address this problem in other types of software. Aims: Peer code review is less prevalent in research software than it is in other types of software. In addition, the literature does not contain any studies about the use of peer code review in research software. Therefore, through analyzing developers perceptions, the goal of this work is to understand the current practice of peer code review in the development of research software, identify challenges and barriers associated with peer code review in research software, and present approaches to improve the peer code review in research software. Method: We conducted interviews and a community survey of research software developers to collect information about their current peer code review practices, difficulties they face, and how they address those difficulties. Results: We received 84 unique responses from the interviews and surveys. The results show that while research software teams review a large amount of their code, they lack formal process, proper organization, and adequate people to perform the reviews. Conclusions: Use of peer code review is promising for improving the quality of research software and thereby improving the trustworthiness of the underlying research results. In addition, by using peer code review, research software developers produce more readable and understandable code, which will be easier to maintain.	Arxiv	0	['Jeffrey C. Carver']
169	Insights from the Frontline: GenAI Utilization Among Software Engineering Students	Rudrajit Choudhuri	2024-12-20T07:30:51Z	http://arxiv.org/abs/2412.15624v1	Generative AI (genAI) tools (e.g., ChatGPT, Copilot) have become ubiquitous in software engineering (SE). As SE educators, it behooves us to understand the consequences of genAI usage among SE students and to create a holistic view of where these tools can be successfully used. Through 16 reflective interviews with SE students, we explored their academic experiences of using genAI tools to complement SE learning and implementations. We uncover the contexts where these tools are helpful and where they pose challenges, along with examining why these challenges arise and how they impact students. We validated our findings through member checking and triangulation with instructors. Our findings provide practical considerations of where and why genAI should (not) be used in the context of supporting SE students.	Arxiv	0	['Ambareesh Ramakrishnan', 'Amreeta Chatterjee', 'Bianca Trinkenreich', 'Igor Steinmacher', 'Marco Gerosa', 'Anita Sarma']
170	PHANTOM: Curating GitHub for engineered software projects using time-series clustering	Peter Pickerill	2019-04-25T06:09:11Z	http://arxiv.org/abs/1904.11164v2	"Context: Within the field of Mining Software Repositories, there are numerous methods employed to filter datasets in order to avoid analysing low-quality projects. Unfortunately, the existing filtering methods have not kept up with the growth of existing data sources, such as GitHub, and researchers often rely on quick and dirty techniques to curate datasets.   Objective: The objective of this study is to develop a method capable of filtering large quantities of software projects in a resource-efficient way.   Method: This study follows the Design Science Research (DSR) methodology. The proposed method, PHANTOM, extracts five measures from Git logs. Each measure is transformed into a time-series, which is represented as a feature vector for clustering using the k-means algorithm.   Results: Using the ground truth from a previous study, PHANTOM was shown to be able to rediscover the ground truth on the training dataset, and was able to identify ""engineered"" projects with up to 0.87 Precision and 0.94 Recall on the validation dataset. PHANTOM downloaded and processed the metadata of 1,786,601 GitHub repositories in 21.5 days using a single personal computer, which is over 33% faster than the previous study which used a computer cluster of 200 nodes. The possibility of applying the method outside of the open-source community was investigated by curating 100 repositories owned by two companies.   Conclusions: It is possible to use an unsupervised approach to identify engineered projects. PHANTOM was shown to be competitive compared to the existing supervised approaches while reducing the hardware requirements by two orders of magnitude."	Arxiv	0	['Heiko Joshua Jungen', 'Miroslaw Ochodek', 'Miroslaw Staron']
171	Socio-Technical Grounded Theory for Software Engineering	Rashina Hoda	2021-03-26T02:49:20Z	http://arxiv.org/abs/2103.14235v3	Grounded Theory (GT), a sociological research method designed to study social phenomena, is increasingly being used to investigate the human and social aspects of software engineering (SE). However, being written by and for sociologists, GT is often challenging for a majority of SE researchers to understand and apply. Additionally, SE researchers attempting ad hoc adaptations of traditional GT guidelines for modern socio-technical (ST) contexts often struggle in the absence of clear and relevant guidelines to do so, resulting in poor quality studies. To overcome these research community challenges and leverage modern research opportunities, this paper presents Socio-Technical Grounded Theory (STGT) designed to ease application and achieve quality outcomes. It defines what exactly is meant by an ST research context and presents the STGT guidelines that expand GT's philosophical foundations, provide increased clarity and flexibility in its methodological steps and procedures, define possible scope and contexts of application, encourage frequent reporting of a variety of interim, preliminary, and mature outcomes, and introduce nuanced evaluation guidelines for different outcomes. It is hoped that the SE research community and related ST disciplines such as computer science, data science, artificial intelligence, information systems, human computer/robot/AI interaction, human-centered emerging technologies (and increasingly other disciplines being transformed by rapid digitalisation and AI-based augmentation), will benefit from applying STGT to conduct quality research studies and systematically produce rich findings and mature theories with confidence.	Arxiv	0	[]
172	"We Don't Need Another Hero? The Impact of ""Heroes"" on Software Development"	Amritanshu Agrawal	2017-10-25T02:26:06Z	http://arxiv.org/abs/1710.09055v2	"A software project has ""Hero Developers"" when 80% of contributions are delivered by 20% of the developers. Are such heroes a good idea? Are too many heroes bad for software quality? Is it better to have more/less heroes for different kinds of projects? To answer these questions, we studied 661 open source projects from Public open source software (OSS) Github and 171 projects from an Enterprise Github.   We find that hero projects are very common. In fact, as projects grow in size, nearly all project become hero projects. These findings motivated us to look more closely at the effects of heroes on software development. Analysis shows that the frequency to close issues and bugs are not significantly affected by the presence of project type (Public or Enterprise). Similarly, the time needed to resolve an issue/bug/enhancement is not affected by heroes or project type. This is a surprising result since, before looking at the data, we expected that increasing heroes on a project will slow down howfast that project reacts to change. However, we do find a statistically significant association between heroes, project types, and enhancement resolution rates. Heroes do not affect enhancement resolution rates in Public projects. However, in Enterprise projects, the more heroes increase the rate at which project complete enhancements.   In summary, our empirical results call for a revision of a long-held truism in software engineering. Software heroes are far more common and valuable than suggested by the literature, particularly for medium to large Enterprise developments. Organizations should reflect on better ways to find and retain more of these heroes"	Arxiv	0	['Akond Rahman', 'Rahul Krishna', 'Alexander Sobran', 'Tim Menzies']
173	The Scalability-Efficiency/Maintainability-Portability Trade-off in Simulation Software Engineering: Examples and a Preliminary Systematic Literature Review	Dirk Pfl√ºger	2016-08-15T17:31:46Z	http://arxiv.org/abs/1608.04336v3	Large-scale simulations play a central role in science and the industry. Several challenges occur when building simulation software, because simulations require complex software developed in a dynamic construction process. That is why simulation software engineering (SSE) is emerging lately as a research focus. The dichotomous trade-off between scalability and efficiency (SE) on the one hand and maintainability and portability (MP) on the other hand is one of the core challenges. We report on the SE/MP trade-off in the context of an ongoing systematic literature review (SLR). After characterizing the issue of the SE/MP trade-off using two examples from our own research, we (1) review the 33 identified articles that assess the trade-off, (2) summarize the proposed solutions for the trade-off, and (3) discuss the findings for SSE and future work. Overall, we see evidence for the SE/MP trade-off and first solution approaches. However, a strong empirical foundation has yet to be established; general quantitative metrics and methods supporting software developers in addressing the trade-off have to be developed. We foresee considerable future work in SSE across scientific communities.	Arxiv	0	['Miriam Mehl', 'Julian Valentin', 'Florian Lindner', 'David Pfander', 'Stefan Wagner', 'Daniel Graziotin', 'Yang Wang']
174	Challenges for Inclusion in Software Engineering: The Case of the Emerging Papua New Guinean Society	Raula Gaikovina Kula	2019-10-31T22:20:22Z	http://arxiv.org/abs/1911.04016v2	Software plays a central role in modern societies, with its high economic value and potential for advancing societal change. In this paper, we characterise challenges and opportunities for a country progressing towards entering the global software industry, focusing on Papua New Guinea (PNG). By hosting a Software Engineering workshop, we conducted a qualitative study by recording talks (n=3), employing a questionnaire (n=52), and administering an in-depth focus group session with local actors (n=5). Based on a thematic analysis, we identified challenges as barriers and opportunities for the PNG software engineering community. We also discuss the state of practices and how to make it inclusive for practitioners, researchers, and educators from both the local and global software engineering community.	Arxiv	0	['Christoph Treude', 'Hideaki Hata', 'Sebastian Baltes', 'Igor Steinmacher', 'Marco Aurelio Gerosa', 'Winifred Kula Amini']
175	Foundation Model Engineering: Engineering Foundation Models Just as Engineering Software	Dezhi Ran	2024-07-11T04:40:02Z	http://arxiv.org/abs/2407.08176v1	By treating data and models as the source code, Foundation Models (FMs) become a new type of software. Mirroring the concept of software crisis, the increasing complexity of FMs making FM crisis a tangible concern in the coming decade, appealing for new theories and methodologies from the field of software engineering. In this paper, we outline our vision of introducing Foundation Model (FM) engineering, a strategic response to the anticipated FM crisis with principled engineering methodologies. FM engineering aims to mitigate potential issues in FM development and application through the introduction of declarative, automated, and unified programming interfaces for both data and model management, reducing the complexities involved in working with FMs by providing a more structured and intuitive process for developers. Through the establishment of FM engineering, we aim to provide a robust, automated, and extensible framework that addresses the imminent challenges, and discovering new research opportunities for the software engineering field.	Arxiv	0	['Mengzhou Wu', 'Wei Yang', 'Tao Xie']
176	Fairway: A Way to Build Fair ML Software	Joymallya Chakraborty	2020-03-23T16:16:15Z	http://arxiv.org/abs/2003.10354v6	"Machine learning software is increasingly being used to make decisions that affect people's lives. But sometimes, the core part of this software (the learned model), behaves in a biased manner that gives undue advantages to a specific group of people (where those groups are determined by sex, race, etc.). This ""algorithmic discrimination"" in the AI software systems has become a matter of serious concern in the machine learning and software engineering community. There have been works done to find ""algorithmic bias"" or ""ethical bias"" in the software system. Once the bias is detected in the AI software system, the mitigation of bias is extremely important. In this work, we a)explain how ground-truth bias in training data affects machine learning model fairness and how to find that bias in AI software,b)propose a methodFairwaywhich combines pre-processing and in-processing approach to remove ethical bias from training data and trained model. Our results show that we can find bias and mitigate bias in a learned model, without much damaging the predictive performance of that model. We propose that (1) test-ing for bias and (2) bias mitigation should be a routine part of the machine learning software development life cycle. Fairway offers much support for these two purposes."	Arxiv	0	['Suvodeep Majumder', 'Zhe Yu', 'Tim Menzies']
177	The Present and Future of Bots in Software Engineering	Emad Shihab	2022-07-04T08:26:56Z	http://arxiv.org/abs/2207.01254v1	We are witnessing a massive adoption of software engineering bots, applications that react to events triggered by tools and messages posted by users and run automated tasks in response, in a variety of domains. This thematic issues describes experiences and challenges with these bots.	Arxiv	0	['Stefan Wagner', 'Marco A. Gerosa', 'Mairieli Wessel', 'Jordi Cabot']
178	Recommender Systems for Software Project Managers	Liang Wei	2021-08-09T19:13:31Z	http://arxiv.org/abs/2108.04311v1	The design of recommendation systems is based on complex information processing and big data interaction. This personalized view has evolved into a hot area in the past decade, where applications might have been proved to help for solving problem in the software development field. Therefore, with the evolvement of Recommendation System in Software Engineering (RSSE), the coordination of software projects with their stakeholders is improving. This experiment examines four open source recommender systems and implemented a customized recommender engine with two industrial-oriented packages: Lenskit and Mahout. Each of the main functions was examined and issues were identified during the experiment.	Arxiv	0	['Luiz Fernando Capretz']
179	Trustworthy and Synergistic Artificial Intelligence for Software Engineering: Vision and Roadmaps	David Lo	2023-09-08T05:53:24Z	http://arxiv.org/abs/2309.04142v2	For decades, much software engineering research has been dedicated to devising automated solutions aimed at enhancing developer productivity and elevating software quality. The past two decades have witnessed an unparalleled surge in the development of intelligent solutions tailored for software engineering tasks. This momentum established the Artificial Intelligence for Software Engineering (AI4SE) area, which has swiftly become one of the most active and popular areas within the software engineering field.   This Future of Software Engineering (FoSE) paper navigates through several focal points. It commences with a succinct introduction and history of AI4SE. Thereafter, it underscores the core challenges inherent to AI4SE, particularly highlighting the need to realize trustworthy and synergistic AI4SE. Progressing, the paper paints a vision for the potential leaps achievable if AI4SE's key challenges are surmounted, suggesting a transition towards Software Engineering 2.0. Two strategic roadmaps are then laid out: one centered on realizing trustworthy AI4SE, and the other on fostering synergistic AI4SE. While this paper may not serve as a conclusive guide, its intent is to catalyze further progress. The ultimate aspiration is to position AI4SE as a linchpin in redefining the horizons of software engineering, propelling us toward Software Engineering 2.0.	Arxiv	0	[]
180	Quantum Software Engineering and Potential of Quantum Computing in Software Engineering Research: A Review	Ashis Kumar Mandal	2025-02-13T03:22:36Z	http://arxiv.org/abs/2502.08925v1	Research in software engineering is essential for improving development practices, leading to reliable and secure software. Leveraging the principles of quantum physics, quantum computing has emerged as a new computational paradigm that offers significant advantages over classical computing. As quantum computing progresses rapidly, its potential applications across various fields are becoming apparent. In software engineering, many tasks involve complex computations where quantum computers can greatly speed up the development process, leading to faster and more efficient solutions. With the growing use of quantum-based applications in different fields, quantum software engineering (QSE) has emerged as a discipline focused on designing, developing, and optimizing quantum software for diverse applications. This paper aims to review the role of quantum computing in software engineering research and the latest developments in QSE. To our knowledge, this is the first comprehensive review on this topic. We begin by introducing quantum computing, exploring its fundamental concepts, and discussing its potential applications in software engineering. We also examine various QSE techniques that expedite software development. Finally, we discuss the opportunities and challenges in quantum-driven software engineering and QSE. Our study reveals that quantum machine learning (QML) and quantum optimization have substantial potential to address classical software engineering tasks, though this area is still limited. Current QSE tools and techniques lack robustness and maturity, indicating a need for more focus. One of the main challenges is that quantum computing has yet to reach its full potential.	Arxiv	0	['Md Nadim', 'Chanchal K. Roy', 'Banani Roy', 'Kevin A. Schneider']
181	Automated flakiness detection in quantum software bug reports	Lei Zhang	2024-08-09T20:42:20Z	http://arxiv.org/abs/2408.05331v1	A flaky test yields inconsistent results upon repetition, posing a significant challenge to software developers. An extensive study of their presence and characteristics has been done in classical computer software but not quantum computer software. In this paper, we outline challenges and potential solutions for the automated detection of flaky tests in bug reports of quantum software. We aim to raise awareness of flakiness in quantum software and encourage the software engineering community to work collaboratively to solve this emerging challenge.	Arxiv	0	['Andriy Miranskyy']
182	Analysis of Software Engineering Practices in General Software and Machine Learning Startups	Bishal Lakha	2023-04-04T04:21:09Z	http://arxiv.org/abs/2304.01523v1	Context: On top of the inherent challenges startup software companies face applying proper software engineering practices, the non-deterministic nature of machine learning techniques makes it even more difficult for machine learning (ML) startups.   Objective: Therefore, the objective of our study is to understand the whole picture of software engineering practices followed by ML startups and identify additional needs.   Method: To achieve our goal, we conducted a systematic literature review study on 37 papers published in the last 21 years. We selected papers on both general software startups and ML startups. We collected data to understand software engineering (SE) practices in five phases of the software development life-cycle: requirement engineering, design, development, quality assurance, and deployment.   Results: We find some interesting differences in software engineering practices in ML startups and general software startups. The data management and model learning phases are the most prominent among them.   Conclusion: While ML startups face many similar challenges to general software startups, the additional difficulties of using stochastic ML models require different strategies in using software engineering practices to produce high-quality products.	Arxiv	0	['Kalyan Bhetwal', 'Nasir U. Eisty']
183	Bayesian Data Analysis in Empirical Software Engineering Research	Carlo A. Furia	2018-11-13T17:24:51Z	http://arxiv.org/abs/1811.05422v5	Statistics comes in two main flavors: frequentist and Bayesian. For historical and technical reasons, frequentist statistics have traditionally dominated empirical data analysis, and certainly remain prevalent in empirical software engineering. This situation is unfortunate because frequentist statistics suffer from a number of shortcomings---such as lack of flexibility and results that are unintuitive and hard to interpret---that curtail their effectiveness when dealing with the heterogeneous data that is increasingly available for empirical analysis of software engineering practice.   In this paper, we pinpoint these shortcomings, and present Bayesian data analysis techniques that provide tangible benefits---as they can provide clearer results that are simultaneously robust and nuanced. After a short, high-level introduction to the basic tools of Bayesian statistics, we present the reanalysis of two empirical studies on the effectiveness of automatically generated tests and the performance of programming languages. By contrasting the original frequentist analyses with our new Bayesian analyses, we demonstrate the concrete advantages of the latter. To conclude we advocate a more prominent role for Bayesian statistical techniques in empirical software engineering research and practice.	Arxiv	0	['Robert Feldt', 'Richard Torkar']
184	On the Unhappiness of Software Developers	Daniel Graziotin	2017-03-15T08:07:39Z	http://arxiv.org/abs/1703.04993v3	The happy-productive worker thesis states that happy workers are more productive. Recent research in software engineering supports the thesis, and the ideal of flourishing happiness among software developers is often expressed among industry practitioners. However, the literature suggests that a cost-effective way to foster happiness and productivity among workers could be to limit unhappiness. Psychological disorders such as job burnout and anxiety could also be reduced by limiting the negative experiences of software developers. Simultaneously, a baseline assessment of (un)happiness and knowledge about how developers experience it are missing. In this paper, we broaden the understanding of unhappiness among software developers in terms of (1) the software developer population distribution of (un)happiness, and (2) the causes of unhappiness while developing software. We conducted a large-scale quantitative and qualitative survey, incorporating a psychometrically validated instrument for measuring (un)happiness, with 2220 developers, yielding a rich and balanced sample of 1318 complete responses. Our results indicate that software developers are a slightly happy population, but the need for limiting the unhappiness of developers remains. We also identified 219 factors representing causes of unhappiness while developing software. Our results, which are available as open data, can act as guidelines for practitioners in management positions and developers in general for fostering happiness on the job. We suggest considering happiness in future studies of both human and technical aspects in software engineering.	Arxiv	0	['Fabian Fagerholm', 'Xiaofeng Wang', 'Pekka Abrahamsson']
185	Reflections on Cyberethics Education for Millennial Software Engineers	Claudia de O. Melo	2017-03-02T05:00:50Z	http://arxiv.org/abs/1703.00619v1	"Software is a key component of solutions for 21st Century problems. These problems are often ""wicked"", complex, and unpredictable. To provide the best possible solution, millennial software engineers must be prepared to make ethical decisions, thinking critically, and acting systematically. This reality demands continuous changes in educational systems and curricula delivery, as misjudgment might have serious social impact. This study aims to investigate and reflect on Software Engineering (SE) Programs, proposing a conceptual framework for analyzing cyberethics education and a set of suggestions on how to integrate it into the SE undergraduate curriculum."	Arxiv	0	['Thiago C. de Sousa']
186	Multilingual training for Software Engineering	Toufique Ahmed	2021-12-03T17:47:00Z	http://arxiv.org/abs/2112.02043v4	Well-trained machine-learning models, which leverage large amounts of open-source software data, have now become an interesting approach to automating many software engineering tasks. Several SE tasks have all been subject to this approach, with performance gradually improving over the past several years with better models and training methods. More, and more diverse, clean, labeled data is better for training; but constructing good-quality datasets is time-consuming and challenging. Ways of augmenting the volume and diversity of clean, labeled data generally have wide applicability. For some languages (e.g., Ruby) labeled data is less abundant; in others (e.g., JavaScript) the available data maybe more focused on some application domains, and thus less diverse. As a way around such data bottlenecks, we present evidence suggesting that human-written code in different languages (which performs the same function), is rather similar, and particularly preserving of identifier naming patterns; we further present evidence suggesting that identifiers are a very important element of training data for software engineering tasks. We leverage this rather fortuitous phenomenon to find evidence that available multilingual training data (across different languages) can be used to amplify performance. We study this for 3 different tasks: code summarization, code retrieval, and function naming. We note that this data-augmenting approach is broadly compatible with different tasks, languages, and machine-learning models.	Arxiv	0	['Premkumar Devanbu']
187	Survey Research in Software Engineering: Problems and Strategies	Ahmad Nauman Ghazi	2017-04-04T16:23:35Z	http://arxiv.org/abs/1704.01090v1	Background: The need for empirical investigations in software engineering is growing. Many researchers nowadays, conduct and validate their solutions using empirical research. Survey is one empirical method which enables researchers to collect data from a large population. Main aim of the survey is to generalize the findings. Aims: In this study we aim to identify the problems researchers face during survey design, and mitigation strategies. Method: A literature review as well as semi-structured interviews with nine software engineering researchers were conducted to elicit their views on problems and mitigation strategies. The researchers are all focused on empirical software engineering. Results: We identified 24 problems and 65 strategies, structured according to the survey research process. The most commonly discussed problem was sampling, in particular the ability to obtain a sufficiently large sample. To improve survey instrument design, evaluation and execution recommendations for question formulation and survey pre-testing were given. The importance of involving multiple researchers in the analysis of survey results was stressed. Conclusions: The elicited problems and strategies may serve researchers during the design of their studies. However, it was observed that some strategies were conflicting. This shows that it is important to conduct a trade-off analysis between strategies.	Arxiv	0	['Kai Petersen', 'Sri Sai Vijay Raj Reddy', 'Harini Nekkanti']
188	Extending Behavioral Software Engineering: Decision-Making and Collaboration in Human-AI Teams for Responsible Software Engineering	Lekshmi Murali Rani	2025-04-13T09:40:25Z	http://arxiv.org/abs/2504.09496v2	The study of behavioral and social dimensions of software engineering (SE) tasks characterizes behavioral software engineering (BSE);however, the increasing significance of human-AI collaboration (HAIC) brings new directions in BSE by presenting new challenges and opportunities. This PhD research focuses on decision-making (DM) for SE tasks and collaboration within human-AI teams, aiming to promote responsible software engineering through a cognitive partnership between humans and AI. The goal of the research is to identify the challenges and nuances in HAIC from a cognitive perspective, design and optimize collaboration/partnership (human-AI team) that enhance collective intelligence and promote better, responsible DM in SE through human-centered approaches. The research addresses HAIC and its impact on individual, team, and organizational level aspects of BSE.	Arxiv	0	[]
189	Many-Objective Software Remodularization using NSGA-III	Mohamed Wiem Mkaouer	2020-05-13T18:34:15Z	http://arxiv.org/abs/2005.06510v1	Software systems nowadays are complex and difficult to maintain due to continuous changes and bad design choices. To handle the complexity of systems, software products are, in general, decomposed in terms of packages/modules containing classes that are dependent. However, it is challenging to automatically remodularize systems to improve their maintainability. The majority of existing remodularization work mainly satisfy one objective which is improving the structure of packages by optimizing coupling and cohesion. In addition, most of existing studies are limited to only few operation types such as move class and split packages. Many other objectives, such as the design semantics, reducing the number of changes and maximizing the consistency with development change history, are important to improve the quality of the software by remodularizing it. In this paper, we propose a novel many-objective search-based approach using NSGA-III. The process aims at finding the optimal remodularization solutions that improve the structure of packages, minimize the number of changes, preserve semantics coherence, and re-use the history of changes. We evaluate the efficiency of our approach using four different open-source systems and one automotive industry project, provided by our industrial partner, through a quantitative and qualitative study conducted with software engineers.	Arxiv	0	['Marouane Kessentini', 'Adnan Shaout', 'Patrice Koligheu', 'Slim Bechikh', 'Kalyanmoy Deb', 'Ali Ouni']
190	Sampling in Software Engineering Research: A Critical Review and Guidelines	Sebastian Baltes	2020-02-18T17:53:55Z	http://arxiv.org/abs/2002.07764v6	Representative sampling appears rare in empirical software engineering research. Not all studies need representative samples, but a general lack of representative sampling undermines a scientific field. This article therefore reports a critical review of the state of sampling in recent, high-quality software engineering research. The key findings are: (1) random sampling is rare; (2) sophisticated sampling strategies are very rare; (3) sampling, representativeness and randomness often appear misunderstood. These findings suggest that software engineering research has a generalizability crisis. To address these problems, this paper synthesizes existing knowledge of sampling into a succinct primer and proposes extensive guidelines for improving the conduct, presentation and evaluation of sampling in software engineering research. It is further recommended that while researchers should strive for more representative samples, disparaging non-probability sampling is generally capricious and particularly misguided for predominately qualitative research.	Arxiv	0	['Paul Ralph']
191	Revisiting Sentiment Analysis for Software Engineering in the Era of Large Language Models	Ting Zhang	2023-10-17T09:53:03Z	http://arxiv.org/abs/2310.11113v3	Software development involves collaborative interactions where stakeholders express opinions across various platforms. Recognizing the sentiments conveyed in these interactions is crucial for the effective development and ongoing maintenance of software systems. For software products, analyzing the sentiment of user feedback, e.g., reviews, comments, and forum posts can provide valuable insights into user satisfaction and areas for improvement. This can guide the development of future updates and features. However, accurately identifying sentiments in software engineering datasets remains challenging.   This study investigates bigger large language models (bLLMs) in addressing the labeled data shortage that hampers fine-tuned smaller large language models (sLLMs) in software engineering tasks. We conduct a comprehensive empirical study using five established datasets to assess three open-source bLLMs in zero-shot and few-shot scenarios. Additionally, we compare them with fine-tuned sLLMs, using sLLMs to learn contextual embeddings of text from software platforms.   Our experimental findings demonstrate that bLLMs exhibit state-of-the-art performance on datasets marked by limited training data and imbalanced distributions. bLLMs can also achieve excellent performance under a zero-shot setting. However, when ample training data is available or the dataset exhibits a more balanced distribution, fine-tuned sLLMs can still achieve superior results.	Arxiv	0	['Ivana Clairine Irsan', 'Ferdian Thung', 'David Lo']
192	A Web-based modeling tool for the SEMAT Essence theory of Software Engineering	Daniel Graziotin	2013-07-08T13:00:36Z	http://arxiv.org/abs/1307.2075v2	As opposed to more mature subjects, software engineering lacks general theories to establish its foundations as a discipline. The Essence Theory of software engineering (Essence) has been proposed by the Software Engineering Methods and Theory (SEMAT) initiative. Essence goal is to develop a theoretically sound basis for software engineering practice and its wide adoption. Essence is yet far from reaching academic and industry adoption. Reasons include a struggle to foresee its utilization potential and the lack of tools implementing it. SEMAT Accelerator (SematAcc) is a Web-positioning tool for a software engineering endeavor, which implements the SEMAT's Essence kernel. SematAcc allows using Essence, thus helping to understand it. The tool enables teaching, adopting, and researching Essence in controlled experiments and case studies.	Arxiv	0	['Pekka Abrahamsson']
193	Artefacts in Software Engineering: A Fundamental Positioning	D. M√©ndez Fern√°ndez	2018-05-31T21:00:12Z	http://arxiv.org/abs/1806.00098v3	Artefacts play a vital role in software and systems development processes. Other terms like documents, deliverables, or work products are widely used in software development communities instead of the term artefact. In the following, we use the term `artefact' including all these other terms. Despite its relevance, the exact denotation of the term `artefact' is still not clear due to a variety of different understandings of the term and to a careless negligent usage. This often leads to approaches being grounded in a fuzzy, unclear understanding of the essential concepts involved. In fact, there does not exist a common terminology. Therefore, it is our goal that the term artefact be standardised so that researchers and practitioners have a common understanding for discussions and contributions. In this position paper, we provide a positioning and critical reflection upon the notion of artefact in software engineering at different levels of perception and how these relate to each other. We further contribute a meta model that provides a description of an artefact that is independent from any underlying process model. This meta model defines artefacts at three levels. Abstraction and refinement relations between these levels allow correlating artefacts to each other and defining the notion of related, refined, and equivalent artefacts. Our contribution shall foster the long overdue and too often underestimated terminological discussion on what artefacts are to provide a common ground with clearer concepts and principles for future software engineering contributions, such as the design of artefact-oriented development processes and tools.	Arxiv	0	['W. B√∂hm', 'A. Vogelsang', 'J. Mund', 'M. Broy', 'M. Kuhrmann', 'T. Weyer']
194	What's in a Software Engineering Job Posting?	Marvin Wyrich	2025-11-17T18:14:15Z	http://arxiv.org/abs/2511.13656v1	A well-rounded software engineer is often defined by technical prowess and the ability to deliver on complex projects. However, the narrative around the ideal Software Engineering (SE) candidate is evolving, suggesting that there is more to the story. This article explores the non-technical aspects emphasized in SE job postings, revealing the sociotechnical and organizational expectations of employers. Our Thematic Analysis of 100 job postings shows that employers seek candidates who align with their sense of purpose, fit within company culture, pursue personal and career growth, and excel in interpersonal interactions. This study contributes to ongoing discussions in the SE community about the evolving role and workplace context of software engineers beyond technical skills. By highlighting these expectations, we provide relevant insights for researchers, educators, practitioners, and recruiters. Additionally, our analysis offers a valuable snapshot of SE job postings in 2023, providing a scientific record of prevailing trends and expectations.	Arxiv	0	['Lloyd Montgomery']
195	Ethical Interviews in Software Engineering	Per Erik Strandberg	2019-06-19T09:32:36Z	http://arxiv.org/abs/1906.07993v1	Background: Despite a long history, numerous laws and regulations, ethics remains an unnatural topic for many software engineering researchers. Poor research ethics may lead to mistrust of research results, lost funding and retraction of publications. A core principle for research ethics is confidentiality, and anonymization is a standard approach to guarantee it. Many guidelines for qualitative software engineering research, and for qualitative research in general, exist, but these do not penetrate how and why to anonymize interview data. Aims: In this paper we aim to identify ethical guidelines for software engineering interview studies involving industrial practitioners. Method: By learning from previous experiences and listening to the authority of existing guidelines in the more mature field of medicine as well as in software engineering, a comprehensive set of checklists for interview studies was distilled. Results: The elements of an interview study were identified and ethical considerations and recommendations for each step were produced, in particular with respect to anonymization. Important ethical principles are: consent, beneficence, confidentiality, scientific value, researcher skill, justice, respect for law, and ethical reviews. Conclusions: The most important contribution of this study is the set of checklists for ethical interview studies. Future work is needed to refine these guidelines with respect to legal aspects and ethical boards.	Arxiv	0	[]
196	Human Factors in Software Reliability Engineering	Maria Spichkova	2015-03-12T04:40:08Z	http://arxiv.org/abs/1503.03584v1	In this paper, we present our vision of the integration of human factors engineering into the software development process. The aim of this approach is to improve the quality of software and to deal with human errors in a systematic way.	Arxiv	0	['Huai Liu', 'Mohsen Laali', 'Heinz W. Schmidt']
197	Understanding and Improving Artifact Sharing in Software Engineering Research	Christopher S. Timperley	2020-08-03T17:33:28Z	http://arxiv.org/abs/2008.01046v2	In recent years, many software engineering researchers have begun to include artifacts alongside their research papers. Ideally, artifacts, including tools, benchmarks, and data, support the dissemination of ideas, provide evidence for research claims, and serve as a starting point for future research. However, in practice, artifacts suffer from a variety of issues that prevent the realization of their full potential.   To help the software engineering community realize the full potential of artifacts, we seek to understand the challenges involved in the creation, sharing, and use of artifacts. To that end, we perform a mixed-methods study including a survey of artifacts in software engineering publications, and an online survey of 153 software engineering researchers. By analyzing the perspectives of artifact creators, users, and reviewers, we identify several high-level challenges that affect the quality of artifacts including mismatched expectations between these groups, and a lack of sufficient reward for both creators and reviewers. Using Diffusion of Innovations as an analytical framework, we examine how these challenges relate to one another, and build an understanding of the factors that affect the sharing and success of artifacts. Finally, we make recommendations to improve the quality of artifacts based on our results and existing best practices.	Arxiv	0	['Lauren Herckis', 'Claire Le Goues', 'Michael Hilton']
198	Reflecting on the Use of the Policy-Process-Product Theory in Empirical Software Engineering	Kelechi G. Kalu	2023-08-23T19:01:13Z	http://arxiv.org/abs/2308.12387v1	The primary theory of software engineering is that an organization's Policies and Processes influence the quality of its Products. We call this the PPP Theory. Although empirical software engineering research has grown common, it is unclear whether researchers are trying to evaluate the PPP Theory. To assess this, we analyzed half (33) of the empirical works published over the last two years in three prominent software engineering conferences. In this sample, 70% focus on policies/processes or products, not both. Only 33% provided measurements relating policy/process and products. We make four recommendations: (1) Use PPP Theory in study design; (2) Study feedback relationships; (3) Diversify the studied feedforward relationships; and (4) Disentangle policy and process. Let us remember that research results are in the context of, and with respect to, the relationship between software products, processes, and policies.	Arxiv	0	['Taylor R. Schorlemmer', 'Sophie Chen', 'Kyle Robinson', 'Erik Kocinare', 'James C. Davis']
199	Open Science in Software Engineering	Daniel M√©ndez Fern√°ndez	2019-04-13T07:38:41Z	http://arxiv.org/abs/1904.06499v3	Open science describes the movement of making any research artefact available to the public and includes, but is not limited to, open access, open data, and open source. While open science is becoming generally accepted as a norm in other scientific disciplines, in software engineering, we are still struggling in adapting open science to the particularities of our discipline, rendering progress in our scientific community cumbersome. In this chapter, we reflect upon the essentials in open science for software engineering including what open science is, why we should engage in it, and how we should do it. We particularly draw from our experiences made as conference chairs implementing open science initiatives and as researchers actively engaging in open science to critically discuss challenges and pitfalls, and to address more advanced topics such as how and under which conditions to share preprints, what infrastructure and licence model to cover, or how do it within the limitations of different reviewing models, such as double-blind reviewing. Our hope is to help establishing a common ground and to contribute to make open science a norm also in software engineering.	Arxiv	0	['Daniel Graziotin', 'Stefan Wagner', 'Heidi Seibold']
200	The Current Challenges of Software Engineering in the Era of Large Language Models	Cuiyun Gao	2024-12-19T06:10:40Z	http://arxiv.org/abs/2412.14554v2	With the advent of large language models (LLMs) in the artificial intelligence (AI) area, the field of software engineering (SE) has also witnessed a paradigm shift. These models, by leveraging the power of deep learning and massive amounts of data, have demonstrated an unprecedented capacity to understand, generate, and operate programming languages. They can assist developers in completing a broad spectrum of software development activities, encompassing software design, automated programming, and maintenance, which potentially reduces huge human efforts. Integrating LLMs within the SE landscape (LLM4SE) has become a burgeoning trend, necessitating exploring this emergent landscape's challenges and opportunities.   The paper aims at revisiting the software development life cycle (SDLC) under LLMs, and highlighting challenges and opportunities of the new paradigm. The paper first summarizes the overall process of LLM4SE, and then elaborates on the current challenges based on a through discussion. The discussion was held among more than 20 participants from academia and industry, specializing in fields such as software engineering and artificial intelligence. Specifically, we achieve 26 key challenges from seven aspects, including software requirement & design, coding assistance, testing code generation, code review, code maintenance, software vulnerability management, and data, training, and evaluation. We hope the achieved challenges would benefit future research in the LLM4SE field.	Arxiv	0	['Xing Hu', 'Shan Gao', 'Xin Xia', 'Zhi Jin']
201	On the Pragmatic Design of Literature Studies in Software Engineering: An Experience-based Guideline	M. Kuhrmann	2016-12-12T09:33:04Z	http://arxiv.org/abs/1612.03583v1	Systematic literature studies have received much attention in empirical software engineering in recent years. They have become a powerful tool to collect and structure reported knowledge in a systematic and reproducible way. We distinguish systematic literature reviews to systematically analyze reported evidence in depth, and systematic mapping studies to structure a field of interest in a broader, usually quantified manner. Due to the rapidly increasing body of knowledge in software engineering, researchers who want to capture the published work in a domain often face an extensive amount of publications, which need to be screened, rated for relevance, classified, and eventually analyzed. Although there are several guidelines to conduct literature studies, they do not yet help researchers coping with the specific difficulties encountered in the practical application of these guidelines. In this article, we present an experience-based guideline to aid researchers in designing systematic literature studies with special emphasis on the data collection and selection procedures. Our guideline aims at providing a blueprint for a practical and pragmatic path through the plethora of currently available practices and deliverables capturing the dependencies among the single steps. The guideline emerges from various mapping studies and literature reviews conducted by the authors and provides recommendations for the general study design, data collection, and study selection procedures. Finally, we share our experiences and lessons learned in applying the different practices of the proposed guideline.	Arxiv	0	['D. M√©ndez Fern√°ndez', 'M. Daneva']
202	The Diversity of Gamification Evaluation in the Software Engineering Education and Industry: Trends, Comparisons and Gaps	Rodrigo Henrique Barbosa Monteiro	2021-02-09T19:39:07Z	http://arxiv.org/abs/2102.05089v1	Gamification has been used to motivate and engage participants in software engineering education and practice activities. There is a significant demand for empirical studies for the understanding of the impacts and efficacy of gamification. However, the lack of standard procedures and models for the evaluation of gamification is a challenge for the design, comparison, and report of results related to the assessment of gamification approaches and its effects. The goal of this study is to identify models and strategies for the evaluation of gamification reported in the literature. To achieve this goal, we conducted a systematic mapping study to investigate strategies for the evaluation of gamification in the context of software engineering. We selected 100 primary studies on gamification in software engineering (from 2011 to 2020). We categorized the studies regarding the presence of evaluation procedures or models for the evaluation of gamification, the purpose of the evaluation, the criteria used, the type of data, instruments, and procedures for data analysis. Our results show that 64 studies report procedures for the evaluation of gamification. However, only three studies actually propose evaluation models for gamification. We observed that the evaluation of gamification focuses on two aspects: the evaluation of the gamification strategy itself, related to the user experience and perceptions; and the evaluation of the outcomes and effects of gamification on its users and context. The most recurring criteria for the evaluation are 'engagement', 'motivation', 'satisfaction', and 'performance'. Finally, the evaluation of gamification requires a mix of subjective and objective inputs, and qualitative and quantitative data analysis approaches. Depending of the focus of the evaluation (the strategy or the outcomes), there is a predominance of a type of data and analysis.	Arxiv	0	['Maur√≠cio Ronny de Almeida Souza', 'Sandro Ronaldo Bezerra Oliveira', 'Carlos dos Santos Portela', 'Cesar Elias de Cristo Lobato']
203	On the Presence of Green and Sustainable Software Engineering in Higher Education Curricula	Damiano Torre	2017-03-03T08:39:48Z	http://arxiv.org/abs/1703.01078v1	Nowadays, software is pervasive in our everyday lives. Its sustainability and environmental impact have become major factors to be considered in the development of software systems. Millennials-the newer generation of university students-are particularly keen to learn about and contribute to a more sustainable and green society. The need for training on green and sustainable topics in software engineering has been reflected in a number of recent studies. The goal of this paper is to get a first understanding of what is the current state of teaching sustainability in the software engineering community, what are the motivations behind the current state of teaching, and what can be done to improve it. To this end, we report the findings from a targeted survey of 33 academics on the presence of green and sustainable software engineering in higher education. The major findings from the collected data suggest that sustainability is under-represented in the curricula, while the current focus of teaching is on energy efficiency delivered through a fact-based approach. The reasons vary from lack of awareness, teaching material and suitable technologies, to the high effort required to teach sustainability. Finally, we provide recommendations for educators willing to teach sustainability in software engineering that can help to suit millennial students needs.	Arxiv	0	['Giuseppe Procaccianti', 'Davide Fucci', 'Sonja Lutovac', 'Giuseppe Scanniello']
204	Beyond Self-Promotion: How Software Engineering Research Is Discussed on LinkedIn	Marvin Wyrich	2024-01-04T13:38:51Z	http://arxiv.org/abs/2401.02268v1	LinkedIn is the largest professional network in the world. As such, it can serve to build bridges between practitioners, whose daily work is software engineering (SE), and researchers, who work to advance the field of software engineering. We know that such a metaphorical bridge exists: SE research findings are sometimes shared on LinkedIn and commented on by software practitioners. Yet, we do not know what state the bridge is in. Therefore, we quantitatively and qualitatively investigate how SE practitioners and researchers approach each other via public LinkedIn discussions and what both sides can contribute to effective science communication. We found that a considerable proportion of LinkedIn posts on SE research are written by people who are not the paper authors (39%). Further, 71% of all comments in our dataset are from people in the industry, but only every second post receives at least one comment at all. Based on our findings, we formulate concrete advice for researchers and practitioners to make sharing new research findings on LinkedIn more fruitful.	Arxiv	0	['Justus Bogner']
205	Do Research Software Engineers and Software Engineering Researchers Speak the Same Language?	Timo Kehrer	2025-07-03T14:27:54Z	http://arxiv.org/abs/2507.02665v1	Anecdotal evidence suggests that Research Software Engineers (RSEs) and Software Engineering Researchers (SERs) often use different terminologies for similar concepts, creating communication challenges. To better understand these divergences, we have started investigating how SE fundamentals from the SER community are interpreted within the RSE community, identifying aligned concepts, knowledge gaps, and areas for potential adaptation. Our preliminary findings reveal opportunities for mutual learning and collaboration, and our systematic methodology for terminology mapping provides a foundation for a crowd-sourced extension and validation in the future.	Arxiv	0	['Robert Haines', 'Guido Juckeland', 'Shurui Zhou', 'David E. Bernholdt']
206	The Affect of Software Developers: Common Misconceptions and Measurements	Daniel Graziotin	2015-05-18T09:13:49Z	http://arxiv.org/abs/1505.04563v1	The study of affects (i.e., emotions, moods) in the workplace has received a lot of attention in the last 15 years. Despite the fact that software development has been shown to be intellectual, creative, and driven by cognitive activities, and that affects have a deep influence on cognitive activities, software engineering research lacks an understanding of the affects of software developers. This note provides (1) common misconceptions of affects when dealing with job satisfaction, motivation, commitment, well-being, and happiness; (2) validated measurement instruments for affect measurement; and (3) our recommendations when measuring the affects of software developers.	Arxiv	0	['Xiaofeng Wang', 'Pekka Abrahamsson']
207	Storytelling in human--centric software engineering research	Austen Rainer	2021-04-29T12:31:40Z	http://arxiv.org/abs/2104.14296v2	BACKGROUND: Software engineering is a human activity. People naturally make sense of their activities and experience through storytelling. But storytelling does not appear to have been properly studied by software engineering research. AIM: We explore the question: what contribution can storytelling make to human--centric software engineering research? METHOD: We define concepts, identify types of story and their purposes, outcomes and effects, briefly review prior literature, identify several contributions and propose next steps. RESULTS: Storytelling can, amongst other contributions, contribute to data collection, data analyses, ways of knowing, research outputs, interventions in practice, and advocacy, and can integrate with evidence and arguments. Like all methods, storytelling brings risks. These risks can be managed. CONCLUSION: Storytelling provides a potential counter--balance to abstraction, and an approach to retain and honour human meaning in software engineering.	Arxiv	0	[]
208	The Role of Emotional Intelligence in Handling Requirements Changes in Software Engineering	Kashumi Madampe	2022-06-23T10:26:41Z	http://arxiv.org/abs/2206.11603v1	Background: Requirements changes (RCs) are inevitable in Software Engineering. Research shows that emotional intelligence (EI) should be used alongside agility and cognitive intelligence during RC handling. Objective: We wanted to study the role of EI in-depth during RC handling. Method: We conducted a socio-technical grounded theory study with eighteen software practitioners from Australia, New Zealand, Singapore, and Sri Lanka. Findings: We found causal condition (software practitioners handling RCs), intervening condition (mode of work), causes (being aware of own emotions, being aware of others' emotions), direct consequences (regulating own emotions, managing relationships), extended consequences (sustaining productivity, setting and sustaining team goals), and contingencies: strategies (open and regular communication, tracking commitments and issues, and ten other strategies) of using EI during RC handling. We also found the covariances where strategies co-vary with the causes and direct consequences, and ease/ difficulty in executing strategies co-vary with the intervening condition. Conclusion: Open and regular communication is key to EI during RC handling. To the best of our knowledge, the framework we present in this paper is the first theoretical framework on EI in Software Engineering research. We provide recommendations including a problem-solution chart in the form of causes, direct consequences, and mode of work against the contingencies: strategies for software practitioners to consider during RC handling, and future directions of research.	Arxiv	0	['Rashina Hoda', 'John Grundy']
209	Teaching Empirical Research Methods in Software Engineering: An Editorial Introduction	Daniel Mendez	2025-01-13T10:42:43Z	http://arxiv.org/abs/2501.07195v1	Empirical Software Engineering has received much attention in recent years and became a de-facto standard for scientific practice in Software Engineering. However, while extensive guidelines are nowadays available for designing, conducting, reporting, and reviewing empirical studies, similar attention has not yet been paid to teaching empirical software engineering. Closing this gap is the scope of this edited book. In the following editorial introduction, we, the editors, set the foundation by laying out the larger context of the discipline for a positioning of the remainder of this book.	Arxiv	0	['Paris Avgeriou', 'Marcos Kalinowski', 'Nauman bin Ali']
210	Motivational models for validating agile requirements in Software Engineering subjects	Eduardo A. Oliveira	2023-06-12T02:51:32Z	http://arxiv.org/abs/2306.06834v1	This paper describes how motivational models can be used to cross check agile requirements artifacts to improve consistency and completeness of software requirements. Motivational models provide a high level understanding of the purposes of a software system. They complement personas and user stories which focus more on user needs rather than on system features. We present an exploratory case study sought to understand how software engineering students could use motivational models to create better requirements artifacts so they are understandable to non-technical users, easily understood by developers, and are consistent with each other. Nine consistency principles were created as an outcome of our study and are now successfully adopted by software engineering students at the University of Melbourne to ensure consistency between motivational models, personas, and user stories in requirements engineering.	Arxiv	0	['Leon Sterling']
211	Do Performance Aspirations Matter for Guiding Software Configuration Tuning?	Tao Chen	2023-01-09T12:11:05Z	http://arxiv.org/abs/2301.03290v1	Configurable software systems can be tuned for better performance. Leveraging on some Pareto optimizers, recent work has shifted from tuning for a single, time-related performance objective to two intrinsically different objectives that assess distinct performance aspects of the system, each with varying aspirations. Before we design better optimizers, a crucial engineering decision to make therein is how to handle the performance requirements with clear aspirations in the tuning process. For this, the community takes two alternative optimization models: either quantifying and incorporating the aspirations into the search objectives that guide the tuning, or not considering the aspirations during the search but purely using them in the later decision-making process only. However, despite being a crucial decision that determines how an optimizer can be designed and tailored, there is a rather limited understanding of which optimization model should be chosen under what particular circumstance, and why.   In this paper, we seek to close this gap. Firstly, we do that through a review of over 426 papers in the literature and 14 real-world requirements datasets. Drawing on these, we then conduct a comprehensive empirical study that covers 15 combinations of the state-of-the-art performance requirement patterns, four types of aspiration space, three Pareto optimizers, and eight real-world systems/environments, leading to 1,296 cases of investigation. We found that (1) the realism of aspirations is the key factor that determines whether they should be used to guide the tuning; (2) the given patterns and the position of the realistic aspirations in the objective landscape are less important for the choice, but they do matter to the extents of improvement; (3) the available tuning budget can also influence the choice for unrealistic aspirations but it is insignificant under realistic ones.	Arxiv	0	['Miqing Li']
212	Software Engineers vs. Machine Learning Algorithms: An Empirical Study Assessing Performance and Reuse Tasks	Nathalia Nascimento	2018-02-04T09:38:48Z	http://arxiv.org/abs/1802.01096v2	Several papers have recently contained reports on applying machine learning (ML) to the automation of software engineering (SE) tasks, such as project management, modeling and development. However, there appear to be no approaches comparing how software engineers fare against machine-learning algorithms as applied to specific software development tasks. Such a comparison is essential to gain insight into which tasks are better performed by humans and which by machine learning and how cooperative work or human-in-the-loop processes can be implemented more effectively. In this paper, we present an empirical study that compares how software engineers and machine-learning algorithms perform and reuse tasks. The empirical study involves the synthesis of the control structure of an autonomous streetlight application. Our approach consists of four steps. First, we solved the problem using machine learning to determine specific performance and reuse tasks. Second, we asked software engineers with different domain knowledge levels to provide a solution to the same tasks. Third, we compared how software engineers fare against machine-learning algorithms when accomplishing the performance and reuse tasks based on criteria such as energy consumption and safety. Finally, we analyzed the results to understand which tasks are better performed by either humans or algorithms so that they can work together more effectively. Such an understanding and the resulting human-in-the-loop approaches, which take into account the strengths and weaknesses of humans and machine-learning algorithms, are fundamental not only to provide a basis for cooperative work in support of software engineering, but also, in other areas.	Arxiv	0	['Carlos Lucena', 'Paulo Alencar', 'Donald Cowan']
213	Towards Understanding the Impact of Data Bugs on Deep Learning Models in Software Engineering	Mehil B Shah	2024-11-19T00:28:20Z	http://arxiv.org/abs/2411.12137v3	Deep learning (DL) techniques have achieved significant success in various software engineering tasks (e.g., code completion by Copilot). However, DL systems are prone to bugs from many sources, including training data. Existing literature suggests that bugs in training data are highly prevalent, but little research has focused on understanding their impacts on the models used in software engineering tasks. In this paper, we address this research gap through a comprehensive empirical investigation focused on three types of data prevalent in software engineering tasks: code-based, text-based, and metric-based. Using state-of-the-art baselines, we compare the models trained on clean datasets with those trained on datasets with quality issues and without proper preprocessing. By analysing the gradients, weights, and biases from neural networks under training, we identify the symptoms of data quality and preprocessing issues. Our analysis reveals that quality issues in code data cause biased learning and gradient instability, whereas problems in text data lead to overfitting and poor generalisation of models. On the other hand, quality issues in metric data result in exploding gradients and model overfitting, and inadequate preprocessing exacerbates these effects across all three data types. Finally, we demonstrate the validity and generalizability of our findings using six new datasets. Our research provides a better understanding of the impact and symptoms of data bugs in software engineering datasets. Practitioners and researchers can leverage these findings to develop better monitoring systems and data-cleaning methods to help detect and resolve data bugs in deep learning systems.	Arxiv	0	['Mohammad Masudur Rahman', 'Foutse Khomh']
214	A Road-Map for Transferring Software Engineering methods for Model-Based Early V&V of Behaviour to Systems Engineering	Johan Cederbladh	2024-06-06T13:04:23Z	http://arxiv.org/abs/2406.04037v1	In this paper we discuss the growing need for system behaviour to be validated and verified (V&V'ed) early in model-based systems engineering. Several aspects push companies towards integration of techniques, methods, and processes that promote specific and general V&V activities earlier to support more effective decision-making. As a result, there are incentives to introduce new technologies to remain competitive with the recently drastic changes in system complexity and heterogeneity. Performing V&V early on in development is a means of reducing risk for later error detection while moving key activities earlier in a process. We present a summary of the literature on early V&V and position existing challenges regarding potential solutions and future investigations. In particular, we reason that the software engineering community can act as a source for inspiration as many emerging technologies in the software domain are showing promise in the wider systems domain, and there already exist well formed methods for early V&V of software behaviour in the software modelling community. We conclude the paper with a road-map for future research and development for both researchers and practitioners to further develop the concepts discussed in the paper.	Arxiv	0	['Antonio Cicchetti']
215	Stop Words for Processing Software Engineering Documents: Do they Matter?	Yaohou Fan	2023-03-18T15:39:23Z	http://arxiv.org/abs/2303.10439v2	Stop words, which are considered non-predictive, are often eliminated in natural language processing tasks. However, the definition of uninformative vocabulary is vague, so most algorithms use general knowledge-based stop lists to remove stop words. There is an ongoing debate among academics about the usefulness of stop word elimination, especially in domain-specific settings. In this work, we investigate the usefulness of stop word removal in a software engineering context. To do this, we replicate and experiment with three software engineering research tools from related work. Additionally, we construct a corpus of software engineering domain-related text from 10,000 Stack Overflow questions and identify 200 domain-specific stop words using traditional information-theoretic methods. Our results show that the use of domain-specific stop words significantly improved the performance of research tools compared to the use of a general stop list and that 17 out of 19 evaluation measures showed better performance.   Online appendix: https://zenodo.org/record/7865748	Arxiv	0	['Chetan Arora', 'Christoph Treude']
216	AIBugHunter: A Practical Tool for Predicting, Classifying and Repairing Software Vulnerabilities	Michael Fu	2023-05-26T04:21:53Z	http://arxiv.org/abs/2305.16615v1	Many ML-based approaches have been proposed to automatically detect, localize, and repair software vulnerabilities. While ML-based methods are more effective than program analysis-based vulnerability analysis tools, few have been integrated into modern IDEs, hindering practical adoption. To bridge this critical gap, we propose AIBugHunter, a novel ML-based software vulnerability analysis tool for C/C++ languages that is integrated into Visual Studio Code. AIBugHunter helps software developers to achieve real-time vulnerability detection, explanation, and repairs during programming. In particular, AIBugHunter scans through developers' source code to (1) locate vulnerabilities, (2) identify vulnerability types, (3) estimate vulnerability severity, and (4) suggest vulnerability repairs. In this article, we propose a novel multi-objective optimization (MOO)-based vulnerability classification approach and a transformer-based estimation approach to help AIBugHunter accurately identify vulnerability types and estimate severity. Our empirical experiments on a large dataset consisting of 188K+ C/C++ functions confirm that our proposed approaches are more accurate than other state-of-the-art baseline methods for vulnerability classification and estimation. Furthermore, we conduct qualitative evaluations including a survey study and a user study to obtain software practitioners' perceptions of our AIBugHunter tool and assess the impact that AIBugHunter may have on developers' productivity in security aspects. Our survey study shows that our AIBugHunter is perceived as useful where 90% of the participants consider adopting our AIBugHunter. Last but not least, our user study shows that our AIBugHunter could possibly enhance developers' productivity in combating cybersecurity issues during software development.	Arxiv	0	['Chakkrit Tantithamthavorn', 'Trung Le', 'Yuki Kume', 'Van Nguyen', 'Dinh Phung', 'John Grundy']
217	Multilingual Crowd-Based Requirements Engineering Using Large Language Models	Arthur Pilone	2024-08-12T21:40:39Z	http://arxiv.org/abs/2408.06505v1	A central challenge for ensuring the success of software projects is to assure the convergence of developers' and users' views. While the availability of large amounts of user data from social media, app store reviews, and support channels bears many benefits, it still remains unclear how software development teams can effectively use this data. We present an LLM-powered approach called DeeperMatcher that helps agile teams use crowd-based requirements engineering (CrowdRE) in their issue and task management. We are currently implementing a command-line tool that enables developers to match issues with relevant user reviews. We validated our approach on an existing English dataset from a well-known open-source project. Additionally, to check how well DeeperMatcher works for other languages, we conducted a single-case mechanism experiment alongside developers of a local project that has issues and user feedback in Brazilian Portuguese. Our preliminary analysis indicates that the accuracy of our approach is highly dependent on the text embedding method used. We discuss further refinements needed for reliable crowd-based requirements engineering with multilingual support.	Arxiv	0	['Paulo Meirelles', 'Fabio Kon', 'Walid Maalej']
218	The Second Round: Diverse Paths Towards Software Engineering	Sonja Hyrynsalmi	2024-02-27T08:31:12Z	http://arxiv.org/abs/2402.17306v1	In the extant literature, there has been discussion on the drivers and motivations of minorities to enter the software industry. For example, universities have invested in more diverse imagery for years to attract a more diverse pool of students. However, in our research, we consider whether we understand why students choose their current major and how they did in the beginning decided to apply to study software engineering. We were also interested in learning if there could be some signs that would help us in marketing to get more women into tech. We approached the topic via an online survey (N = 78) sent to the university students of software engineering in Finland. Our results show that, on average, women apply later to software engineering studies than men, with statistically significant differences between genders. Additionally, we found that marketing actions have different impacts based on gender: personal guidance in live events or platforms is most influential for women, whereas teachers and social media have a more significant impact on men. The results also indicate two main paths into the field: the traditional linear educational pathway and the adult career change pathway, each significantly varying by gender	Arxiv	0	['Ella Peltonen', 'Fanny Vainionp√§√§', 'Sami Hyrynsalmi']
219	Case Survey Studies in Software Engineering Research	Jorge Melegati	2020-07-27T14:18:59Z	http://arxiv.org/abs/2007.13592v1	Background: Given the social aspects of Software Engineering (SE), in the last twenty years, researchers from the field started using research methods common in social sciences such as case study, ethnography, and grounded theory. More recently, case survey, another imported research method, has seen its increasing use in SE studies. It is based on existing case studies reported in the literature and intends to harness the generalizability of survey and the depth of case study. However, little is known on how case survey has been applied in SE research, let alone guidelines on how to employ it properly. Aims: This article aims to provide a better understanding of how case survey has been applied in Software Engineering research. Method: To address this knowledge gap, we performed a systematic mapping study and analyzed 12 Software Engineering studies that used the case survey method. Results: Our findings show that these studies presented a heterogeneous understanding of the approach ranging from secondary studies to primary inquiries focused on a large number of instances of a research phenomenon. They have not applied the case survey method consistently as defined in the seminal methodological papers. Conclusions: We conclude that a set of clearly defined guidelines are needed on how to use case survey in SE research, to ensure the quality of the studies employing this approach and to provide a set of clearly defined criteria to evaluate such work.	Arxiv	0	['Xiaofeng Wang']
220	Software Engineering Challenges of Deep Learning	Anders Arpteg	2018-10-29T10:05:37Z	http://arxiv.org/abs/1810.12034v1	Surprisingly promising results have been achieved by deep learning (DL) systems in recent years. Many of these achievements have been reached in academic settings, or by large technology companies with highly skilled research groups and advanced supporting infrastructure. For companies without large research groups or advanced infrastructure, building high-quality production-ready systems with DL components has proven challenging. There is a clear lack of well-functioning tools and best practices for building DL systems. It is the goal of this research to identify what the main challenges are, by applying an interpretive research approach in close collaboration with companies of varying size and type.   A set of seven projects have been selected to describe the potential with this new technology and to identify associated main challenges. A set of 12 main challenges has been identified and categorized into the three areas of development, production, and organizational challenges. Furthermore, a mapping between the challenges and the projects is defined, together with selected motivating descriptions of how and why the challenges apply to specific projects.   Compared to other areas such as software engineering or database technologies, it is clear that DL is still rather immature and in need of further work to facilitate development of high-quality systems. The challenges identified in this paper can be used to guide future research by the software engineering and DL communities. Together, we could enable a large number of companies to start taking advantage of the high potential of the DL technology.	Arxiv	0	['Bj√∂rn Brinne', 'Luka Crnkovic-Friis', 'Jan Bosch']
221	To get good student ratings should you only teach programming courses? Investigation and implications of student evaluations of teaching in a software engineering context	Antti Knutas	2021-02-15T11:10:10Z	http://arxiv.org/abs/2102.08179v1	Student evaluations of teaching (SET) are commonly used in universities for assessing teaching quality. However, previous literature shows that in software engineering students tend to rate certain topics higher than others: In particular students tend to value programming and software construction over software design, software engineering models and methods, or soft skills. We hypothesize that these biases also play a role in SET responses collected from students. The objective of this study is to investigate how the topic of a software engineering course affects the SET metrics. We accomplish this by performing multilevel regression analysis on SET data collected in a software engineering programme. We analyzed a total of 1295 student evaluations from 46 university courses in a Finnish university. The results of the analysis verifies that the student course evaluations exhibit similar biases as distinguished by previous software engineering education research. The type of the course can predict a higher SET rating. In our dataset, software construction and programming courses received higher SET ratings compared to courses on software engineering processes, models, and methods.	Arxiv	0	['Timo Hynninen', 'Maija Hujala']
222	"""Sampling""' as a Baseline Optimizer for Search-based Software Engineering"	Jianfeng Chen	2016-08-26T22:10:01Z	http://arxiv.org/abs/1608.07617v3	"Increasingly, Software Engineering (SE) researchers use search-based optimization techniques to solve SE problems with multiple conflicting objectives. These techniques often apply CPU-intensive evolutionary algorithms to explore generations of mutations to a population of candidate solutions. An alternative approach, proposed in this paper, is to start with a very large population and sample down to just the better solutions. We call this method ""SWAY"", short for ""the sampling way"". Sway is very simple to implement and, in studies with various software engineering models, this sampling approach was found to be competitive with corresponding state-of-the-art evolutionary algorithms while requiring far less computation cost. Considering the simplicity and effectiveness of Sway, we, therefore, propose this approach as a baseline method for search-based software engineering models, especially for models that are very slow to execute."	Arxiv	0	['Vivek Nair', 'Rahul Krishna', 'Tim Menzies']
223	Quantum Software Engineering: Roadmap and Challenges Ahead	Juan M. Murillo	2024-04-10T08:24:53Z	http://arxiv.org/abs/2404.06825v2	As quantum computers advance, the complexity of the software they can execute increases as well. To ensure this software is efficient, maintainable, reusable, and cost-effective -key qualities of any industry-grade software-mature software engineering practices must be applied throughout its design, development, and operation. However, the significant differences between classical and quantum software make it challenging to directly apply classical software engineering methods to quantum systems. This challenge has led to the emergence of Quantum Software Engineering as a distinct field within the broader software engineering landscape. In this work, a group of active researchers analyse in depth the current state of quantum software engineering research. From this analysis, the key areas of quantum software engineering are identified and explored in order to determine the most relevant open challenges that should be addressed in the next years. These challenges help identify necessary breakthroughs and future research directions for advancing Quantum Software Engineering.	Arxiv	0	['Jose Garcia-Alonso', 'Enrique Moguel', 'Johanna Barzen', 'Frank Leymann', 'Shaukat Ali', 'Tao Yue', 'Paolo Arcaini', 'Ricardo P√©rez Castillo', 'Ignacio Garc√≠a Rodr√≠guez de Guzm√°n', 'Mario Piattini', 'Antonio Ruiz-Cort√©s', 'Antonio Brogi', 'Jianjun Zhao', 'Andriy Miranskyy', 'Manuel Wimmer']
224	Mining Software Repair Models for Reasoning on the Search Space of Automated Program Fixing	Matias Martinez	2013-11-14T08:28:45Z	http://arxiv.org/abs/1311.3414v1	This paper is about understanding the nature of bug fixing by analyzing thousands of bug fix transactions of software repositories. It then places this learned knowledge in the context of automated program repair. We give extensive empirical results on the nature of human bug fixes at a large scale and a fine granularity with abstract syntax tree differencing. We set up mathematical reasoning on the search space of automated repair and the time to navigate through it. By applying our method on 14 repositories of Java software and 89,993 versioning transactions, we show that not all probabilistic repair models are equivalent.	Arxiv	0	['Martin Monperrus']
225	Semi-Automatically Extracting FAQs to Improve Accessibility of Software Development Knowledge	Stefan Hen√ü	2012-03-23T07:13:06Z	http://arxiv.org/abs/1203.5188v1	Frequently asked questions (FAQs) are a popular way to document software development knowledge. As creating such documents is expensive, this paper presents an approach for automatically extracting FAQs from sources of software development discussion, such as mailing lists and Internet forums, by combining techniques of text mining and natural language processing. We apply the approach to popular mailing lists and carry out a survey among software developers to show that it is able to extract high-quality FAQs that may be further improved by experts.	Arxiv	0	['Martin Monperrus', 'Mira Mezini']
226	Designing a Syllabus for a Course on Empirical Software Engineering	Paris Avgeriou	2025-03-14T10:58:29Z	http://arxiv.org/abs/2503.11291v1	Increasingly, courses on Empirical Software Engineering research methods are being offered in higher education institutes across the world, mostly at the M.Sc. and Ph.D. levels. While the need for such courses is evident and in line with modern software engineering curricula, educators designing and implementing such courses have so far been reinventing the wheel; every course is designed from scratch with little to no reuse of ideas or content across the community. Due to the nature of the topic, it is rather difficult to get it right the first time when defining the learning objectives, selecting the material, compiling a reader, and, more importantly, designing relevant and appropriate practical work. This leads to substantial effort (through numerous iterations) and poses risks to the course quality. This chapter attempts to support educators in the first and most crucial step in their course design: creating the syllabus. It does so by consolidating the collective experience of the authors as well as of members of the Empirical Software Engineering community; the latter was mined through two working sessions and an online survey. Specifically, it offers a list of the fundamental building blocks for a syllabus, namely course aims, course topics, and practical assignments. The course topics are also linked to the subsequent chapters of this book, so that readers can dig deeper into those chapters and get support on teaching specific research methods or cross-cutting topics. Finally, we guide educators on how to take these building blocks as a starting point and consider a number of relevant aspects to design a syllabus to meet the needs of their own program, students, and curriculum.	Arxiv	0	['Nauman bin Ali', 'Marcos Kalinowski', 'Daniel Mendez']
227	Efficient and Green Large Language Models for Software Engineering: Literature Review, Vision, and the Road Ahead	Jieke Shi	2024-04-06T09:27:04Z	http://arxiv.org/abs/2404.04566v4	Large Language Models (LLMs) have recently shown remarkable capabilities in various software engineering tasks, spurring the rapid growth of the Large Language Models for Software Engineering (LLM4SE) area. However, limited attention has been paid to developing efficient LLM4SE techniques that demand minimal computational cost, time, and memory resources, as well as green LLM4SE solutions that reduce energy consumption, water usage, and carbon emissions.   This paper aims to redirect the focus of the research community towards the efficiency and greenness of LLM4SE, while also sharing potential research directions to achieve this goal. It commences with a brief overview of the significance of LLM4SE and highlights the need for efficient and green LLM4SE solutions. Subsequently, the paper presents a vision for a future where efficient and green LLM4SE revolutionizes the LLM-based software engineering tool landscape, benefiting various stakeholders, including industry, individual practitioners, and society. The paper then delineates a roadmap for future research, outlining specific research paths and potential solutions for the research community to pursue. While not intended to be a definitive guide, the paper aims to inspire further progress, with the ultimate goal of establishing efficient and green LLM4SE as a central element in the future of software engineering.	Arxiv	0	['Zhou Yang', 'David Lo']
228	A Requirements Engineering Technology for the IoT Software Systems	Danyllo Valente da Silva	2021-03-26T09:41:50Z	http://arxiv.org/abs/2103.14348v1	Contemporary software systems (CSS), such as the internet of things (IoT) based software systems, incorporate new concerns and characteristics inherent to the network, software, hardware, context awareness, interoperability, and others, compared to conventional software systems. In this sense, requirements engineering (RE) plays a fundamental role in ensuring these software systems' correct development looking for the business and end-user needs. Several software technologies supporting RE are available in the literature, but many do not cover all CSS specificities, notably those based on IoT. This research article presents RETIoT (Requirements Engineering Technology for the Internet of Things based software systems), aiming to provide methodological, technical, and tooling support to produce IoT software system requirements document. It is composed of an IoT scenario description technique, a checklist to verify IoT scenarios, construction processes, and templates for IoT software systems. A feasibility study was carried out in IoT system projects to observe its templates and identify improvement opportunities. The results indicate the feasibility of RETIoT templates' when used to capture IoT characteristics. However, further experimental studies represent research opportunities, strengthen confidence in its elements (construction process, techniques, and templates), and capture end-user perception.	Arxiv	0	['Bruno Pedra√ßa de Souza', 'Taisa Guidini Gon√ßalves', 'Guilherme Horta Travassos']
229	Compiler.next: A Search-Based Compiler to Power the AI-Native Future of Software Engineering	Filipe R. Cogo	2025-10-27T21:01:48Z	http://arxiv.org/abs/2510.24799v1	The rapid advancement of AI-assisted software engineering has brought transformative potential to the field of software engineering, but existing tools and paradigms remain limited by cognitive overload, inefficient tool integration, and the narrow capabilities of AI copilots. In response, we propose Compiler.next, a novel search-based compiler designed to enable the seamless evolution of AI-native software systems as part of the emerging Software Engineering 3.0 era. Unlike traditional static compilers, Compiler.next takes human-written intents and automatically generates working software by searching for an optimal solution. This process involves dynamic optimization of cognitive architectures and their constituents (e.g., prompts, foundation model configurations, and system parameters) while finding the optimal trade-off between several objectives, such as accuracy, cost, and latency. This paper outlines the architecture of Compiler.next and positions it as a cornerstone in democratizing software development by lowering the technical barrier for non-experts, enabling scalable, adaptable, and reliable AI-powered software. We present a roadmap to address the core challenges in intent compilation, including developing quality programming constructs, effective search heuristics, reproducibility, and interoperability between compilers. Our vision lays the groundwork for fully automated, search-driven software development, fostering faster innovation and more efficient AI-driven systems.	Arxiv	0	['Gustavo A. Oliva', 'Ahmed E. Hassan']
230	The Future of Software Engineering in an AI-Driven World	Valerio Terragni	2024-06-11T21:46:19Z	http://arxiv.org/abs/2406.07737v1	A paradigm shift is underway in Software Engineering, with AI systems such as LLMs gaining increasing importance for improving software development productivity. This trend is anticipated to persist. In the next five years, we will likely see an increasing symbiotic partnership between human developers and AI. The Software Engineering research community cannot afford to overlook this trend; we must address the key research challenges posed by the integration of AI into the software development process. In this paper, we present our vision of the future of software development in an AI-Driven world and explore the key challenges that our research community should address to realize this vision.	Arxiv	0	['Partha Roop', 'Kelly Blincoe']
231	Status Quo in Requirements Engineering: A Theory and a Global Family of Surveys	Stefan Wagner	2018-05-21T08:57:22Z	http://arxiv.org/abs/1805.07951v4	Requirements Engineering (RE) has established itself as a software engineering discipline during the past decades. While researchers have been investigating the RE discipline with a plethora of empirical studies, attempts to systematically derive an empirically-based theory in context of the RE discipline have just recently been started. However, such a theory is needed if we are to define and motivate guidance in performing high quality RE research and practice. We aim at providing an empirical and valid foundation for a theory of RE, which helps software engineers establish effective and efficient RE processes. We designed a survey instrument and theory that has now been replicated in 10 countries world-wide. We evaluate the propositions of the theory with bootstrapped confidence intervals and derive potential explanations for the propositions. We report on the underlying theory and the full results obtained from the replication studies with participants from 228 organisations. Our results represent a substantial step forward towards developing an empirically-based theory of RE giving insights into current practices with RE processes. The results reveal, for example, that there are no strong differences between organisations in different countries and regions, that interviews, facilitated meetings and prototyping are the most used elicitation techniques, that requirements are often documented textually, that traces between requirements and code or design documents is common, requirements specifications themselves are rarely changed and that requirements engineering (process) improvement endeavours are mostly intrinsically motivated. Our study establishes a theory that can be used as starting point for many further studies for more detailed investigations. Practitioners can use the results as theory-supported guidance on selecting suitable RE methods and techniques.	Arxiv	0	['Daniel M√©ndez Fern√°ndez', 'Michael Felderer', 'Antonio Vetr√≥', 'Marcos Kalinowski', 'Roel Wieringa', 'Dietmar Pfahl', 'Tayana Conte', 'Marie-Therese Christiansson', 'Desmond Greer', 'Casper Lassenius', 'Tomi M√§nnist√∂', 'Maleknaz Nayebi', 'Markku Oivo', 'Birgit Penzenstadler', 'Rafael Prikladnicki', 'Guenther Ruhe', 'Andr√© Schekelmann', 'Sagar Sen', 'Rodrigo Sp√≠nola', 'Ahmed Tuzcu', 'Jose Luis de la Vara', 'Dietmar Winkler']
232	Teaching and Learning Ethnography for Software Engineering Contexts	Yvonne Dittrich	2024-07-05T15:43:02Z	http://arxiv.org/abs/2407.04596v2	Ethnography has become one of the established methods for empirical research on software engineering. Although there is a wide variety of introductory books available, there has been no material targeting software engineering students particularly, until now. In this chapter we provide an introduction to teaching and learning ethnography for faculty teaching ethnography to software engineering graduate students and for the students themselves of such courses.   The contents of the chapter focuses on what we think is the core basic knowledge for newbies to ethnography as a research method. We complement the text with proposals for exercises, tips for teaching, and pitfalls that we and our students have experienced.   The chapter is designed to support part of a course on empirical software engineering and provides pointers and literature for further reading.	Arxiv	0	['Helen Sharp', 'Cleidson de Souza']
233	Deep Learning & Software Engineering: State of Research and Future Directions	Prem Devanbu	2020-09-17T20:46:08Z	http://arxiv.org/abs/2009.08525v1	Given the current transformative potential of research that sits at the intersection of Deep Learning (DL) and Software Engineering (SE), an NSF-sponsored community workshop was conducted in co-location with the 34th IEEE/ACM International Conference on Automated Software Engineering (ASE'19) in San Diego, California. The goal of this workshop was to outline high priority areas for cross-cutting research. While a multitude of exciting directions for future work were identified, this report provides a general summary of the research areas representing the areas of highest priority which were discussed at the workshop. The intent of this report is to serve as a potential roadmap to guide future work that sits at the intersection of SE & DL.	Arxiv	0	['Matthew Dwyer', 'Sebastian Elbaum', 'Michael Lowry', 'Kevin Moran', 'Denys Poshyvanyk', 'Baishakhi Ray', 'Rishabh Singh', 'Xiangyu Zhang']
234	Notes On Writing Effective Empirical Software Engineering Papers: An Opinionated Primer	Roberto Verdecchia	2025-04-17T08:25:01Z	http://arxiv.org/abs/2506.11002v2	While mastered by some, good scientific writing practices within Empirical Software Engineering (ESE) research appear to be seldom discussed and documented. Despite this, these practices are implicit or even explicit evaluation criteria of typical software engineering conferences and journals. In this pragmatic, educational-first document, we want to provide guidance to those who may feel overwhelmed or confused by writing ESE papers, but also those more experienced who still might find an opinionated collection of writing advice useful. The primary audience we had in mind for this paper were our own BSc, MSc, and PhD students, but also students of others. Our documented advice therefore reflects a subjective and personal vision of writing ESE papers. By no means do we claim to be fully objective, generalizable, or representative of the whole discipline. With that being said, writing papers in this way has worked pretty well for us so far. We hope that this guide can at least partially do the same for others.	Arxiv	0	['Justus Bogner']
235	Happiness and the productivity of software engineers	Daniel Graziotin	2019-04-16T13:11:34Z	http://arxiv.org/abs/1904.08239v1	Software companies and startups often follow the idea of flourishing happiness among developers. Perks, playground rooms, free breakfast, remote office options, sports facilities near the companies, company retreats, you name it. The rationale is that happy developers should be more productive and also retained.   But is it the case that happy software engineers are more productive? Moreover, are perks the way to go to make developers happy? Are developers happy at all? What are the consequences of unhappiness among software engineers?   These questions are important to ask both from the perspective of productivity and from the perspective of sustainable software development and well-being in the workplace. Managers, team leaders, as well as team members should be interested in these concerns.   This chapter provides an overview of our studies on the happiness of software developers. You will learn why it is important to make software developers happy, how happy they really are, what makes them unhappy, and what is expected regarding happiness and productivity while developing software.	Arxiv	0	['Fabian Fagerholm']
236	Software Engineering for Millennials, by Millennials	Jocelyn Simmonds	2018-04-05T17:16:59Z	http://arxiv.org/abs/1804.03518v1	"Software engineers need to manage both technical and professional skills in order to be successful. Our university offers a 5.5 year program that mixes computer science, software and computer engineering, where the first two years are mostly math and physics courses. As such, our students' first real teamwork experience is during the introductory SE course, where they modify open source projects in groups of 6-8. However, students have problems working in such large teams, and feel that the course material and project are ""disconnected"". We decided to redesign this course in 2017, trying to achieve a balance between theory and practice, and technical and professional skills, with a maximum course workload of 150 hrs per semester. We share our experience in this paper, discussing the strategies we used to improve teamwork and help students learn new technologies in a more autonomous manner. We also discuss what we learned from the two times we taught the new course."	Arxiv	0	['Ma√≠ra Marques Samary', 'Milenko Tomic', 'Francisco Madrid', 'Constanza Escobar']
237	Towards the Assessment of Stress and Emotional Responses of a Salutogenesis-Enhanced Software Tool Using Psychophysiological Measurements	Jan-Peter Ostberg	2017-01-20T09:53:23Z	http://arxiv.org/abs/1701.05739v2	Software development is intellectual, based on collaboration, and performed in a highly demanding economic market. As such, it is dominated by time pressure, stress, and emotional trauma. While studies of affect are emerging and rising in software engineering research, stress has yet to find its place in the literature despite that it is highly related to affect. In this paper, we study stress coping with the affect-laden framework of Salutogenesis, which is a validated psychological framework for enhancing mental health through a feeling of coherence. We propose a controlled experiment for testing our hypotheses that a static analysis tool enhanced with the Salutogenesis model will bring 1) a higher number of fixed quality issues, 2) reduced cognitive load, 3) reduction of the overall stress, and 4) positive affect induction effects to developers. The experiment will make use of validated physiological measurements of stress as proxied by cortisol and alpha-amylase levels in saliva samples, a psychometrically validated measurement of mood and affect disposition, and stress inductors such as a cognitive load task. Our hypotheses, if empirically supported, will lead to the creation of environments, methods, and tools that alleviate stress among developers while enhancing affect on the job and task performance.	Arxiv	0	['Daniel Graziotin', 'Stefan Wagner', 'Birgit Derntl']
238	Integrating Software Engineering Key Practices into an OOP Massive In-Classroom Course: an Experience Report	Marco Torchiano	2018-04-05T07:25:12Z	http://arxiv.org/abs/1804.01700v1	Programming and software engineering courses in computer science curricula typically focus on both providing theoretical knowledge of programming languages and best-practices, and developing practical development skills. In a massive course - several hundred students - the teachers are not able to adequately attend to the practical part, therefore process automation and incentives to students must be used to drive the students in the right direction. Our goals was to design an automated programming assignment infrastructure capable of supporting massive courses. The infrastructure should encourage students to apply the key software engineering (SE) practices - automated testing, con guration management, and Integrated Development Environment (IDE) - and acquire the basic skills for using the corresponding tools. We selected a few widely adopted development tools used to support the key software engineering practices and mapped them to the basic activities in our exam assignment management process. This experience report describes the results from the past academic year. The infrastructure we built has been used for a full academic year and supported four exam sessions for a total of over a thousand students. The satisfaction level reported by the students is generally high.	Arxiv	0	['Giorgio Bruno']
239	Assured LLM-Based Software Engineering	Nadia Alshahwan	2024-02-06T20:38:46Z	http://arxiv.org/abs/2402.04380v1	In this paper we address the following question: How can we use Large Language Models (LLMs) to improve code independently of a human, while ensuring that the improved code   - does not regress the properties of the original code?   - improves the original in a verifiable and measurable way?   To address this question, we advocate Assured LLM-Based Software Engineering; a generate-and-test approach, inspired by Genetic Improvement. Assured LLMSE applies a series of semantic filters that discard code that fails to meet these twin guarantees. This overcomes the potential problem of LLM's propensity to hallucinate. It allows us to generate code using LLMs, independently of any human. The human plays the role only of final code reviewer, as they would do with code generated by other human engineers.   This paper is an outline of the content of the keynote by Mark Harman at the International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering, Monday 15th April 2024, Lisbon, Portugal.	Arxiv	0	['Mark Harman', 'Inna Harper', 'Alexandru Marginean', 'Shubho Sengupta', 'Eddy Wang']
240	Beyond Code Generation: An Observational Study of ChatGPT Usage in Software Engineering Practice	Ranim Khojah	2024-04-23T10:34:16Z	http://arxiv.org/abs/2404.14901v2	Large Language Models (LLMs) are frequently discussed in academia and the general public as support tools for virtually any use case that relies on the production of text, including software engineering. Currently there is much debate, but little empirical evidence, regarding the practical usefulness of LLM-based tools such as ChatGPT for engineers in industry. We conduct an observational study of 24 professional software engineers who have been using ChatGPT over a period of one week in their jobs, and qualitatively analyse their dialogues with the chatbot as well as their overall experience (as captured by an exit survey). We find that, rather than expecting ChatGPT to generate ready-to-use software artifacts (e.g., code), practitioners more often use ChatGPT to receive guidance on how to solve their tasks or learn about a topic in more abstract terms. We also propose a theoretical framework for how (i) purpose of the interaction, (ii) internal factors (e.g., the user's personality), and (iii) external factors (e.g., company policy) together shape the experience (in terms of perceived usefulness and trust). We envision that our framework can be used by future research to further the academic discussion on LLM usage by software engineering practitioners, and to serve as a reference point for the design of future empirical LLM research in this domain.	Arxiv	0	['Mazen Mohamad', 'Philipp Leitner', 'Francisco Gomes de Oliveira Neto']
241	Benchmarking as Empirical Standard in Software Engineering Research	Wilhelm Hasselbring	2021-05-01T14:54:56Z	http://arxiv.org/abs/2105.00272v1	In empirical software engineering, benchmarks can be used for comparing different methods, techniques and tools. However, the recent ACM SIGSOFT Empirical Standards for Software Engineering Research do not include an explicit checklist for benchmarking. In this paper, we discuss benchmarks for software performance and scalability evaluation as example research areas in software engineering, relate benchmarks to some other empirical research methods, and discuss the requirements on benchmarks that may constitute the basis for a checklist of a benchmarking standard for empirical software engineering research.	Arxiv	0	[]
242	Supporting Defect Causal Analysis in Practice with Cross-Company Data on Causes of Requirements Engineering Problems	Marcos Kalinowski	2017-02-13T16:14:30Z	http://arxiv.org/abs/1702.03851v1	[Context] Defect Causal Analysis (DCA) represents an efficient practice to improve software processes. While knowledge on cause-effect relations is helpful to support DCA, collecting cause-effect data may require significant effort and time. [Goal] We propose and evaluate a new DCA approach that uses cross-company data to support the practical application of DCA. [Method] We collected cross-company data on causes of requirements engineering problems from 74 Brazilian organizations and built a Bayesian network. Our DCA approach uses the diagnostic inference of the Bayesian network to support DCA sessions. We evaluated our approach by applying a model for technology transfer to industry and conducted three consecutive evaluations: (i) in academia, (ii) with industry representatives of the Fraunhofer Project Center at UFBA, and (iii) in an industrial case study at the Brazilian National Development Bank (BNDES). [Results] We received positive feedback in all three evaluations and the cross-company data was considered helpful for determining main causes. [Conclusions] Our results strengthen our confidence in that supporting DCA with cross-company data is promising and should be further investigated.	Arxiv	0	['Pablo Curty', 'Aline Paes', 'Alexandre Ferreira', 'Rodrigo Sp√≠nola', 'Daniel M√©ndez Fern√°ndez', 'Michael Felderer', 'Stefan Wagner']
243	Temporal Discounting in Software Engineering: A Replication Study	Fabian Fagerholm	2019-06-26T13:13:07Z	http://arxiv.org/abs/1906.11072v1	Background: Many decisions made in Software Engineering practices are intertemporal choices: trade-offs in time between closer options with potential short-term benefit and future options with potential long-term benefit. However, how software professionals make intertemporal decisions is not well understood.   Aim: This paper investigates how shifting time frames influence preferences in software projects in relation to purposefully selected background factors.   Method: We investigate temporal discounting by replicating a questionnaire-based observational study. The replication uses a changed-population and -experimenter design to increase the internal and external validity of the original results.   Results: The results of this study confirm the occurrence of temporal discounting in samples of both professional and student participants from different countries and demonstrate strong variance in discounting between study participants. We found that professional experience influenced discounting. Participants with broader professional experience exhibited less discounting than those with narrower experience.   Conclusions: The results provide strong empirical support for the relevance and importance of temporal discounting in SE and the urgency of targeted interdisciplinary research to explore the underlying mechanisms and their theoretical and practical implications. The results suggest that technical debt management could be improved by increasing the breadth of experience available for critical decisions with long-term impact. In addition, the present study provides a methodological basis for replicating temporal discounting studies in software engineering.	Arxiv	0	['Christoph Becker', 'Alexander Chatzigeorgiou', 'Stefanie Betz', 'Leticia Duboc', 'Birgit Penzenstadler', 'Rahul Mohanani', 'Colin Venters']
244	Not real or too soft? On the challenges of publishing interdisciplinary software engineering research	Sonja M. Hyrynsalmi	2025-01-11T12:18:46Z	http://arxiv.org/abs/2501.06523v1	The discipline of software engineering (SE) combines social and technological dimensions. It is an interdisciplinary research field. However, interdisciplinary research submitted to software engineering venues may not receive the same level of recognition as more traditional or technical topics such as software testing. For this paper, we conducted an online survey of 73 SE researchers and used a mixed-method data analysis approach to investigate their challenges and recommendations when publishing interdisciplinary research in SE. We found that the challenges of publishing interdisciplinary research in SE can be divided into topic-related and reviewing-related challenges. Furthermore, while our initial focus was on publishing interdisciplinary research, the impact of current reviewing practices on marginalized groups emerged from our data, as we found that marginalized groups are more likely to receive negative feedback. In addition, we found that experienced researchers are less likely to change their research direction due to feedback they receive. To address the identified challenges, our participants emphasize the importance of highlighting the impact and value of interdisciplinary work for SE, collaborating with experienced researchers, and establishing clearer submission guidelines and new interdisciplinary SE publication venues. Our findings contribute to the understanding of the current state of the SE research community and how we could better support interdisciplinary research in our field.	Arxiv	0	['Grischa Liebel', 'Ronnie de Souza Santos', 'Sebastian Baltes']
245	The Potential of Citizen Platforms for Requirements Engineering of Large Socio-Technical Software Systems	Jukka Ruohonen	2024-10-04T07:18:26Z	http://arxiv.org/abs/2410.03195v2	Participatory citizen platforms are innovative solutions to digitally better engage citizens in policy-making and deliberative democracy in general. Although these platforms have been used also in an engineering context, thus far, there is no existing work for connecting the platforms to requirements engineering. The present paper fills this notable gap. In addition to discussing the platforms in conjunction with requirements engineering, the paper elaborates potential advantages and disadvantages, thus paving the way for a future pilot study in a software engineering context. With these engineering tenets, the paper also contributes to the research of large socio-technical software systems in a public sector context, including their implementation and governance.	Arxiv	0	['Kalle Hjerppe']
246	Qualifying Software Engineers Undergraduates in DevOps -- Challenges of Introducing Technical and Non-technical Concepts in a Project-oriented Course	Isaque Alves	2021-02-12T18:05:09Z	http://arxiv.org/abs/2102.06662v1	The constant changes in the software industry, practices, and methodologies impose challenges to teaching and learning current software engineering concepts and skills. DevOps is particularly challenging because it covers technical concepts, such as pipeline automation, and non-technical ones, such as team roles and project management. The present study investigates a course setup to introduce these concepts to software engineering undergraduates. We designed the course by employing coding to associate DevOps concepts to Agile, Lean, and Open source practices and tools. We present the main aspects of this project-oriented DevOps course, with 240 students enrolled in it since its first offering in 2016. We conducted an empirical study, with both a quantitative and qualitative analysis, to evaluate this project-oriented course setup. We collected the data from the projects repository and students perceptions from a questionnaire. We mined 148 repositories (corresponding to 72 projects) and obtained 86 valid responses to the questionnaire. We also mapped the concepts which are more challenging to students learn from experience. The results evidence that first-hand experience facilitates the comprehension of DevOps concepts and enriches classes discussions. We present a set of lessons learned, which may help professors better design and conduct project-oriented courses to cover DevOps concepts.	Arxiv	0	['Carla Rocha']
247	Requirements are All You Need: The Final Frontier for End-User Software Engineering	Diana Robinson	2024-05-22T14:57:21Z	http://arxiv.org/abs/2405.13708v1	What if end users could own the software development lifecycle from conception to deployment using only requirements expressed in language, images, video or audio? We explore this idea, building on the capabilities that generative Artificial Intelligence brings to software generation and maintenance techniques. How could designing software in this way better serve end users? What are the implications of this process for the future of end-user software engineering and the software development lifecycle? We discuss the research needed to bridge the gap between where we are today and these imagined systems of the future.	Arxiv	0	['Christian Cabrera', 'Andrew D. Gordon', 'Neil D. Lawrence', 'Lars Mennen']
248	Prompt-with-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering	Ziyou Li	2025-09-21T14:24:37Z	http://arxiv.org/abs/2509.17096v1	Large Language Models are transforming software engineering, yet prompt management in practice remains ad hoc, hindering reliability, reuse, and integration into industrial workflows. We present Prompt-with-Me, a practical solution for structured prompt management embedded directly in the development environment. The system automatically classifies prompts using a four-dimensional taxonomy encompassing intent, author role, software development lifecycle stage, and prompt type. To enhance prompt reuse and quality, Prompt-with-Me suggests language refinements, masks sensitive information, and extracts reusable templates from a developer's prompt library. Our taxonomy study of 1108 real-world prompts demonstrates that modern LLMs can accurately classify software engineering prompts. Furthermore, our user study with 11 participants shows strong developer acceptance, with high usability (Mean SUS=73), low cognitive load (Mean NASA-TLX=21), and reported gains in prompt quality and efficiency through reduced repetitive effort. Lastly, we offer actionable insights for building the next generation of prompt management and maintenance tools for software engineering workflows.	Arxiv	0	['Agnia Sergeyuk', 'Maliheh Izadi']
249	Understanding Peer Review of Software Engineering Papers	Neil A. Ernst	2020-09-02T17:31:45Z	http://arxiv.org/abs/2009.01209v2	Peer review is a key activity intended to preserve the quality and integrity of scientific publications. However, in practice it is far from perfect.   We aim at understanding how reviewers, including those who have won awards for reviewing, perform their reviews of software engineering papers to identify both what makes a good reviewing approach and what makes a good paper.   We first conducted a series of in-person interviews with well-respected reviewers in the software engineering field. Then, we used the results of those interviews to develop a questionnaire used in an online survey and sent out to reviewers from well-respected venues covering a number of software engineering disciplines, some of whom had won awards for their reviewing efforts.   We analyzed the responses from the interviews and from 175 reviewers who completed the online survey (including both reviewers who had won awards and those who had not). We report on several descriptive results, including: 45% of award-winners are reviewing 20+ conference papers a year, while 28% of non-award winners conduct that many. 88% of reviewers are taking more than two hours on journal reviews. We also report on qualitative results. To write a good review, the important criteria were it should be factual and helpful, ranked above others such as being detailed or kind. The most important features of papers that result in positive reviews are clear and supported validation, an interesting problem, and novelty. Conversely, negative reviews tend to result from papers that have a mismatch between the method and the claims and from those with overly grandiose claims.   The main recommendation for authors is to make the contribution of the work very clear in their paper. In addition, reviewers viewed data availability and its consistency as being important.	Arxiv	0	['Jeffrey C. Carver', 'Daniel Mendez', 'Marco Torchiano']
250	The Evolving Landscape of Software Performance Engineering	Gunnar Kudrjavets	2022-05-05T22:17:58Z	http://arxiv.org/abs/2205.02950v1	Satisfactory software performance is essential for the adoption and the success of a product. In organizations that follow traditional software development models (e.g., waterfall), Software Performance Engineering (SPE) involves time-consuming experimental modeling and performance testing outside the actual production environment. Such existing SPE methods, however, are not optimized for environments utilizing Continuous Integration (CI) and Continuous Delivery (CD) that result in high frequency and high volume of code changes. We present a summary of lessons learned and propose improvements to the SPE process in the context of CI/CD. Our findings are based on SPE work on products A and B conducted over 5 years at an online services company X. We find that (a) SPE has mainly become a post hoc activity based on data from the production environment, (b) successful application of SPE techniques require frequent re-evaluation of priorities, and (c) engineers working on SPE require a broader skill set than one traditionally possessed by engineers working on performance.	Arxiv	0	['Jeff Thomas', 'Nachiappan Nagappan']
251	The Role of Empathy in Software Engineering -- A Socio-Technical Grounded Theory	Hashini Gunatilake	2025-04-17T15:13:18Z	http://arxiv.org/abs/2504.13002v2	Empathy, defined as the ability to understand and share others' perspectives and emotions, is essential in software engineering (SE), where developers often collaborate with diverse stakeholders. It is also considered as a vital competency in many professional fields such as medicine, healthcare, nursing, animal science, education, marketing, and project management. Despite its importance, empathy remains under-researched in SE. To further explore this, we conducted a socio-technical grounded theory (STGT) study through in-depth semi-structured interviews with 22 software developers and stakeholders. Our study explored the role of empathy in SE and how SE activities and processes can be improved by considering empathy. Through applying the systematic steps of STGT data analysis and theory development, we developed a theory that explains the role of empathy in SE. Our theory details the contexts in which empathy arises, the conditions that shape it, the causes and consequences of its presence and absence. We also identified contingencies for enhancing empathy or overcoming barriers to its expression. Our findings provide practical implications for SE practitioners and researchers, offering a deeper understanding of how to effectively integrate empathy into SE processes.	Arxiv	0	['John Grundy', 'Rashina Hoda', 'Ingo Mueller']
252	The Influence of Human Aspects on Requirements Engineering-related Activities: Software Practitioners Perspective	Dulaji Hidellaarachchi	2021-09-16T11:01:02Z	http://arxiv.org/abs/2109.07868v3	"Requirements Engineering (RE)-related activities require high collaboration between various roles in software engineering (SE), such as requirements engineers, stakeholders, developers, etc. Their demographics, views, understanding of technologies, working styles, communication and collaboration capabilities make RE highly human dependent. Identifying how ""human aspects"" such as motivation, domain knowledge, communication skills, personality, emotions, culture, etc. might impact RE-related activities would help us improve the RE and SE in general. This study aims to better understand current industry perspectives on the influence of human aspects on RE-related activities, specifically focusing on motivation and personality by targeting software practitioners involved in RE-related activities. Our findings indicate that software practitioners consider motivation, domain knowledge, attitude, communication skills and personality as highly important human aspects when involved in RE-related activities. A set of factors were identified as software practitioners motivational factors when involved in RE-related activities and identified important personality characteristics to have when involved in RE. We also identified factors that made individuals less effective when involved in RE-related activities and obtained an initial idea on measuring individuals performance when involved in RE. The findings from our study suggest various areas needing more investigation, and we summarise a set of key recommendations for further research."	Arxiv	0	['John Grundy', 'Rashina Hoda', 'Ingo Mueller']
253	Adoption and Effects of Software Engineering Best Practices in Machine Learning	Alex Serban	2020-07-28T11:20:09Z	http://arxiv.org/abs/2007.14130v2	The increasing reliance on applications with machine learning (ML) components calls for mature engineering techniques that ensure these are built in a robust and future-proof manner. We aim to empirically determine the state of the art in how teams develop, deploy and maintain software with ML components. We mined both academic and grey literature and identified 29 engineering best practices for ML applications. We conducted a survey among 313 practitioners to determine the degree of adoption for these practices and to validate their perceived effects. Using the survey responses, we quantified practice adoption, differentiated along demographic characteristics, such as geography or team size. We also tested correlations and investigated linear and non-linear relationships between practices and their perceived effect using various statistical models. Our findings indicate, for example, that larger teams tend to adopt more practices, and that traditional software engineering practices tend to have lower adoption than ML specific practices. Also, the statistical models can accurately predict perceived effects such as agility, software quality and traceability, from the degree of adoption for specific sets of practices. Combining practice adoption rates with practice importance, as revealed by statistical models, we identify practices that are important but have low adoption, as well as practices that are widely adopted but are less important for the effects we studied. Overall, our survey and the analysis of responses received provide a quantitative basis for assessment and step-wise improvement of practice adoption by ML teams.	Arxiv	0	['Koen van der Blom', 'Holger Hoos', 'Joost Visser']
254	Leveraging Generative AI: Improving Software Metadata Classification with Generated Code-Comment Pairs	Samah Syed	2023-10-14T12:09:43Z	http://arxiv.org/abs/2311.03365v1	"In software development, code comments play a crucial role in enhancing code comprehension and collaboration. This research paper addresses the challenge of objectively classifying code comments as ""Useful"" or ""Not Useful."" We propose a novel solution that harnesses contextualized embeddings, particularly BERT, to automate this classification process. We address this task by incorporating generated code and comment pairs. The initial dataset comprised 9048 pairs of code and comments written in C, labeled as either Useful or Not Useful. To augment this dataset, we sourced an additional 739 lines of code-comment pairs and generated labels using a Large Language Model Architecture, specifically BERT. The primary objective was to build classification models that can effectively differentiate between useful and not useful code comments. Various machine learning algorithms were employed, including Logistic Regression, Decision Tree, K-Nearest Neighbors (KNN), Support Vector Machine (SVM), Gradient Boosting, Random Forest, and a Neural Network. Each algorithm was evaluated using precision, recall, and F1-score metrics, both with the original seed dataset and the augmented dataset. This study showcases the potential of generative AI for enhancing binary code comment quality classification models, providing valuable insights for software developers and researchers in the field of natural language processing and software engineering."	Arxiv	0	['Angel Deborah S']
255	An RSE Group Model: Operational and Organizational Approaches From Princeton University's Central Research Software Engineering Group	Ian A. Cosden	2022-10-28T16:51:31Z	http://arxiv.org/abs/2210.16261v1	The Princeton Research Software Engineering Group has grown rapidly since its inception in late 2016. The group, housed in the central Research Computing Department, comprised of professional Research Software Engineers (RSEs), works directly with researchers to create high quality research software to enable new scientific advances. As the group has matured so has the need for formalizing operational details and procedures. The RSE group uses an RSE partnership model, where Research Software Engineers work long-term with a designated academic department, institute, center, consortium, or individual principal investigator (PI). This article describes the operation of the central Princeton RSE group including funding, partner & project selection, and best practices for defining expectations for a successful partnership with researchers.	Arxiv	0	[]
256	Combining Design Thinking and Software Requirements Engineering to create Human-centered Software-intensive Systems	Jennifer Hehn	2021-12-10T14:01:57Z	http://arxiv.org/abs/2112.05549v1	Effective Requirements Engineering is a crucial activity in softwareintensive development projects. The human-centric working mode of Design Thinking is considered a powerful way to complement such activities when designing innovative systems. Research has already made great strides to illustrate the benefits of using Design Thinking for Requirements Engineering. However, it has remained mostly unclear how to actually realize a combination of both. In this chapter, we contribute an artifact-based model that integrates Design Thinking and Requirements Engineering for innovative software-intensive systems. Drawing from our research and project experiences, we suggest three strategies for tailoring and integrating Design Thinking and Requirements Engineering with complementary synergies.	Arxiv	0	['Daniel Mendez']
257	Systematic Literature Review of Gender and Software Engineering in Asia	Hironori Washizaki	2022-11-16T14:58:01Z	http://arxiv.org/abs/2211.09554v1	It is essential to discuss the role, difficulties, and opportunities concerning people of different gender in the field of software engineering research, education, and industry. Although some literature reviews address software engineering and gender, it is still unclear how research and practices in Asia exist for handling gender aspects in software development and engineering. We conducted a systematic literature review to grasp the comprehensive view of gender research and practices in Asia. We analyzed the 32 identified papers concerning countries and publication years among 463 publications. Researchers and practitioners from various organizations actively work on gender research and practices in some countries, including China, India, and Turkey. We identified topics and classified them into seven categories varying from personal mental health and team building to organization. Future research directions include investigating the synergy between (regional) gender aspects and cultural concerns and considering possible contributions and dependency among different topics to have a solid foundation for accelerating further research and getting actionable practices.	Arxiv	0	[]
258	Bayesian propensity score matching in automotive embedded software engineering	Yuchu Liu	2021-09-26T11:27:19Z	http://arxiv.org/abs/2109.12563v1	Randomised field experiments, such as A/B testing, have long been the gold standard for evaluating the value that new software brings to customers. However, running randomised field experiments is not always desired, possible or even ethical in the development of automotive embedded software. In the face of such restrictions, we propose the use of the Bayesian propensity score matching technique for causal inference of observational studies in the automotive domain. In this paper, we present a method based on the Bayesian propensity score matching framework, applied in the unique setting of automotive software engineering. This method is used to generate balanced control and treatment groups from an observational online evaluation and estimate causal treatment effects from the software changes, even with limited samples in the treatment group. We exemplify the method with a proof-of-concept in the automotive domain. In the example, we have a larger control ($N_c=1100$) fleet of cars using the current software and a small treatment fleet ($N_t=38$), in which we introduce a new software variant. We demonstrate a scenario that shipping of a new software to all users is restricted, as a result, a fully randomised experiment could not be conducted. Therefore, we utilised the Bayesian propensity score matching method with 14 observed covariates as inputs. The results show more balanced groups, suitable for estimating causal treatment effects from the collected observational data. We describe the method in detail and share our configuration. Furthermore, we discuss how can such a method be used for online evaluation of new software utilising small groups of samples.	Arxiv	0	['David Issa Mattos', 'Jan Bosch', 'Helena Holmstr√∂m Olsson', 'Jonn Lantz']
259	In Quest for Proper Mediums for Technology Transfer in Software Engineering	F. Grigoleit	2016-12-05T15:04:14Z	http://arxiv.org/abs/1612.01385v1	Successful transfer of the results of research projects into practice is of great interest to all project participants. It can be assumed that different transfer mediums fulfill technology transfer (TT) with different levels of success and that they are impaired by different kinds of barriers. The goal of this study is to gain a better understanding about the different mediums used for TT in software engineering, and to identify barriers weakening the success of the application of such mediums. We conducted an exploratory study implemented by a survey in the context of a German research project with a broad range of used mediums. The main reported barriers were low expectations of usefulness, no awareness of existence, lack of resources, or inadequateness in terms of outdated material or being in an immature state. We interpreted our results as symptoms of a lack of a dissemination plan in the project. Further work will be needed to explore the implications for the transfer of research results (knowledge and techniques) to practice.	Arxiv	0	['A. Vetr√≤', 'D. M√©ndez Fern√°ndez', 'W. B√∂hm', 'P. Diebold']
260	More than Code: Contributions in Scrum Software Engineering Teams	Frederike Ramin	2020-07-16T10:18:35Z	http://arxiv.org/abs/2007.08237v1	Motivated and competent team members are a vital part of Agile Software development and make or break any project's success. Motivation is fostered by continuous progress and recognition of efforts. These concepts are founding pillars of the Scrum methodology, which focuses on self-organizing teams. The types of contributions Scrum development team members make to a project's progress are not only technical. However, a comprehensive model comprising the varied contributions in modern software engineering teams is not yet established. We propose a model that incorporates contributions of all Scrum roles, explicitly including those which are not directly related to project artifacts. It improves the visibility of performed tasks, acts as a starting point for team retrospection, and serves as a foundation for discussion in the research community.	Arxiv	0	['Christoph Matthies', 'Ralf Teusner']
261	Requirements engineering current practice and capability in small and medium software development enterprises in New Zealand	Alison Talbot	2014-07-23T03:42:33Z	http://arxiv.org/abs/1407.6102v1	"This paper presents research on current industry practices with respect to requirements engineering as implemented within software development companies in New Zealand. A survey instrument is designed and deployed. The results are analysed and compared against what is internationally considered ""best practice"" and previous New Zealand and Australian studies. An attempt is made to assess the requirements engineering capability of New Zealand companies using both formal and informal frameworks."	Arxiv	0	['Andy M. Connor']
262	"""Software is the easy part of Software Engineering"" -- Lessons and Experiences from A Large-Scale, Multi-Team Capstone Course"	Ze Shi Li	2023-02-10T22:33:35Z	http://arxiv.org/abs/2302.05536v1	Capstone courses in undergraduate software engineering are a critical final milestone for students. These courses allow students to create a software solution and demonstrate the knowledge they accumulated in their degrees. However, a typical capstone project team is small containing no more than 5 students and function independently from other teams. To better reflect real-world software development and meet industry demands, we introduce in this paper our novel capstone course. Each student was assigned to a large-scale, multi-team (i.e., company) of up to 20 students to collaboratively build software. Students placed in a company gained first-hand experiences with respect to multi-team coordination, integration, communication, agile, and teamwork to build a microservices based project. Furthermore, each company was required to implement plug-and-play so that their services would be compatible with another company, thereby sharing common APIs. Through developing the product in autonomous sub-teams, the students enhanced not only their technical abilities but also their soft skills such as communication and coordination. More importantly, experiencing the challenges that arose from the multi-team project trained students to realize the pitfalls and advantages of organizational culture. Among many lessons learned from this course experience, students learned the critical importance of building team trust. We provide detailed information about our course structure, lessons learned, and propose recommendations for other universities and programs. Our work concerns educators interested in launching similar capstone projects so that students in other institutions can reap the benefits of large-scale, multi-team development	Arxiv	0	['Nowshin Nawar Arony', 'Kezia Devathasan', 'Daniela Damian']
263	Research Software Engineers: Career Entry Points and Training Gaps	Ian A. Cosden	2022-10-09T14:40:32Z	http://arxiv.org/abs/2210.04275v2	As software has become more essential to research across disciplines, and as the recognition of this fact has grown, the importance of professionalizing the development and maintenance of this software has also increased. The community of software professionals who work on this software have come together under the title Research Software Engineer (RSE) over the last decade. This has led to the formalization of RSE roles and organized RSE groups in universities, national labs, and industry. This, in turn, has created the need to understand how RSEs come into this profession and into these groups, how to further promote this career path to potential members, as well as the need to understand what training gaps need to be filled for RSEs coming from different entry points. We have categorized three main classifications of entry paths into the RSE profession and identified key elements, both advantages and disadvantages, that should be acknowledged and addressed by the broader research community in order to attract and retain a talented and diverse pool of future RSEs.	Arxiv	0	['Kenton McHenry', 'Daniel S. Katz']
264	Flipping a Graduate-Level Software Engineering Foundations Course	Hakan Erdogmus	2017-02-23T02:25:15Z	http://arxiv.org/abs/1702.07069v1	Creating a graduate-level software engineering breadth course is challenging. The scope is wide. Students prefer hands-on work over theory. Industry increasingly values soft skills. Changing software technology requires the syllabus to be technology-agnostic, yet abstracting away technology compromises realism. Instructors must balance scope with depth of learning. At Carnegie Mellon University, we designed a flipped-classroom course that tackles these tradeoffs. The course has been offered since Fall 2014 in the Silicon Valley campus. In this paper, we describe the course's key features and summarize our experiences and lessons learned while designing, teaching, and maintaining it. We found that the pure flipped-classroom format was not optimal in ensuring sufficient transfer of knowledge, especially in remote settings. We initially underestimated teaching assistantship resources. We gradually complemented video lectures and hands-on live sessions with additional live components: easily replaceable recitations that focus on current technology and mini lectures that address application of theory and common wisdom. We also provided the students with more opportunities to share their successes and experiments with their peers. We achieved scalability by increasing the number of teaching assistants, paying attention to teaching assistant recruitment, and fostering a culture of mentoring among the teaching team.	Arxiv	0	['Cecile Peraire']
265	Measuring affective states from technical debt: A psychoempirical software engineering experiment	Jesper Olsson	2020-09-22T16:30:19Z	http://arxiv.org/abs/2009.10660v3	Software engineering is a human activity. Despite this, human aspects are under-represented in technical debt research, perhaps because they are challenging to evaluate.   This study's objective was to investigate the relationship between technical debt and affective states (feelings, emotions, and moods) from software practitioners. Forty participants (N = 40) from twelve companies took part in a mixed-methods approach, consisting of a repeated-measures (r = 5) experiment (n = 200), a survey, and semi-structured interviews.   The statistical analysis shows that different design smells (strong indicators of technical debt) negatively or positively impact affective states. From the qualitative data, it is clear that technical debt activates a substantial portion of the emotional spectrum and is psychologically taxing. Further, the practitioners' reactions to technical debt appear to fall in different levels of maturity.   We argue that human aspects in technical debt are important factors to consider, as they may result in, e.g., procrastination, apprehension, and burnout.	Arxiv	0	['Erik Risfelt', 'Terese Besker', 'Antonio Martini', 'Richard Torkar']
266	An Introduction to Software Engineering and Fault Tolerance	Patrizio Pelliccione	2010-11-06T10:27:01Z	http://arxiv.org/abs/1011.1551v1	This book consists of the chapters describing novel approaches to integrating fault tolerance into software development process. They cover a wide range of topics focusing on fault tolerance during the different phases of the software development, software engineering techniques for verification and validation of fault tolerance means, and languages for supporting fault tolerance specification and implementation. Accordingly, the book is structured into the following three parts: Part A: Fault tolerance engineering: from requirements to code; Part B: Verification and validation of fault tolerant systems; Part C: Languages and Tools for engineering fault tolerant systems.	Arxiv	0	['Henry Muccini', 'Nicolas Guelfi', 'Alexander Romanovsky']
267	Insights Towards Better Case Study Reporting in Software Engineering	Sergio Rico	2024-02-13T12:29:26Z	http://arxiv.org/abs/2402.08411v1	Case studies are a popular and noteworthy type of research study in software engineering, offering significant potential to impact industry practices by investigating phenomena in their natural contexts. This potential to reach a broad audience beyond the academic community is often undermined by deficiencies in reporting, particularly in the context description, study classification, generalizability, and the handling of validity threats. This paper presents a reflective analysis aiming to share insights that can enhance the quality and impact of case study reporting.   We emphasize the need to follow established guidelines, accurate classification, and detailed context descriptions in case studies. Additionally, particular focus is placed on articulating generalizable findings and thoroughly discussing generalizability threats. We aim to encourage researchers to adopt more rigorous and communicative strategies, ensuring that case studies are methodologically sound, resonate with, and apply to software engineering practitioners and the broader academic community. The reflections and recommendations offered in this paper aim to ensure that insights from case studies are transparent, understandable, and tailored to meet the needs of both academic researchers and industry practitioners. In doing so, we seek to enhance the real-world applicability of academic research, bridging the gap between theoretical research and practical implementation in industry.	Arxiv	0	[]
268	Taming Multi-Output Recommenders for Software Engineering	Christoph Treude	2022-07-31T14:44:37Z	http://arxiv.org/abs/2208.00443v1	Recommender systems are a valuable tool for software engineers. For example, they can provide developers with a ranked list of files likely to contain a bug, or multiple auto-complete suggestions for a given method stub. However, the way these recommender systems interact with developers is often rudimentary -- a long list of recommendations only ranked by the model's confidence. In this vision paper, we lay out our research agenda for re-imagining how recommender systems for software engineering communicate their insights to developers. When issuing recommendations, our aim is to recommend diverse rather than redundant solutions and present them in ways that highlight their differences. We also want to allow for seamless and interactive navigation of suggestions while striving for holistic end-to-end evaluations. By doing so, we believe that recommender systems can play an even more important role in helping developers write better software.	Arxiv	0	[]
269	First things first: If software engineering is the solution, then what is the problem?	Jesus Zavala Ruiz	2019-04-11T20:46:15Z	http://arxiv.org/abs/1904.11540v1	Software engineering (SE) undergoes an ontological crisis and it lacks of a theory. Why? Among other reasons, because always it succumbed to the pragmatism demanded by the commercial and political interests and abandoned any intention to become a science instead of a professional discipline. For beginning a discussion for define a theory of software, first, is required to know what software is.	Arxiv	0	[]
270	Generative AI for Software Metadata: Overview of the Information Retrieval in Software Engineering Track at FIRE 2023	Srijoni Majumdar	2023-10-27T14:13:23Z	http://arxiv.org/abs/2311.03374v1	The Information Retrieval in Software Engineering (IRSE) track aims to develop solutions for automated evaluation of code comments in a machine learning framework based on human and large language model generated labels. In this track, there is a binary classification task to classify comments as useful and not useful. The dataset consists of 9048 code comments and surrounding code snippet pairs extracted from open source github C based projects and an additional dataset generated individually by teams using large language models. Overall 56 experiments have been submitted by 17 teams from various universities and software companies. The submissions have been evaluated quantitatively using the F1-Score and qualitatively based on the type of features developed, the supervised learning model used and their corresponding hyper-parameters. The labels generated from large language models increase the bias in the prediction model but lead to less over-fitted results.	Arxiv	0	['Soumen Paul', 'Debjyoti Paul', 'Ayan Bandyopadhyay', 'Samiran Chattopadhyay', 'Partha Pratim Das', 'Paul D Clough', 'Prasenjit Majumder']
271	Development of recommendation systems for software engineering: the CROSSMINER experience	Juri Di Rocco	2021-03-11T22:19:50Z	http://arxiv.org/abs/2103.06987v1	To perform their daily tasks, developers intensively make use of existing resources by consulting open-source software (OSS) repositories. Such platforms contain rich data sources, e.g., code snippets, documentation, and user discussions, that can be useful for supporting development activities. Over the last decades, several techniques and tools have been promoted to provide developers with innovative features, aiming to bring in improvements in terms of development effort, cost savings, and productivity. In the context of the EU H2020 CROSSMINER project, a set of recommendation systems has been conceived to assist software programmers in different phases of the development process. The systems provide developers with various artifacts, such as third-party libraries, documentation about how to use the APIs being adopted, or relevant API function calls. To develop such recommendations, various technical choices have been made to overcome issues related to several aspects including the lack of baselines, limited data availability, decisions about the performance measures, and evaluation approaches. This paper is an experience report to present the knowledge pertinent to the set of recommendation systems developed through the CROSSMINER project. We explain in detail the challenges we had to deal with, together with the related lessons learned when developing and evaluating these systems. Our aim is to provide the research community with concrete takeaway messages that are expected to be useful for those who want to develop or customize their own recommendation systems. The reported experiences can facilitate interesting discussions and research work, which in the end contribute to the advancement of recommendation systems applied to solve different issues in Software Engineering.	Arxiv	0	['Davide Di Ruscio', 'Claudio Di Sipio', 'Phuong T. Nguyen', 'Riccardo Rubei']
272	Standards of Validity and the Validity of Standards in Behavioral Software Engineering Research: The Perspective of Psychological Test Theory	Lucas Gren	2018-09-06T12:21:31Z	http://arxiv.org/abs/1809.01940v1	Background. There are some publications in software engineering research that aim at guiding researchers in assessing validity threats to their studies. Still, many researchers fail to address many aspects of validity that are essential to quantitative research on human factors. Goal. This paper has the goal of triggering a change of mindset in what types of studies are the most valuable to the behavioral software engineering field, and also provide more details of what construct validity is. Method. The approach is based on psychological test theory and draws upon methods used in psychology in relation to construct validity. Results. In this paper, I suggest a different approach to validity threats than what is commonplace in behavioral software engineering research. Conclusions. While this paper focuses on behavioral software engineering, I believe other types of software engineering research might also benefit from an increased focus on construct validity.	Arxiv	0	[]
273	An Analytical Approach for Project Managers in Effective Defect Management in Software Process	T. R. Gopalakrishnan Nair	2012-03-29T06:23:13Z	http://arxiv.org/abs/1203.6439v1	Defect estimation and prediction are some of the main modulating factors for the success of software projects in any software industry. Maturity and competency of a project manager in efficient prediction and estimation of resource capabilities are one of the strategic driving forces towards the generation of high quality software. Currently, there are no estimation techniques developed through empirical analysis to evaluate the decision capability of a project manager towards resource allocation for effective defect management. This paper brings out an empirical study carried out in a product based software organization. Our deep investigation on several projects throws light on the impact of decision capability of project manager towards accomplishment of an aforementioned objective. The paper enables project managers to gain further awareness towards the significance of predictive positioning in resource allocation in order to develop high quality defect-free software products. It also enhances the maturity level of the company and its persistence in the competitive atmosphere.	Arxiv	0	['V. Suma', 'N. R. Shashi Kumar']
274	Unhappy Developers: Bad for Themselves, Bad for Process, and Bad for Software Product	Daniel Graziotin	2017-01-11T12:38:13Z	http://arxiv.org/abs/1701.02952v3	"Recent research in software engineering supports the ""happy-productive"" thesis, and the desire of flourishing happiness among programmers is often expressed by industry practitioners. Recent literature has suggested that a cost-effective way to foster happiness and productivity among workers could be to limit unhappiness of developers due to its negative impact. However, possible negative effects of unhappiness are still largely unknown in the software development context. In this paper, we present the first results from a study exploring the consequences of the unhappy developers. Using qualitative data analysis of the survey responses given by 181 participants, we identified 49 potential consequences of unhappiness while developing software. These results have several implications. While raising the awareness of the role of moods, emotions and feelings in software development, we foresee that our classification scheme will spawn new happiness studies linking causes and effects, and it can act as a guideline for developers and managers to foster happiness at work."	Arxiv	0	['Fabian Fagerholm', 'Xiaofeng Wang', 'Pekka Abrahamsson']
275	Software Engineering in Australasia	Sherlock A. Licorish	2022-06-11T02:14:54Z	http://arxiv.org/abs/2206.05397v1	Six months ago an important call was made for researchers globally to provide insights into the way Software Engineering is done in their region. Heeding this call we hereby outline the position Software Engineering in Australasia (New Zealand and Australia). This article first considers the software development methods practices and tools that are popular in the Australasian software engineering community. We then briefly review the particular strengths of software engineering researchers in Australasia. Finally we make an open call for collaborators by reflecting on our current position and identifying future opportunities	Arxiv	0	['Christoph Treude', 'John Grundy', 'Chakkrit Tantithamthavorn', 'Kelly Blincoe', 'Stephen MacDonell', 'Li Li', 'Jean-Guy Schneider']
276	Understanding Fairness in Software Engineering: Insights from Stack Exchange	Emeralda Sesari	2024-02-29T11:02:47Z	http://arxiv.org/abs/2402.19038v3	Software practitioners discuss problems at work with peers, in-person and online. These discussions can be technical (e.g., how to fix a bug?) and social (e.g., how to assign work fairly?). While there is a growing body of knowledge exploring fairness problems and solutions in the human and social factors of software engineering, most focus has been on specific problems. This study provides fairness discussions by software practitioners on Stack Exchange sites. We present an exploratory study presenting the fairness experience of software practitioners and fairness expectations in software teams. We also want to identify the fairness aspects software practitioners talk about the most. For example, do they care more about fairness in income or how they are treated in the workplace?   Our investigation of fairness discussions on eight Stack Exchange sites resulted in a list of 136 posts (28 questions and 108 answers) manually curated from 4,178 candidate posts. The study reveals that the majority of fairness discussions (24 posts) revolve around the topic of income suggesting that many software practitioners are highly interested in matters related to their pay and how it is fairly distributed. Further, we noted that while not discussed as often, discussions on fairness in recruitment tend to receive the highest number of views and scores. Interestingly, the study shows that unfairness experiences extend beyond the protected attributes. In this study, only 25 out of 136 posts mention protected attributes, with gender mainly being discussed.	Arxiv	0	['Federica Sarro', 'Ayushi Rastogi']
277	A customizable approach to assess software quality through Multi-Criteria Decision Making	Francesco Basciani	2023-01-28T13:53:43Z	http://arxiv.org/abs/2301.12202v1	Over the years, Software Quality Engineering has increased interest, demonstrated by significant research papers published in this area. Determining when a software artifact is qualitatively valid is tricky, given the impossibility of providing an objective definition valid for any perspective, context, or stakeholder. Many quality model solutions have been proposed that reference specific quality attributes in this context. However, these approaches do not consider the context in which the artifacts will operate and the stakeholder's perspective who evaluate its validity. Furthermore, these solutions suffer from the limitations of being artifact-specific and not extensible.   In this paper, we provide a generic and extensible mechanism that makes it possible to aggregate and prioritize quality attributes. The user, taking into account his perspective and the context in which the software artifact will operate, is guided in defining all the criteria for his quality model. The management of these criteria is then facilitated through Multi-Criteria Decision Making (MCDM). In addition, we present the PRETTEF model, a concrete instance of the proposed approach for assessing and selecting MVC frameworks.	Arxiv	0	['Daniele Di Pompeo', 'Juri Di Rocco', 'Alfonso Pierantonio']
278	Bridging the Quantum Divide: Aligning Academic and Industry Goals in Software Engineering	Jake Zappin	2025-02-10T20:17:41Z	http://arxiv.org/abs/2502.07014v1	This position paper examines the substantial divide between academia and industry within quantum software engineering. For example, while academic research related to debugging and testing predominantly focuses on a limited subset of primarily quantum-specific issues, industry practitioners face a broader range of practical concerns, including software integration, compatibility, and real-world implementation hurdles. This disconnect mainly arises due to academia's limited access to industry practices and the often confidential, competitive nature of quantum development in commercial settings. As a result, academic advancements often fail to translate into actionable tools and methodologies that meet industry needs. By analyzing discussions within quantum developer forums, we identify key gaps in focus and resource availability that hinder progress on both sides. We propose collaborative efforts aimed at developing practical tools, methodologies, and best practices to bridge this divide, enabling academia to address the application-driven needs of industry and fostering a more aligned, sustainable ecosystem for quantum software development.	Arxiv	0	['Trevor Stalnaker', 'Oscar Chaparro', 'Denys Poshyvanyk']
279	Taxing Collaborative Software Engineering	Michael Dorner	2023-04-13T13:49:23Z	http://arxiv.org/abs/2304.06539v3	The engineering of complex software systems is often the result of a highly collaborative effort. However, collaboration within a multinational enterprise has an overlooked legal implication when developers collaborate across national borders: It is taxable. In this article, we discuss the unsolved problem of taxing collaborative software engineering across borders. We (1) introduce the reader to the basic principle of international taxation, (2) identify three main challenges for taxing collaborative software engineering making it a software engineering problem, and (3) estimate the industrial significance of cross-border collaboration in modern software engineering by measuring cross-border code reviews at a multinational software company.	Arxiv	0	['Maximilian Capraro', 'Oliver Treidler', 'Tom-Eric Kunz', 'Darja ≈†mite', 'Ehsan Zabardast', 'Daniel Mendez', 'Krzysztof Wnuk']
280	Software Engineering Process and Methodology in Blockchain-Oriented Software Development: A Systematic Study	Md Jobair Hossain Faruk	2022-07-02T18:19:49Z	http://arxiv.org/abs/2207.00892v1	Software Engineering is the process of a systematic, disciplined, quantifiable approach that has significant impact on large-scale and complex software development. Scores of well-established software process models have long been adopted in the software development life cycle that pour stakeholders towards the completion of final software product development. Within the boundary of advanced technology, various emerging and futuristic technology is evolving that really need the attention of the software engineering community whether the conventional software process techniques are capable to inherit the core fundamental into futuristic software development. In this paper, we study the impact of existing software engineering processes and models including Agile, and DevOps in Blockchain-Oriented Software Engineering. We also examine the essentiality of adopting state-of-art concepts and evolving the current software engineering process for blockchain-oriented systems. We discuss the insight of software project management practices in BOS development. The findings of this study indicate that utilizing state-of-art techniques in software processes for futuristic technology would be challenging and promising research is needed extensively towards addressing and improving state-of-the-art software engineering processes and methodology for novel technologies.	Arxiv	0	['Santhiya Subramanian', 'Hossain Shahriar', 'Maria Valero', 'Xia Li', 'Masrura Tasnim']
281	How software engineering research aligns with design science: A review	Emelie Engstr√∂m	2019-04-29T14:28:24Z	http://arxiv.org/abs/1904.12742v2	Background: Assessing and communicating software engineering research can be challenging. Design science is recognized as an appropriate research paradigm for applied research but is seldom referred to in software engineering. Applying the design science lens to software engineering research may improve the assessment and communication of research contributions. Aim: The aim of this study is 1) to understand whether the design science lens helps summarize and assess software engineering research contributions, and 2) to characterize different types of design science contributions in the software engineering literature. Method: In previous research, we developed a visual abstract template, summarizing the core constructs of the design science paradigm. In this study, we use this template in a review of a set of 38 top software engineering publications to extract and analyze their design science contributions. Results: We identified five clusters of papers, classifying them according to their alignment with the design science paradigm. Conclusions: The design science lens helps emphasize the theoretical contribution of research output---in terms of technological rules---and reflect on the practical relevance, novelty, and rigor of the rules proposed by the research.	Arxiv	0	['Margaret-Anne Storey', 'Per Runeson', 'Martin H√∂st', 'Maria Teresa Baldassarre']
282	Impostor Phenomenon Among Software Engineers: Investigating Gender Differences and Well-Being	Paloma Guenes	2025-02-11T19:36:44Z	http://arxiv.org/abs/2502.07914v1	Research shows that more than half of software professionals experience the Impostor Phenomenon (IP), with a notably higher prevalence among women compared to men. IP can lead to mental health consequences, such as depression and burnout, which can significantly impact personal well-being and software professionals' productivity. This study investigates how IP manifests among software professionals across intersections of gender with race/ethnicity, marital status, number of children, age, and professional experience. Additionally, it examines the well-being of software professionals experiencing IP, providing insights into the interplay between these factors. We analyzed data collected through a theory-driven survey (n = 624) that used validated psychometric instruments to measure IP and well-being in software engineering professionals. We explored the prevalence of IP in the intersections of interest. Additionally, we applied bootstrapping to characterize well-being within our field and statistically tested whether professionals of different genders suffering from IP have lower well-being. The results show that IP occurs more frequently in women and that the prevalence is particularly high among black women as well as among single and childless women. Furthermore, regardless of gender, software engineering professionals suffering from IP have significantly lower well-being. Our findings indicate that effective IP mitigation strategies are needed to improve the well-being of software professionals. Mitigating IP would have particularly positive effects on the well-being of women, who are more frequently affected by IP.	Arxiv	0	['Rafael Tomaz', 'Bianca Trinkenreich', 'Maria Teresa Baldassarre', 'Margarte-Anne Storey', 'Marcos Kalinowski']
283	A Comparison of Natural Language Understanding Platforms for Chatbots in Software Engineering	Ahmad Abdellatif	2020-12-04T14:59:08Z	http://arxiv.org/abs/2012.02640v2	Chatbots are envisioned to dramatically change the future of Software Engineering, allowing practitioners to chat and inquire about their software projects and interact with different services using natural language. At the heart of every chatbot is a Natural Language Understanding (NLU) component that enables the chatbot to understand natural language input. Recently, many NLU platforms were provided to serve as an off-the-shelf NLU component for chatbots, however, selecting the best NLU for Software Engineering chatbots remains an open challenge.   Therefore, in this paper, we evaluate four of the most commonly used NLUs, namely IBM Watson, Google Dialogflow, Rasa, and Microsoft LUIS to shed light on which NLU should be used in Software Engineering based chatbots. Specifically, we examine the NLUs' performance in classifying intents, confidence scores stability, and extracting entities. To evaluate the NLUs, we use two datasets that reflect two common tasks performed by Software Engineering practitioners, 1) the task of chatting with the chatbot to ask questions about software repositories 2) the task of asking development questions on Q&A forums (e.g., Stack Overflow). According to our findings, IBM Watson is the best performing NLU when considering the three aspects (intents classification, confidence scores, and entity extraction). However, the results from each individual aspect show that, in intents classification, IBM Watson performs the best with an F1-measure > 84%, but in confidence scores, Rasa comes on top with a median confidence score higher than 0.91. Our results also show that all NLUs, except for Dialogflow, generally provide trustable confidence scores. For entity extraction, Microsoft LUIS and IBM Watson outperform other NLUs in the two SE tasks. Our results provide guidance to software engineering practitioners when deciding which NLU to use in their chatbots.	Arxiv	0	['Khaled Badran', 'Diego Elias Costa', 'Emad Shihab']
284	Software Engineering for AI-Based Systems: A Survey	Silverio Mart√≠nez-Fern√°ndez	2021-05-05T11:22:08Z	http://arxiv.org/abs/2105.01984v2	AI-based systems are software systems with functionalities enabled by at least one AI component (e.g., for image- and speech-recognition, and autonomous driving). AI-based systems are becoming pervasive in society due to advances in AI. However, there is limited synthesized knowledge on Software Engineering (SE) approaches for building, operating, and maintaining AI-based systems. To collect and analyze state-of-the-art knowledge about SE for AI-based systems, we conducted a systematic mapping study. We considered 248 studies published between January 2010 and March 2020. SE for AI-based systems is an emerging research area, where more than 2/3 of the studies have been published since 2018. The most studied properties of AI-based systems are dependability and safety. We identified multiple SE approaches for AI-based systems, which we classified according to the SWEBOK areas. Studies related to software testing and software quality are very prevalent, while areas like software maintenance seem neglected. Data-related issues are the most recurrent challenges. Our results are valuable for: researchers, to quickly understand the state of the art and learn which topics need more research; practitioners, to learn about the approaches and challenges that SE entails for AI-based systems; and, educators, to bridge the gap among SE and AI in their curricula.	Arxiv	0	['Justus Bogner', 'Xavier Franch', 'Marc Oriol', 'Julien Siebert', 'Adam Trendowicz', 'Anna Maria Vollmer', 'Stefan Wagner']
285	Mapping the Trust Terrain: LLMs in Software Engineering -- Insights and Perspectives	Dipin Khati	2025-03-18T00:49:43Z	http://arxiv.org/abs/2503.13793v2	Applications of Large Language Models (LLMs) are rapidly growing in industry and academia for various software engineering (SE) tasks. As these models become more integral to critical processes, ensuring their reliability and trustworthiness becomes essential. Consequently, the concept of trust in these systems is becoming increasingly critical. Well-calibrated trust is important, as excessive trust can lead to security vulnerabilities, and risks, while insufficient trust can hinder innovation. However, the landscape of trust-related concepts in LLMs in SE is relatively unclear, with concepts such as trust, distrust, and trustworthiness lacking clear conceptualizations in the SE community. To bring clarity to the current research status and identify opportunities for future work, we conducted a comprehensive review of $88$ papers: a systematic literature review of $18$ papers focused on LLMs in SE, complemented by an analysis of 70 papers from broader trust literature. Additionally, we conducted a survey study with 25 domain experts to gain insights into practitioners' understanding of trust and identify gaps between existing literature and developers' perceptions. The result of our analysis serves as a roadmap that covers trust-related concepts in LLMs in SE and highlights areas for future exploration.	Arxiv	0	['Yijin Liu', 'David N. Palacio', 'Yixuan Zhang', 'Denys Poshyvanyk']
286	Qualitative Research Methods in Software Engineering: Past, Present, and Future	Carolyn Seaman	2025-02-11T03:25:58Z	http://arxiv.org/abs/2502.07220v1	"The paper entitled ""Qualitative Methods in Empirical Studies of Software Engineering"" by Carolyn Seaman was published in TSE in 1999. It has been chosen as one of the most influential papers from the third decade of TSE's 50 years history. In this retrospective, the authors discuss the evolution of the use of qualitative methods in software engineering research, the impact it's had on research and practice, and reflections on what is coming and deserves attention."	Arxiv	0	['Rashina Hoda', 'Robert Feldt']
287	An Approach for Auto Generation of Labeling Functions for Software Engineering Chatbots	Ebube Alor	2024-10-09T17:34:14Z	http://arxiv.org/abs/2410.07094v2	Software engineering (SE) chatbots are increasingly gaining attention for their role in enhancing development processes. At the core of chatbots are Natural Language Understanding platforms (NLUs), which enable them to comprehend user queries but require labeled data for training. However, acquiring such labeled data for SE chatbots is challenging due to the scarcity of high-quality datasets, as training requires specialized vocabulary and phrases not found in typical language datasets. Consequently, developers often resort to manually annotating user queries -- a time-consuming and resource-intensive process. Previous approaches require human intervention to generate rules, called labeling functions (LFs), that categorize queries based on specific patterns. To address this issue, we propose an approach to automatically generate LFs by extracting patterns from labeled user queries. We evaluate our approach on four SE datasets and measure performance improvement from training NLUs on queries labeled by the generated LFs. The generated LFs effectively label data with AUC scores up to 85.3% and NLU performance improvements up to 27.2%. Furthermore, our results show that the number of LFs affects labeling performance. We believe that our approach can save time and resources in labeling users' queries, allowing practitioners to focus on core chatbot functionalities rather than manually labeling queries.	Arxiv	0	['Ahmad Abdellatif', 'SayedHassan Khatoonabadi', 'Emad Shihab']
288	An Agile Software Engineering Method to Design Blockchain Applications	Michele Marchesi	2018-09-25T17:16:05Z	http://arxiv.org/abs/1809.09596v1	"Cryptocurrencies and their foundation technology, the Blockchain, are reshaping finance and economics, allowing a decentralized approach enabling trusted applications with no trusted counterpart. More recently, the Blockchain and the programs running on it, called Smart Contracts, are also finding more and more applications in all fields requiring trust and sound certifications. Some people have come to the point of saying that the ""Blockchain revolution"" can be compared to that of the Internet and the Web in their early days. As a result, all the software development revolving around the Blockchain technology is growing at a staggering rate. The feeling of many software engineers about such huge interest in Blockchain technologies is that of unruled and hurried software development, a sort of competition on a first-come-first-served basis which does not assure neither software quality, nor that the basic concepts of software engineering are taken into account. This paper tries to cope with this issue, proposing a software development process to gather the requirement, analyze, design, develop, test and deploy Blockchain applications. The process is based on several Agile practices, such as User Stories and iterative and incremental development based on them. However, it makes also use of more formal notations, such as some UML diagrams describing the design of the system, with additions to represent specific concepts found in Blockchain development. The method is described in good detail, and an example is given to show how it works."	Arxiv	0	['Lodovica Marchesi', 'Roberto Tonelli']
289	Survey on Essential and Accidental Real-Time Issues in Software Engineering	Furrakh Shahzad	2017-03-10T17:58:55Z	http://arxiv.org/abs/1703.03783v1	Software product lines have recently been presented as one of the best promising improvements for the efficient software development. Different research works contribute supportive parameters and negotiations regarding the problems of producing a perfect software scheme. Traditional approaches or recycling software are not effective to solve the problems concerning software competence. Since fast developments with software engineering in the past few years, studies show that some approaches are getting extensive attention in both industries and universities. This method is categorized as the software product line improvement; that supports reusing of software in big organizations. Different industries are adopting product lines to enhance efficiency and reduce operational expenses by way of emerging product developments. This research paper is formed to offer in-depth study regarding the software engineering issues such as complexity, conformity, changeability, invisibility, time constraints, budget constraints, and security. We have conducted various research surveys by visiting different professional software development organizations and took feedback from the professional software engineers to analyze the real-time problems that they are facing during the development process of software systems. Survey results proved that complexity is a most occurring issue that most software developers face while developing software applications. Moreover, invisibility is the problem that rarely happens according to the survey.	Arxiv	0	['Maruf Pasha', 'Urooj Pasha', 'Bushra Majeed', 'Khurram Shahzad']
290	A Formal Method for Mapping Software Engineering Practices to Essence	Murat Pasa Uysal	2018-12-04T07:15:06Z	http://arxiv.org/abs/1812.01791v1	Essence Framework EF aims at addressing the core problems of software engineering SE and its practices	Arxiv	0	[]
291	Agent-Driven Automatic Software Improvement	Fernando Vallecillos Ruiz	2024-06-24T15:45:22Z	http://arxiv.org/abs/2406.16739v1	With software maintenance accounting for 50% of the cost of developing software, enhancing code quality and reliability has become more critical than ever. In response to this challenge, this doctoral research proposal aims to explore innovative solutions by focusing on the deployment of agents powered by Large Language Models (LLMs) to perform software maintenance tasks. The iterative nature of agents, which allows for continuous learning and adaptation, can help surpass common challenges in code generation. One distinct challenge is the last-mile problems, errors at the final stage of producing functionally and contextually relevant code. Furthermore, this project aims to surpass the inherent limitations of current LLMs in source code through a collaborative framework where agents can correct and learn from each other's errors. We aim to use the iterative feedback in these systems to further fine-tune the LLMs underlying the agents, becoming better aligned to the task of automated software improvement. Our main goal is to achieve a leap forward in the field of automatic software improvement by developing new tools and frameworks that can enhance the efficiency and reliability of software development.	Arxiv	0	[]
292	Consequences of Unhappiness While Developing Software	Daniel Graziotin	2017-01-20T13:48:10Z	http://arxiv.org/abs/1701.05789v2	The growing literature on affect among software developers mostly reports on the linkage between happiness, software quality, and developer productivity. Understanding the positive side of happiness -- positive emotions and moods -- is an attractive and important endeavor. Scholars in industrial and organizational psychology have suggested that also studying the negative side -- unhappiness -- could lead to cost-effective ways of enhancing working conditions, job performance, and to limiting the occurrence of psychological disorders. Our comprehension of the consequences of (un)happiness among developers is still too shallow, and is mainly expressed in terms of development productivity and software quality. In this paper, we attempt to uncover the experienced consequences of unhappiness among software developers. Using qualitative data analysis of the responses given by 181 questionnaire participants, we identified 49 consequences of unhappiness while doing software development. We found detrimental consequences on developers' mental well-being, the software development process, and the produced artifacts. Our classification scheme, available as open data, will spawn new happiness research opportunities of cause-effect type, and it can act as a guideline for practitioners for identifying damaging effects of unhappiness and for fostering happiness on the job.	Arxiv	0	['Fabian Fagerholm', 'Xiaofeng Wang', 'Pekka Abrahamsson']
293	Orchestration of Global Software Engineering Projects	Christian Bartelt	2014-09-22T12:02:49Z	http://arxiv.org/abs/1409.6587v1	"Global software engineering has become a fact in many companies due to real necessity in practice. In contrast to co-located projects global projects face a number of additional software engineering challenges. Among them quality management has become much more difficult and schedule and budget overruns can be observed more often. Compared to co-located projects global software engineering is even more challenging due to the need for integration of different cultures, different languages, and different time zones - across companies, and across countries. The diversity of development locations on several levels seriously endangers an effective and goal-oriented progress of projects. In this position paper we discuss reasons for global development, sketch settings for distribution and views of orchestration of dislocated companies in a global project that can be seen as a ""virtual project environment"". We also present a collection of questions, which we consider relevant for global software engineering. The questions motivate further discussion to derive a research agenda in global software engineering."	Arxiv	0	['Manfred Broy', 'Christoph Herrmann', 'Eric Knauss', 'Marco Kuhrmann', 'Andreas Rausch', 'Bernhard Rumpe', 'Kurt Schneider']
294	SWE-Arena: An Interactive Platform for Evaluating Foundation Models in Software Engineering	Zhimin Zhao	2025-02-03T22:19:28Z	http://arxiv.org/abs/2502.01860v5	Foundation models (FMs), particularly large language models (LLMs), have shown significant promise in various software engineering (SE) tasks, including code generation, debugging, and requirement refinement. Despite these advances, existing evaluation frameworks are insufficient for assessing model performance in iterative, context-rich workflows characteristic of SE activities. To address this limitation, we introduce \emph{SWE-Arena}, an interactive platform designed to evaluate FMs in SE tasks. SWE-Arena provides a transparent, open-source leaderboard, supports multi-round conversational workflows, and enables end-to-end model comparisons. The platform introduces novel metrics, including \emph{model consistency score} that measures the consistency of model outputs through self-play matches, and \emph{conversation efficiency index} that evaluates model performance while accounting for the number of interaction rounds required to reach conclusions. Moreover, SWE-Arena incorporates a new feature called \emph{RepoChat}, which automatically injects repository-related context (e.g., issues, commits, pull requests) into the conversation, further aligning evaluations with real-world development processes. This paper outlines the design and capabilities of SWE-Arena, emphasizing its potential to advance the evaluation and practical application of FMs in software engineering.	Arxiv	0	[]
295	Software Engineering Educational Experience in Building an Intelligent Tutoring System	Zhiyu Fan	2023-10-09T07:28:41Z	http://arxiv.org/abs/2310.05472v3	"The growing number of students enrolling in Computer Science (CS) programmes is pushing CS educators to their limits. This poses significant challenges to computing education, particularly the teaching of introductory programming and advanced software engineering (SE) courses. First-year programming courses often face overwhelming enrollments, including interdisciplinary students who are not CS majors. The high teacher-to-student ratio makes it challenging to provide timely and high-quality feedback. Meanwhile, software engineering education comes with inherent difficulties like acquiring industry partners and the dilemma that such software projects are often under or over-specified and one-time efforts within one team or one course. To address these challenges, we designed a novel foundational SE course. This SE course envisions building a full-fledged Intelligent Tutoring System (ITS) of Programming Assignments to provide automated, real-time feedback for novice students in programming courses over multiple years. Each year, SE students contribute to specific short-running SE projects that improve the existing ITS implementation, while at the same time, we can deploy the ITS for usage by students for learning programming. This project setup builds awareness among SE students about their contribution to a ""to-be-deployed"" software project. In this multi-year teaching effort, we have incrementally built an ITS that is now deployed in various programming courses. This paper discusses the Intelligent Tutoring System architecture, our teaching concept in the SE course, our experience with the built ITS, and our view of future computing education."	Arxiv	0	['Yannic Noller', 'Ashish Dandekar', 'Abhik Roychoudhury']
296	How Developers Interact with AI: A Taxonomy of Human-AI Collaboration in Software Engineering	Christoph Treude	2025-01-15T12:53:49Z	http://arxiv.org/abs/2501.08774v2	Artificial intelligence (AI), including large language models and generative AI, is emerging as a significant force in software development, offering developers powerful tools that span the entire development lifecycle. Although software engineering research has extensively studied AI tools in software development, the specific types of interactions between developers and these AI-powered tools have only recently begun to receive attention. Understanding and improving these interactions has the potential to enhance productivity, trust, and efficiency in AI-driven workflows. In this paper, we propose a taxonomy of interaction types between developers and AI tools, identifying eleven distinct interaction types, such as auto-complete code suggestions, command-driven actions, and conversational assistance. Building on this taxonomy, we outline a research agenda focused on optimizing AI interactions, improving developer control, and addressing trust and usability challenges in AI-assisted development. By establishing a structured foundation for studying developer-AI interactions, this paper aims to stimulate research on creating more effective, adaptive AI tools for software development.	Arxiv	0	['Marco A. Gerosa']
297	Formal Quantum Software Engineering: Introducing the Formal Methods of Software Engineering to Quantum Computing	Carmelo R. Cartiere	2021-11-14T22:11:26Z	http://arxiv.org/abs/2111.08426v1	Quantum computing (QC) represents the future of computing systems, but the tools for reasoning about the quantum model of computation, in which the laws obeyed are those on the quantum mechanical scale, are still a mix of linear algebra and Dirac notation; two subjects more suitable for physicists, rather than computer scientists and software engineers. On this ground, we believe it is possible to provide a more intuitive approach to thinking and writing about quantum computing systems, in order to simplify the design of quantum algorithms and the development of quantum software. In this paper, we move the first step in such direction, introducing a specification language as the tool to represent the operations of a quantum computer via axiomatic definitions, by adopting the same symbolisms and reasoning principles used by formal methods in software engineering. We name this approach formal quantum software engineering (F-QSE). This work assumes familiarity with the basic principles of quantum mechanics (QM), with the use of Zed (Z) which is a formal language of software engineering (SE), and with the notation and techniques of first-order logic (FOL) and functional programming (FP).	Arxiv	0	[]
298	Assessment of Off-the-Shelf SE-specific Sentiment Analysis Tools: An Extended Replication Study	Nicole Novielli	2020-10-20T10:10:19Z	http://arxiv.org/abs/2010.10172v2	Sentiment analysis methods have become popular for investigating human communication, including discussions related to software projects. Since general-purpose sentiment analysis tools do not fit well with the information exchanged by software developers, new tools, specific for software engineering (SE), have been developed. We investigate to what extent SE-specific tools for sentiment analysis mitigate the threats to conclusion validity of empirical studies in software engineering, highlighted by previous research. First, we replicate two studies addressing the role of sentiment in security discussions on GitHub and in question-writing on Stack Overflow. Then, we extend the previous studies by assessing to what extent the tools agree with each other and with the manual annotation on a gold standard of 600 documents. We find that different SE-specific sentiment analysis tools might lead to contradictory results at a fine-grain level, when used 'off-the-shelf'. Conversely, platform-specific tuning or retraining might be needed to take into account differences in platform conventions, jargon, or document lengths.	Arxiv	0	['Fabio Calefato', 'Filippo Lanubile', 'Alexander Serebrenik']
299	Investigating the Use of LLMs for Evidence Briefings Generation in Software Engineering	Mauro Marcelino	2025-07-21T17:37:23Z	http://arxiv.org/abs/2507.15828v1	[Context] An evidence briefing is a concise and objective transfer medium that can present the main findings of a study to software engineers in the industry. Although practitioners and researchers have deemed Evidence Briefings useful, their production requires manual labor, which may be a significant challenge to their broad adoption. [Goal] The goal of this registered report is to describe an experimental protocol for evaluating LLM-generated evidence briefings for secondary studies in terms of content fidelity, ease of understanding, and usefulness, as perceived by researchers and practitioners, compared to human-made briefings. [Method] We developed an RAG-based LLM tool to generate evidence briefings. We used the tool to automatically generate two evidence briefings that had been manually generated in previous research efforts. We designed a controlled experiment to evaluate how the LLM-generated briefings compare to the human-made ones regarding perceived content fidelity, ease of understanding, and usefulness. [Results] To be reported after the experimental trials. [Conclusion] Depending on the experiment results.	Arxiv	0	['Marcos Alves', 'Bianca Trinkenreich', 'Bruno Cartaxo', 'S√©rgio Soares', 'Simone D. J. Barbosa', 'Marcos Kalinowski']
300	Embracing Experiential Learning: Hackathons as an Educational Strategy for Shaping Soft Skills in Software Engineering	Allysson Allex Ara√∫jo	2025-02-11T20:58:33Z	http://arxiv.org/abs/2502.07950v1	In recent years, Software Engineering (SE) scholars and practitioners have emphasized the importance of integrating soft skills into SE education. However, teaching and learning soft skills are complex, as they cannot be acquired passively through raw knowledge acquisition. On the other hand, hackathons have attracted increasing attention due to their experiential, collaborative, and intensive nature, which certain tasks could be similar to real-world software development. This paper aims to discuss the idea of hackathons as an educational strategy for shaping SE students' soft skills in practice. Initially, we overview the existing literature on soft skills and hackathons in SE education. Then, we report preliminary empirical evidence from a seven-day hybrid hackathon involving 40 students. We assess how the hackathon experience promoted innovative and creative thinking, collaboration and teamwork, and knowledge application among participants through a structured questionnaire designed to evaluate students' self-awareness. Lastly, our findings and new directions are analyzed through the lens of Self-Determination Theory, which offers a psychological lens to understand human behavior. This paper contributes to academia by advocating the potential of hackathons in SE education and proposing concrete plans for future research within SDT. For industry, our discussion has implications around developing soft skills in future SE professionals, thereby enhancing their employability and readiness in the software market.	Arxiv	0	['Marcos Kalinowski', 'Maria Teresa Baldassarre']
301	An Architecture Process Maturity Model of Software Product Line Engineering	Faheem Ahmed	2015-07-24T16:03:35Z	http://arxiv.org/abs/1507.06901v1	Software architecture has been a key research area in the software engineering community due to its significant role in creating high quality software. The trend of developing product lines rather than single products has made the software product line a viable option in the industry. Software product line architecture is regarded as one of the crucial components in the product lines, since all of the resulting products share this common architecture. The increased popularity of software product lines demands a process maturity evaluation methodology. Consequently, this paper presents an architecture process maturity model for software product line engineering to evaluate the current maturity of the product line architecture development process in an organization. Assessment questionnaires and a rating methodology comprise the framework of this model. The objective of the questionnaires is to collect information about the software product line architecture development process. Thus, in general this work contributes towards the establishment of a comprehensive and unified strategy for the process maturity evaluation of software product line engineering. Furthermore, we conducted two case studies and reported the assessment results, which show the maturity of the architecture development process in two organizations	Arxiv	0	['Luiz Fernando Capretz']
302	Do feelings matter? On the correlation of affects and the self-assessed productivity in software engineering	Daniel Graziotin	2014-08-06T14:31:15Z	http://arxiv.org/abs/1408.1293v2	Background: software engineering research (SE) lacks theory and methodologies for addressing human aspects in software development. Development tasks are undertaken through cognitive processing activities. Affects (emotions, moods, feelings) have a linkage to cognitive processing activities and the productivity of individuals. SE research needs to incorporate affect measurements to valorize human factors and to enhance management styles.   Objective: analyze the affects dimensions of valence, arousal, and dominance of software developers and their real-time correlation with their self-assessed productivity (sPR).   Method: repeated measurements design with 8 participants (4 students, 4 professionals), conveniently sampled and studied individually over 90 minutes of programming. The analysis was performed by fitting a linear mixed- effects (LME) model.   Results: valence and dominance are positively correlated with the sPR. The model was able to express about 38% of deviance from the sPR. Many lessons were learned when employing psychological measurements in SE and for fitting LME.   Conclusion: this article demonstrates the value of applying psychological tests in SE and echoes a call to valorize the human, individualized aspects of software developers. It reports a body of knowledge about affects, their classification, their measurement, and the best practices to perform psychological measurements in SE with LME models.	Arxiv	0	['Xiaofeng Wang', 'Pekka Abrahamsson']
303	Using Software Categories for the Development of Generative Software	Pedram Mir Seyed Nazari	2015-09-08T09:25:18Z	http://arxiv.org/abs/1509.02293v1	"In model-driven development (MDD) software emerges by systematically transforming abstract models to concrete source code. Ideally, performing those transformations is to a large extent the task of code generators. One approach for developing a new code generator is to write a reference implementation and separate it into handwritten and generatable code. Typically, the generator developer manually performs this separation a process that is often time-consuming, labor-intensive, difficult to maintain and may produce more code than necessary. Software categories provide a way for separating code into designated parts with defined dependencies, for example, ""Business Logic"" code that may not directly use ""Technical"" code. This paper presents an approach that uses the concept of software categories to semi-automatically determine candidates for generated code. The main idea is to iteratively derive the categories for uncategorized code from the dependencies of categorized code. The candidates for generated or handwritten code finally are code parts belonging to specific (previously defined) categories. This approach helps the generator developer in finding candidates for generated code more easily and systematically than searching by hand and is a step towards tool-supported development of generative software."	Arxiv	0	['Bernhard Rumpe']
304	Rise of Distributed Deep Learning Training in the Big Model Era: From a Software Engineering Perspective	Xuanzhe Liu	2021-12-12T12:58:48Z	http://arxiv.org/abs/2112.06222v2	"Deep learning (DL) has become a key component of modern software. In the ""big model"" era, the rich features of DL-based software substantially rely on powerful DL models, e.g., BERT, GPT-3, and the recently emerging GPT-4, which are trained on the powerful cloud with large datasets. Hence, training effective DL models has become a vital stage in the whole software lifecycle. When training deep learning models, especially those big models, developers need to parallelize and distribute the computation and memory resources amongst multiple devices in the training process, which is known as distributed deep learning training, or distributed training for short. However, the unique challenges that developers encounter in distributed training process have not been studied in the software engineering community. Given the increasingly heavy dependence of current DL-based software on distributed training, this paper aims to fill in the knowledge gap and presents the first comprehensive study on developers' issues in distributed training. To this end, we analyze 1,131 real-world developers' issues about using these frameworks reported on Stack Overflow and GitHub. We construct a fine-grained taxonomy consisting of 30 categories regarding the fault symptoms and summarize common fix patterns for different symptoms. Based on the results, we suggest actionable implications on research avenues that can potentially facilitate the distributed training to develop DL-based software, such as focusing on the frequent and common fix patterns when designing testing or debugging tools, developing efficient testing and debugging techniques for communication configuration along with the synthesis of network configuration analysis, designing new multi-device checkpoint-and-replay techniques to help reproduction, and designing serverless APIs for cloud platforms."	Arxiv	0	['Diandian Gu', 'Zhenpeng Chen', 'Jinfeng Wen', 'Zili Zhang', 'Yun Ma', 'Haoyu Wang', 'Xin Jin']
305	Pandemic Programming: How COVID-19 affects software developers and how their organizations can help	Paul Ralph	2020-05-03T16:18:46Z	http://arxiv.org/abs/2005.01127v3	Context. As a novel coronavirus swept the world in early 2020, thousands of software developers began working from home. Many did so on short notice, under difficult and stressful conditions. Objective. This study investigates the effects of the pandemic on developers' wellbeing and productivity. Method. A questionnaire survey was created mainly from existing, validated scales and translated into 12 languages. The data was analyzed using non-parametric inferential statistics and structural equation modeling. Results. The questionnaire received 2225 usable responses from 53 countries. Factor analysis supported the validity of the scales and the structural model achieved a good fit (CFI = 0.961, RMSEA = 0.051, SRMR = 0.067). Confirmatory results include: (1) the pandemic has had a negative effect on developers' wellbeing and productivity; (2) productivity and wellbeing are closely related; (3) disaster preparedness, fear related to the pandemic and home office ergonomics all affect wellbeing or productivity. Exploratory analysis suggests that: (1) women, parents and people with disabilities may be disproportionately affected; (2) different people need different kinds of support. Conclusions. To improve employee productivity, software companies should focus on maximizing employee wellbeing and improving the ergonomics of employees' home offices. Women, parents and disabled persons may require extra support.	Arxiv	0	['Sebastian Baltes', 'Gianisa Adisaputri', 'Richard Torkar', 'Vladimir Kovalenko', 'Marcos Kalinowski', 'Nicole Novielli', 'Shin Yoo', 'Xavier Devroey', 'Xin Tan', 'Minghui Zhou', 'Burak Turhan', 'Rashina Hoda', 'Hideaki Hata', 'Gregorio Robles', 'Amin Milani Fard', 'Rana Alkadhi']
306	Software Engineering Practices for Scientific Software Development: A Systematic Mapping Study	Elvira-Maria Arvanitou	2020-10-19T23:24:00Z	http://arxiv.org/abs/2010.09914v1	"Background: The development of scientific software applications is far from trivial, due to the constant increase in the necessary complexity of these applications, their increasing size, and their need for intensive maintenance and reuse. Aim: To this end, developers of scientific software (who usually lack a formal computer science background) need to use appropriate software engineering (SE) practices. This paper describes the results of a systematic mapping study on the use of SE for scientific application development and their impact on software quality. Method: To achieve this goal we have performed a systematic mapping study on 359 papers. We first describe a catalogue of SE practices used in scientific software development. Then, we discuss the quality attributes of interest that drive the application of these practices, as well as tentative side-effects of applying the practices on qualities. Results: The main findings indicate that scientific software developers are focusing on practices that improve implementation productivity, such as code reuse, use of third-party libraries, and the application of ""good"" programming techniques. In addition, apart from the finding that performance is a key-driver for many of these applications, scientific software developers also find maintainability and productivity to be important. Conclusions: The results of the study are compared to existing literature, are interpreted under a software engineering prism, and various implications for researchers and practitioners are provided. One of the key findings of the study, which is considered as important for driving future research endeavors is the lack of evidence on the trade-offs that need to be made when applying a software practice, i.e., negative (indirect) effects on other quality attributes."	Arxiv	0	['Apostolos Ampatzoglou', 'Alexander Chatzigeorgiou', 'Jeffrey C. Carver']
307	Looking back and forward: A retrospective and future directions on Software Engineering for systems-of-systems	Everton Cavalcante	2024-03-25T13:12:39Z	http://arxiv.org/abs/2403.16740v2	Modern systems are increasingly connected and more integrated with other existing systems, giving rise to \textit{systems-of-systems} (SoS). An SoS consists of a set of independent, heterogeneous systems that interact to provide new functionalities and accomplish global missions through emergent behavior manifested at runtime. The distinctive characteristics of SoS, when contrasted to traditional systems, pose significant research challenges within Software Engineering. These challenges motivate the need for a paradigm shift and the exploration of novel approaches for designing, developing, deploying, and evolving these systems. The \textit{International Workshop on Software Engineering for Systems-of-Systems} (SESoS) series started in 2013 to fill a gap in scientific forums addressing SoS from the Software Engineering perspective, becoming the first venue for this purpose. This article presents a study aimed at outlining the evolution and future trajectory of Software Engineering for SoS based on the examination of 57 papers spanning the 11 editions of the SESoS workshop (2013-2023). The study combined scoping review and scientometric analysis methods to categorize and analyze the research contributions concerning temporal and geographic distribution, topics of interest, research methodologies employed, application domains, and research impact. Based on such a comprehensive overview, this article discusses current and future directions in Software Engineering for SoS.	Arxiv	0	['Thais Batista', 'Flavio Oquendo']
308	How do Practitioners Perceive the Relevance of Requirements Engineering Research?	Xavier Franch	2020-11-10T14:09:26Z	http://arxiv.org/abs/2011.05106v2	The relevance of Requirements Engineering (RE) research to practitioners is vital for a long-term dissemination of research results to everyday practice. Some authors have speculated about a mismatch between research and practice in the RE discipline. However, there is not much evidence to support or refute this perception. This paper presents the results of a study aimed at gathering evidence from practitioners about their perception of the relevance of RE research and at understanding the factors that influence that perception. We conducted a questionnaire-based survey of industry practitioners with expertise in RE. The participants rated the perceived relevance of 435 scientific papers presented at five top RE-related conferences. The 153 participants provided a total of 2,164 ratings. The practitioners rated RE research as essential or worthwhile in a majority of cases. However, the percentage of non-positive ratings is still higher than we would like. Among the factors that affect the perception of relevance are the research's links to industry, the research method used, and respondents' roles. The reasons for positive perceptions were primarily related to the relevance of the problem and the soundness of the solution, while the causes for negative perceptions were more varied. The respondents also provided suggestions for future research, including topics researchers have studied for decades, like elicitation or requirement quality criteria.	Arxiv	0	['Daniel Mendez', 'Andreas Vogelsang', 'Rogardt Heldal', 'Eric Knauss', 'Marc Oriol', 'Guilherme H. Travassos', 'Jeffrey C. Carver', 'Thomas Zimmermann']
309	A longitudinal case study on the effects of an evidence-based software engineering training	Sebasti√°n Pizard	2022-02-07T17:26:58Z	http://arxiv.org/abs/2202.03367v1	Context: Evidence-based software engineering (EBSE) can be an effective resource to bridge the gap between academia and industry by balancing research of practical relevance and academic rigor. To achieve this, it seems necessary to investigate EBSE training and its benefits for the practice. Objective: We sought both to develop an EBSE training course for university students and to investigate what effects it has on the attitudes and behaviors of the trainees. Method: We conducted a longitudinal case study to study our EBSE course and its effects. For this, we collect data at the end of each EBSE course (2017, 2018, and 2019), and in two follow-up surveys (one after 7 months of finishing the last course, and a second after 21 months). Results: Our EBSE courses seem to have taught students adequately and consistently. Half of the respondents to the surveys report making use of the new skills from the course. The most-reported effects in both surveys indicated that EBSE concepts increase awareness of the value of research and evidence and EBSE methods improve information gathering skills. Conclusions: As suggested by research in other areas, training appears to play a key role in the adoption of evidence-based practice. Our results indicate that our training method provides an introduction to EBSE suitable for undergraduates. However, we believe it is necessary to continue investigating EBSE training and its impact on software engineering practice.	Arxiv	0	['Diego Vallespir', 'Barbara Kitchenham']
310	Towards effective assessment of steady state performance in Java software: Are we there yet?	Luca Traini	2022-09-30T10:42:45Z	http://arxiv.org/abs/2209.15369v2	Microbenchmarking is a widely used form of performance testing in Java software. A microbenchmark repeatedly executes a small chunk of code while collecting measurements related to its performance. Due to Java Virtual Machine optimizations, microbenchmarks are usually subject to severe performance fluctuations in the first phase of their execution (also known as warmup). For this reason, software developers typically discard measurements of this phase and focus their analysis when benchmarks reach a steady state of performance. Developers estimate the end of the warmup phase based on their expertise, and configure their benchmarks accordingly. Unfortunately, this approach is based on two strong assumptions: (i) benchmarks always reach a steady state of performance and (ii) developers accurately estimate warmup. In this paper, we show that Java microbenchmarks do not always reach a steady state, and often developers fail to accurately estimate the end of the warmup phase. We found that a considerable portion of studied benchmarks do not hit the steady state, and warmup estimates provided by software developers are often inaccurate (with a large error). This has significant implications both in terms of results quality and time-effort. Furthermore, we found that dynamic reconfiguration significantly improves warmup estimation accuracy, but still it induces suboptimal warmup estimates and relevant side-effects. We envision this paper as a starting point for supporting the introduction of more sophisticated automated techniques that can ensure results quality in a timely fashion.	Arxiv	0	['Vittorio Cortellessa', 'Daniele Di Pompeo', 'Michele Tucci']
311	Qualitative analysis of the relationship between design smells and software engineering challenges	Asif Imran	2023-10-22T23:21:13Z	http://arxiv.org/abs/2310.14449v1	"Software design debt aims to elucidate the rectification attempts of the present design flaws and studies the influence of those to the cost and time of the software. Design smells are a key cause of incurring design debt. Although the impact of design smells on design debt have been predominantly considered in current literature, how design smells are caused due to not following software engineering best practices require more exploration. This research provides a tool which is used for design smell detection in Java software by analyzing large volume of source codes. More specifically, 409,539 Lines of Code (LoC) and 17,760 class files of open source Java software are analyzed here. Obtained results show desirable precision values ranging from 81.01\% to 93.43\%. Based on the output of the tool, a study is conducted to relate the cause of the detected design smells to two software engineering challenges namely ""irregular team meetings"" and ""scope creep"". As a result, the gained information will provide insight to the software engineers to take necessary steps of design remediation actions."	Arxiv	0	['Tevfik Kosar']
312	Assets in Software Engineering: What are they after all?	Ehsan Zabardast	2021-01-19T18:31:33Z	http://arxiv.org/abs/2101.07768v5	During the development and maintenance of software-intensive products or services, we depend on various artefacts. Some of those artefacts, we deem central to the feasibility of a project and the product's final quality. Typically, these central artefacts are referred to as assets. However, despite their central role in the software development process, little thought is yet invested into what eventually characterises as an asset, often resulting in many terms and underlying concepts being mixed and used inconsistently. A precise terminology of assets and related concepts, such as asset degradation, are crucial for setting up a new generation of cost-effective software engineering practices.   In this position paper, we critically reflect upon the notion of assets in software engineering. As a starting point, we define the terminology and concepts of assets and extend the reasoning behind them. We explore assets' characteristics and discuss what asset degradation is as well as its various types and the implications that asset degradation might bring for the planning, realisation, and evolution of software-intensive products and services over time.   We aspire to contribute to a more standardised definition of assets in software engineering and foster research endeavours and their practical dissemination in a common, more unified direction.	Arxiv	0	['Julian Frattini', 'Javier Gonzalez-Huerta', 'Daniel Mendez', 'Tony Gorschek', 'Krzysztof Wnuk']
313	Data Quality in Empirical Software Engineering: A Targeted Review	Michael Franklin Bosu	2021-05-23T09:31:47Z	http://arxiv.org/abs/2105.10895v1	Context: The utility of prediction models in empirical software engineering (ESE) is heavily reliant on the quality of the data used in building those models. Several data quality challenges such as noise, incompleteness, outliers and duplicate data points may be relevant in this regard. Objective: We investigate the reporting of three potentially influential elements of data quality in ESE studies: data collection, data pre-processing, and the identification of data quality issues. This enables us to establish how researchers view the topic of data quality and the mechanisms that are being used to address it. Greater awareness of data quality should inform both the sound conduct of ESE research and the robust practice of ESE data collection and processing. Method: We performed a targeted literature review of empirical software engineering studies covering the period January 2007 to September 2012. A total of 221 relevant studies met our inclusion criteria and were characterized in terms of their consideration and treatment of data quality. Results: We obtained useful insights as to how the ESE community considers these three elements of data quality. Only 23 of these 221 studies reported on all three elements of data quality considered in this paper. Conclusion: The reporting of data collection procedures is not documented consistently in ESE studies. It will be useful if data collection challenges are reported in order to improve our understanding of why there are problems with software engineering data sets and the models developed from them. More generally, data quality should be given far greater attention by the community. The improvement of data sets through enhanced data collection, pre-processing and quality assessment should lead to more reliable prediction models, thus improving the practice of software engineering.	Arxiv	0	['Stephen G. MacDonell']
314	Mining Treatment-Outcome Constructs from Sequential Software Engineering Data	Maleknaz Nayebi	2019-01-17T03:40:39Z	http://arxiv.org/abs/1901.05604v1	Many investigations in empirical software engineering look at sequences of data resulting from development or management processes. In this paper, we propose an analytical approach called the Gandhi-Washington Method (GWM) to investigate the impact of recurring events in software projects. GWM takes an encoding of events and activities provided by a software analyst as input. It uses regular expressions to automatically condense and summarize information and infer treatments. Relating the treatments to the outcome through statistical tests, treatment-outcome constructs are automatically mined from the data. The output of GWM is a set of treatment-outcome constructs. Each treatment in the set of mined constructs is significantly different from the other treatments considering the impact on the outcome and/or is structurally different from other treatments considering the sequence of events. We describe GWM and classes of problems to which GWM can be applied. We demonstrate the applicability of this method for empirical studies on sequences of file editing, code ownership, and release cycle time.	Arxiv	0	['Guenther Ruhe', 'Thomas Zimmermann']
315	Game Development Software Engineering Process Life Cycle: A Systematic Review	Saiqa Aleem	2017-11-22T22:37:41Z	http://arxiv.org/abs/1711.08527v1	Software game is a kind of application that is used not only for entertainment, but also for serious purposes that can be applicable to different domains such as education, business, and health care. Although the game development process differs from the traditional software development process because it involves interdisciplinary activities. Software engineering techniques are still important for game development because they can help the developer to achieve maintainability, flexibility, lower effort and cost, and better design. The purpose of this study is to assesses the state of the art research on the game development software engineering process and highlight areas that need further consideration by researchers. In the study, we used a systematic literature review methodology based on well-known digital libraries. The largest number of studies have been reported in the production phase of the game development software engineering process life cycle, followed by the pre-production phase. By contrast, the post-production phase has received much less research activity than the pre-production and production phases. The results of this study suggest that the game development software engineering process has many aspects that need further attention from researchers; that especially includes the postproduction phase.	Arxiv	0	['Luiz Fernando Capretz', 'Faheem Ahmed']
316	Apples, Oranges, and Software Engineering: Study Selection Challenges for Secondary Research on Latent Variables	Marvin Wyrich	2024-02-13T17:32:17Z	http://arxiv.org/abs/2402.08706v1	Software engineering (SE) is full of abstract concepts that are crucial for both researchers and practitioners, such as programming experience, team productivity, code comprehension, and system security. Secondary studies aimed at summarizing research on the influences and consequences of such concepts would therefore be of great value.   However, the inability to measure abstract concepts directly poses a challenge for secondary studies: primary studies in SE can operationalize such concepts in many ways. Standardized measurement instruments are rarely available, and even if they are, many researchers do not use them or do not even provide a definition for the studied concept. SE researchers conducting secondary studies therefore have to decide a) which primary studies intended to measure the same construct, and b) how to compare and aggregate vastly different measurements for the same construct.   In this experience report, we discuss the challenge of study selection in SE secondary research on latent variables. We report on two instances where we found it particularly challenging to decide which primary studies should be included for comparison and synthesis, so as not to end up comparing apples with oranges. Our report aims to spark a conversation about developing strategies to address this issue systematically and pave the way for more efficient and rigorous secondary studies in software engineering.	Arxiv	0	['Marvin Mu√±oz Bar√≥n', 'Justus Bogner']
317	Privacy by Design: Aligning GDPR and Software Engineering Specifications with a Requirements Engineering Approach	Oleksandr Kosenkov	2025-10-24T15:59:34Z	http://arxiv.org/abs/2510.21591v2	Context: Consistent requirements and system specifications are essential for the compliance of software systems towards the General Data Protection Regulation (GDPR). Both artefacts need to be grounded in the original text and conjointly assure the achievement of privacy by design (PbD). Objectives: There is little understanding of the perspectives of practitioners on specification objectives and goals to address PbD. Existing approaches do not account for the complex intersection between problem and solution space expressed in GDPR. In this study we explore the demand for conjoint requirements and system specification for PbD and suggest an approach to address this demand. Methods: We reviewed secondary and related primary studies and conducted interviews with practitioners to (1) investigate the state-of-practice and (2) understand the underlying specification objectives and goals (e.g., traceability). We developed and evaluated an approach for requirements and systems specification for PbD, and evaluated it against the specification objectives. Results: The relationship between problem and solution space, as expressed in GDPR, is instrumental in supporting PbD. We demonstrate how our approach, based on the modeling GDPR content with original legal concepts, contributes to specification objectives of capturing legal knowledge, supporting specification transparency, and traceability. Conclusion: GDPR demands need to be addressed throughout different levels of abstraction in the engineering lifecycle to achieve PbD. Legal knowledge specified in the GDPR text should be captured in specifications to address the demands of different stakeholders and ensure compliance. While our results confirm the suitability of our approach to address practical needs, we also revealed specific needs for the future effective operationalization of the approach.	Arxiv	0	['Ehsan Zabardast', 'Davide Fucci', 'Daniel Mendez', 'Michael Unterkalmsteiner']
318	Sentiment Polarity Detection for Software Development	Fabio Calefato	2017-09-09T17:28:10Z	http://arxiv.org/abs/1709.02984v2	The role of sentiment analysis is increasingly emerging to study software developers' emotions by mining crowd-generated content within social software engineering tools. However, off-the-shelf sentiment analysis tools have been trained on non-technical domains and general-purpose social media, thus resulting in misclassifications of technical jargon and problem reports. Here, we present Senti4SD, a classifier specifically trained to support sentiment analysis in developers' communication channels. Senti4SD is trained and validated using a gold standard of Stack Overflow questions, answers, and comments manually annotated for sentiment polarity. It exploits a suite of both lexicon- and keyword-based features, as well as semantic features based on word embedding. With respect to a mainstream off-the-shelf tool, which we use as a baseline, Senti4SD reduces the misclassifications of neutral and positive posts as emotionally negative. To encourage replications, we release a lab package including the classifier, the word embedding space, and the gold standard with annotation guidelines.	Arxiv	0	['Filippo Lanubile', 'Federico Maiorano', 'Nicole Novielli']
319	Building Bridges: Establishing a Dialogue Between Software Engineering Research and Computational Science	Reed Milewicz	2022-01-11T15:44:50Z	http://arxiv.org/abs/2201.04007v1	There has been growing interest within the computational science and engineering (CSE) community in engaging with software engineering research -- the systematic study of software systems and their development, operation, and maintenance -- to solve challenges in scientific software development. Historically, there has been little interaction between scientific computing and the field, which has held back progress. With the ranks of scientific software teams expanding to include software engineering researchers and practitioners, we can work to build bridges to software science and reap the rewards of evidence-based practice in software development.	Arxiv	0	['Miranda Mundt']
320	Testing Research Software: A Survey	Nasir U. Eisty	2022-05-31T17:40:03Z	http://arxiv.org/abs/2205.15982v1	Background: Research software plays an important role in solving real-life problems, empowering scientific innovations, and handling emergency situations. Therefore, the correctness and trustworthiness of research software are of absolute importance. Software testing is an important activity for identifying problematic code and helping to produce high-quality software. However, testing of research software is difficult due to the complexity of the underlying science, relatively unknown results from scientific algorithms, and the culture of the research software community. Aims: The goal of this paper is to better understand current testing practices, identify challenges, and provide recommendations on how to improve the testing process for research software development. Method: We surveyed members of the research software developer community to collect information regarding their knowledge about and use of software testing in their projects. Results: We analysed 120 responses and identified that even though research software developers report they have an average level of knowledge about software testing, they still find it difficult due to the numerous challenges involved. However, there are a number of ways, such as proper training, that can improve the testing process for research software. Conclusions: Testing can be challenging for any type of software. This difficulty is especially present in the development of research software, where software engineering activities are typically given less attention. To produce trustworthy results from research software, there is a need for a culture change so that testing is valued and teams devote appropriate effort to writing and executing tests.	Arxiv	0	['Jeffrey C. Carver']
321	How Bad Can a Bug Get? An Empirical Analysis of Software Failures in the OpenStack Cloud Computing Platform	Domenico Cotroneo	2019-07-09T09:32:08Z	http://arxiv.org/abs/1907.04055v1	Cloud management systems provide abstractions and APIs for programmatically configuring cloud infrastructures. Unfortunately, residual software bugs in these systems can potentially lead to high-severity failures, such as prolonged outages and data losses. In this paper, we investigate the impact of failures in the context widespread OpenStack cloud management system, by performing fault injection and by analyzing the impact of the resulting failures in terms of fail-stop behavior, failure detection through logging, and failure propagation across components. The analysis points out that most of the failures are not timely detected and notified; moreover, many of these failures can silently propagate over time and through components of the cloud management system, which call for more thorough run-time checks and fault containment.	Arxiv	0	['Luigi De Simone', 'Pietro Liguori', 'Roberto Natella', 'Nematollah Bidokhti']
322	Improving Software Engineering Research through Experimentation Workbenches	Klaus Schmid	2021-10-25T13:16:14Z	http://arxiv.org/abs/2110.12937v1	Experimentation with software prototypes plays a fundamental role in software engineering research. In contrast to many other scientific disciplines, however, explicit support for this key activity in software engineering is relatively small. While some approaches to improve this situation have been proposed by the software engineering community, experiments are still very difficult and sometimes impossible to replicate. In this paper, we propose the concept of an experimentation workbench as a means of explicit support for experimentation in software engineering research. In particular, we discuss core requirements that an experimentation workbench should satisfy in order to qualify as such and to offer a real benefit for researchers. Beyond their core benefits for experimentation, we stipulate that experimentation workbenches will also have benefits in regard to reproducibility and repeatability of software engineering research. Further, we illustrate this concept with a scenario and a case study, and describe relevant challenges as well as our experience with experimentation workbenches.	Arxiv	0	['Sascha El-Sharkawy', 'Christian Kr√∂her']
323	Applying empirical software engineering to software architecture: challenges and lessons learned	Davide Falessi	2017-01-21T09:09:07Z	http://arxiv.org/abs/1701.06000v1	In the last 15 years, software architecture has emerged as an important software engineering field for managing the development and maintenance of large, software- intensive systems. Software architecture community has developed numerous methods, techniques, and tools to support the architecture process (analysis, design, and review). Historically, most advances in software architecture have been driven by talented people and industrial experience, but there is now a growing need to systematically gather empirical evidence about the advantages or otherwise of tools and methods rather than just rely on promotional anecdotes or rhetoric. The aim of this paper is to promote and facilitate the application of the empirical paradigm to software architecture. To this end, we describe the challenges and lessons learned when assessing software architecture research that used controlled experiments, replications, expert opinion, systematic literature reviews, obser- vational studies, and surveys. Our research will support the emergence of a body of knowledge consisting of the more widely-accepted and well-formed software architecture theories.	Arxiv	0	['Muhammad Ali Babar', 'Giovanni Cantone', 'Philippe Kruchten']
324	Empirical Software Engineering: From Discipline to Interdiscipline	Daniel M√©ndez Fern√°ndez	2018-05-21T21:55:24Z	http://arxiv.org/abs/1805.08302v3	Empirical software engineering has received much attention in recent years and coined the shift from a more design-science-driven engineering discipline to an insight-oriented, and theory-centric one. Yet, we still face many challenges, among which some increase the need for interdisciplinary research. This is especially true for the investigation of human-centric aspects of software engineering. Although we can already observe an increased recognition of the need for more interdisciplinary research in (empirical) software engineering, such research configurations come with challenges barely discussed from a scientific point of view. In this position paper, we critically reflect upon the epistemological setting of empirical software engineering and elaborate its configuration as an Interdiscipline. In particular, we (1) elaborate a pragmatic view on empirical research for software engineering reflecting a cyclic process for knowledge creation, (2) motivate a path towards symmetrical interdisciplinary research, and (3) adopt five rules of thumb from other interdisciplinary collaborations in our field before concluding with new emerging challenges. This shall support stopping to treating empirical software engineering as a developing discipline moving towards a paradigmatic stage of normal science, but as a configuration of symmetric interdisciplinary teams and research methods.	Arxiv	0	['Jan-Hendrik Passoth']
325	Bayesian data analysis in empirical software engineering---The case of missing data	Richard Torkar	2019-04-01T09:40:06Z	http://arxiv.org/abs/1904.00661v3	Bayesian data analysis (BDA) is today used by a multitude of research disciplines. These disciplines use BDA as a way to embrace uncertainty by using multilevel models and making use of all available information at hand. In this chapter, we first introduce the reader to BDA and then provide an example from empirical software engineering, where we also deal with a common issue in our field, i.e., missing data.   The example we make use of presents the steps done when conducting state of the art statistical analysis. First, we need to understand the problem we want to solve. Second, we conduct causal analysis. Third, we analyze non-identifiability. Fourth, we conduct missing data analysis. Finally, we do a sensitivity analysis of priors. All this before we design our statistical model. Once we have a model, we present several diagnostics one can use to conduct sanity checks.   We hope that through these examples, the reader will see the advantages of using BDA. This way, we hope Bayesian statistics will become more prevalent in our field, thus partly avoiding the reproducibility crisis we have seen in other disciplines.	Arxiv	0	['Robert Feldt', 'Carlo A. Furia']
326	On Gender, Ethnicity, and Culture in Empirical Software Engineering Research	Lucas Gren	2019-04-05T19:09:09Z	http://arxiv.org/abs/1904.09820v1	This note highlights the importance of investigating diversity aspects in combination in empirical research. It draws on the psychological discourse and suggests why and how software engineering scholars can use the aspect of diversity in all their research endeavors.	Arxiv	0	[]
327	How Many Papers Should You Review? A Research Synthesis of Systematic Literature Reviews in Software Engineering	Xiaofeng Wang	2023-07-12T10:18:58Z	http://arxiv.org/abs/2307.06056v1	[Context] Systematic Literature Review (SLR) has been a major type of study published in Software Engineering (SE) venues for about two decades. However, there is a lack of understanding of whether an SLR is really needed in comparison to a more conventional literature review. Very often, SE researchers embark on an SLR with such doubts. We aspire to provide more understanding of when an SLR in SE should be conducted. [Objective] The first step of our investigation was focused on the dataset, i.e., the reviewed papers, in an SLR, which indicates the development of a research topic or area. The objective of this step is to provide a better understanding of the characteristics of the datasets of SLRs in SE. [Method] A research synthesis was conducted on a sample of 170 SLRs published in top-tier SE journals. We extracted and analysed the quantitative attributes of the datasets of these SLRs. [Results] The findings show that the median size of the datasets in our sample is 57 reviewed papers, and the median review period covered is 14 years. The number of reviewed papers and review period have a very weak and non-significant positive correlation. [Conclusions] The results of our study can be used by SE researchers as an indicator or benchmark to understand whether an SLR is conducted at a good time.	Arxiv	0	['Henry Edison', 'Dron Khanna', 'Usman Rafiq']
328	The Essence Theory of Software Engineering - Large-Scale Classroom Experiences from 450+ Software Engineering BSc Students	Kai-Kristian Kemell	2018-09-24T10:11:32Z	http://arxiv.org/abs/1809.08827v1	Software Engineering as an industry is highly diverse in terms of development methods and practices. Practitioners employ a myriad of methods and tend to further tailor them by e.g. omitting some practices or rules. This diversity in development methods poses a challenge for software engineering education, creating a gap between education and industry. General theories such as the Essence Theory of Software Engineering can help bridge this gap by presenting software engineering students with higher-level frameworks upon which to build an understanding of software engineering methods and practical project work. In this paper, we study Essence in an educational setting to evaluate its usefulness for software engineering students while also investigating barriers to its adoption in this context. To this end, we observe 102 student teams utilize Essence in practical software engineering projects during a semester long, project-based course.	Arxiv	0	['Anh Nguyen-Duc', 'Xiaofeng Wang', 'Juhanki Risku', 'Pekka Abrahamsson']
329	Sustaining Research Software via Research Software Engineers and Professional Associations	Jeffrey C. Carver	2021-03-02T17:24:45Z	http://arxiv.org/abs/2103.01880v1	Research software is a class of software developed to support research. Today a wealth of such software is created daily in universities, government, and commercial research enterprises worldwide. The sustainability of this software faces particular challenges due, at least in part, to the type of people who develop it. These Research Software Engineers (RSEs) face challenges in developing and sustaining software that differ from those faced by the developers of traditional software. As a result, professional associations have begun to provide support, advocacy, and resources for RSEs. These benefits are critical to sustaining RSEs, especially in environments where their contributions are often undervalued and not rewarded. This paper focuses on how professional associations, such as the United States Research Software Engineer Association (US-RSE), can provide this.	Arxiv	0	['Ian A. Cosden', 'Chris Hill', 'Sandra Gesing', 'Daniel S. Katz']
330	The EmpathiSEr: Development and Validation of Software Engineering Oriented Empathy Scales	Hashini Gunatilake	2025-10-14T14:10:14Z	http://arxiv.org/abs/2510.12546v1	Empathy plays a critical role in software engineering (SE), influencing collaboration, communication, and user-centred design. Although SE research has increasingly recognised empathy as a key human aspect, there remains no validated instrument specifically designed to measure it within the unique socio-technical contexts of SE. Existing generic empathy scales, while well-established in psychology and healthcare, often rely on language, scenarios, and assumptions that are not meaningful or interpretable for software practitioners. These scales fail to account for the diverse, role-specific, and domain-bound expressions of empathy in SE, such as understanding a non-technical user's frustrations or another practitioner's technical constraints, which differ substantially from empathy in clinical or everyday contexts. To address this gap, we developed and validated two domain-specific empathy scales: EmpathiSEr-P, assessing empathy among practitioners, and EmpathiSEr-U, capturing practitioner empathy towards users. Grounded in a practitioner-informed conceptual framework, the scales encompass three dimensions of empathy: cognitive empathy, affective empathy, and empathic responses. We followed a rigorous, multi-phase methodology, including expert evaluation, cognitive interviews, and two practitioner surveys. The resulting instruments represent the first psychometrically validated empathy scales tailored to SE, offering researchers and practitioners a tool for assessing empathy and designing empathy-enhancing interventions in software teams and user interactions.	Arxiv	0	['John Grundy', 'Rashina Hoda', 'Ingo Mueller']
331	Term Interrelations and Trends in Software Engineering	Janusan Baskararajah	2021-08-21T15:35:57Z	http://arxiv.org/abs/2108.09529v1	The Software Engineering (SE) community is prolific, making it challenging for experts to keep up with the flood of new papers and for neophytes to enter the field. Therefore, we posit that the community may benefit from a tool extracting terms and their interrelations from the SE community's text corpus and showing terms' trends. In this paper, we build a prototyping tool using the word embedding technique. We train the embeddings on the SE Body of Knowledge handbook and 15,233 research papers' titles and abstracts. We also create test cases necessary for validation of the training of the embeddings. We provide representative examples showing that the embeddings may aid in summarizing terms and uncovering trends in the knowledge base.	Arxiv	0	['Lei Zhang', 'Andriy Miranskyy']
332	Some things never change: how far generative AI can really change software engineering practice	Aline de Campos	2024-06-14T05:26:42Z	http://arxiv.org/abs/2406.09725v1	Generative Artificial Intelligence (GenAI) has become an emerging technology with the availability of several tools that could impact Software Engineering (SE) activities. As any other disruptive technology, GenAI led to the speculation that its full potential can deeply change SE. However, an overfocus on improving activities for which GenAI is more suitable could negligent other relevant areas of the process. In this paper, we aim to explore which SE activities are not expected to be profoundly changed by GenAI. To achieve this goal, we performed a survey with SE practitioners to identify their expectations regarding GenAI in SE, including impacts, challenges, ethical issues, and aspects they do not expect to change. We compared our results with previous roadmaps proposed in SE literature. Our results show that although practitioners expect an increase in productivity, coding, and process quality, they envision that some aspects will not change, such as the need for human expertise, creativity, and project management. Our results point to SE areas for which GenAI is probably not so useful, and future research could tackle them to improve SE practice.	Arxiv	0	['Jorge Melegati', 'Nicolas Nascimento', 'Rafael Chanin', 'Afonso Sales', 'Igor Wiese']
333	Characterizing the Experience of Subjects in Software Engineering Studies	Rafael de Mello	2021-10-06T15:09:36Z	http://arxiv.org/abs/2110.02835v1	Context: Empirical studies in software engineering are typically centered on human subjects, ranging from novice to experienced developers. The experience of these individuals is a key context factor that should be properly characterized for supporting the design of empirical studies and interpreting their results. However, the criteria adopted for characterizing the experience of subjects do not follow a standard and are frequently limited. Goal: Our research aims at establishing an optimized and comprehensive scheme to characterize the subjects' experience for studies in software engineering. Method: Based on previous work, we defined the first version of this scheme, composed of three experience attributes, including time, number of projects, and self-perception. In the last years, we applied the characterization scheme over four empirical studies, reaching the characterization of 79 subjects in three different skills. Results: We found that the attributes from our scheme are positively but moderately correlated. This finding suggests these attributes play a complementary role in characterizing the subjects' experience. Besides, we found that study subjects tend to enumerate the technical diversity of their background when summarizing their professional experience. Conclusion: The scheme proposed represents a feasible alternative for characterizing subjects of empirical studies in the field. However, we intend to conduct additional investigations with developers to evolve it.	Arxiv	0	['Matheus Coelho']
334	Action Research with Industrial Software Engineering -- An Educational Perspective	Yvonne Dittrich	2024-07-05T17:05:06Z	http://arxiv.org/abs/2407.04650v2	Action research provides the opportunity to explore the usefulness and usability of software engineering methods in industrial settings, and makes it possible to develop methods, tools and techniques with software engineering practitioners. However, as the research moves beyond the observational approach, it requires a different kind of interaction with the software development organisation. This makes action research a challenging endeavour, and it makes it difficult to teach action research through a course that goes beyond explaining the principles.   This chapter is intended to support learning and teaching action research, by providing a rich set of examples, and identifying tools that we found helpful in our action research projects. The core of this chapter focusses on our interaction with the participating developers and domain experts, and the organisational setting.   This chapter is structured around a set of challenges that reoccurred in the action research projects in which the authors participated. Each section is accompanied by a toolkit that presents related techniques and tools. The exercises are designed to explore the topics, and practise using the tools and techniques presented. We hope the material in this chapter encourages researchers who are new to action research to further explore this promising opportunity.	Arxiv	0	['Johan Bolmsten', 'Catherine Seidelin']
335	Packaged Software Implementation Requirements Engineering by Small Software Enterprises	Issam Jebreen	2021-06-07T02:26:48Z	http://arxiv.org/abs/2106.03304v1	Small to medium sized business enterprises (SMEs) generally thrive because they have successfully done something unique within a niche market. For this reason, SMEs may seek to protect their competitive advantage by avoiding any standardization encouraged by the use of packaged software (PS). Packaged software implementation at SMEs therefore presents challenges relating to how best to respond to misfits between the functionality offered by the packaged software and each SME's business needs. An important question relates to which processes small software enterprises - or Small to Medium-Sized Software Development Companies (SMSSDCs) - apply in order to identify and then deal with these misfits. To explore the processes of packaged software (PS) implementation, an ethnographic study was conducted to gain in-depth insights into the roles played by analysts in two SMSSDCs. The purpose of the study was to understand PS implementation in terms of requirements engineering (or 'PSIRE'). Data collected during the ethnographic study were analyzed using an inductive approach. Based on our analysis of the cases we constructed a theoretical model explaining the requirements engineering process for PS implementation, and named it the PSIRE Parallel Star Model. The Parallel Star Model shows that during PSIRE, more than one RE process can be carried out at the same time. The Parallel Star Model has few constraints, because not only can processes be carried out in parallel, but they do not always have to be followed in a particular order. This paper therefore offers a novel investigation and explanation of RE practices for packaged software implementation, approaching the phenomenon from the viewpoint of the analysts, and offers the first extensive study of packaged software implementation RE (PSIRE) in SMSSDCs.	Arxiv	0	['Robert Wellington', 'Stephen G. MacDonell']
336	Treat societally impactful scientific insights as open-source software artifacts	Cynthia C. S. Liem	2023-02-11T12:03:43Z	http://arxiv.org/abs/2302.05669v1	So far, the relationship between open science and software engineering expertise has largely focused on the open release of software engineering research insights and reproducible artifacts, in the form of open-access papers, open data, and open-source tools and libraries. In this position paper, we draw attention to another perspective: scientific insight itself is a complex and collaborative artifact under continuous development and in need of continuous quality assurance, and as such, has many parallels to software artifacts. Considering current calls for more open, collaborative and reproducible science; increasing demands for public accountability on matters of scientific integrity and credibility; methodological challenges coming with transdisciplinary science; political and communication tensions when scientific insight on societally relevant topics is to be translated to policy; and struggles to incentivize and reward academics who truly want to move into these directions beyond traditional publishing habits and cultures, we make the parallels between the emerging open science requirements and concepts already well-known in (open-source) software engineering research more explicit. We argue that the societal impact of software engineering expertise can reach far beyond the software engineering research community, and call upon the community members to pro-actively help driving the necessary systems and cultural changes towards more open and accountable research.	Arxiv	0	['Andrew M. Demetriou']
337	Understanding the Affect of Developers: Theoretical Background and Guidelines for Psychoempirical Software Engineering	Daniel Graziotin	2015-07-14T08:44:54Z	http://arxiv.org/abs/1507.03767v2	"Affects---emotions and moods---have an impact on cognitive processing activities and the working performance of individuals. It has been established that software development tasks are undertaken through cognitive processing activities. Therefore, we have proposed to employ psychology theory and measurements in software engineering (SE) research. We have called it ""psychoempirical software engineering"". However, we found out that existing SE research has often fallen into misconceptions about the affect of developers, lacking in background theory and how to successfully employ psychological measurements in studies. The contribution of this paper is threefold. (1) It highlights the challenges to conduct proper affect-related studies with psychology; (2) it provides a comprehensive literature review in affect theory; and (3) it proposes guidelines for conducting psychoempirical software engineering."	Arxiv	0	['Xiaofeng Wang', 'Pekka Abrahamsson']
338	Guidelines for Empirical Studies in Software Engineering involving Large Language Models	Sebastian Baltes	2025-08-21T12:30:30Z	http://arxiv.org/abs/2508.15503v3	Large language models (LLMs) are increasingly being integrated into software engineering (SE) research and practice, yet their non-determinism, opaque training data, and evolving architectures complicate the reproduction and replication of empirical studies. We present a community effort to scope this space, introducing a taxonomy of LLM-based study types together with eight guidelines for designing and reporting empirical studies involving LLMs. The guidelines present essential (must) criteria as well as desired (should) criteria and target transparency throughout the research process. Our recommendations, contextualized by our study types, are: (1) to declare LLM usage and role; (2) to report model versions, configurations, and fine-tuning; (3) to document tool architectures; (4) to disclose prompts and interaction logs; (5) to use human validation; (6) to employ an open LLM as a baseline; (7) to use suitable baselines, benchmarks, and metrics; and (8) to openly articulate limitations and mitigations. Our goal is to enable reproducibility and replicability despite LLM-specific barriers to open science. We maintain the study types and guidelines online as a living resource for the community to use and shape (llm-guidelines.org).	Arxiv	0	['Florian Angermeir', 'Chetan Arora', 'Marvin Mu√±oz Bar√≥n', 'Chunyang Chen', 'Lukas B√∂hme', 'Fabio Calefato', 'Neil Ernst', 'Davide Falessi', 'Brian Fitzgerald', 'Davide Fucci', 'Marcos Kalinowski', 'Stefano Lambiase', 'Daniel Russo', 'Mircea Lungu', 'Lutz Prechelt', 'Paul Ralph', 'Rijnard van Tonder', 'Christoph Treude', 'Stefan Wagner']
339	SEntiMoji: An Emoji-Powered Learning Approach for Sentiment Analysis in Software Engineering	Zhenpeng Chen	2019-07-04T03:38:41Z	http://arxiv.org/abs/1907.02202v1	Sentiment analysis has various application scenarios in software engineering (SE), such as detecting developers' emotions in commit messages and identifying their opinions on Q&A forums. However, commonly used out-of-the-box sentiment analysis tools cannot obtain reliable results on SE tasks and the misunderstanding of technical jargon is demonstrated to be the main reason. Then, researchers have to utilize labeled SE-related texts to customize sentiment analysis for SE tasks via a variety of algorithms. However, the scarce labeled data can cover only very limited expressions and thus cannot guarantee the analysis quality. To address such a problem, we turn to the easily available emoji usage data for help. More specifically, we employ emotional emojis as noisy labels of sentiments and propose a representation learning approach that uses both Tweets and GitHub posts containing emojis to learn sentiment-aware representations for SE-related texts. These emoji-labeled posts can not only supply the technical jargon, but also incorporate more general sentiment patterns shared across domains. They as well as labeled data are used to learn the final sentiment classifier. Compared to the existing sentiment analysis methods used in SE, the proposed approach can achieve significant improvement on representative benchmark datasets. By further contrast experiments, we find that the Tweets make a key contribution to the power of our approach. This finding informs future research not to unilaterally pursue the domain-specific resource, but try to transform knowledge from the open domain through ubiquitous signals such as emojis.	Arxiv	0	['Yanbin Cao', 'Xuan Lu', 'Qiaozhu Mei', 'Xuanzhe Liu']
340	An Empirical Comparison of Developer Retention in the RubyGems and npm Software Ecosystems	Eleni Constantinou	2017-08-08T19:34:24Z	http://arxiv.org/abs/1708.02618v1	Software ecosystems can be viewed as socio-technical networks consisting of technical components (software packages) and social components (communities of developers) that maintain the technical components. Ecosystems evolve over time through socio-technical changes that may greatly impact the ecosystem's sustainability. Social changes like developer turnover may lead to technical degradation. This motivates the need to identify those factors leading to developer abandonment, in order to automate the process of identifying developers with high abandonment risk. This paper compares such factors for two software package ecosystems, RubyGems and npm. We analyse the evolution of their packages hosted on GitHub, considering development activity in terms of commits, and social interaction with other developers in terms of comments associated to commits, issues or pull requests. We analyse this socio-technical activity for more than 30k and 60k developers for RubyGems and npm respectively. We use survival analysis to identify which factors coincide with a lower survival probability. Our results reveal that developers with a higher probability to abandon an ecosystem: do not engage in discussions with other developers; do not have strong social and technical activity intensity; communicate or commit less frequently; and do not participate to both technical and social activities for long periods of time. Such observations could be used to automate the identification of developers with a high probability of abandoning the ecosystem and, as such, reduce the risks associated to knowledge loss.	Arxiv	0	['Tom Mens']
341	Beyond Accuracy: Assessing Software Documentation Quality	Christoph Treude	2020-07-21T12:15:52Z	http://arxiv.org/abs/2007.10744v3	"Good software documentation encourages good software engineering, but the meaning of ""good"" documentation is vaguely defined in the software engineering literature. To clarify this ambiguity, we draw on work from the data and information quality community to propose a framework that decomposes documentation quality into ten dimensions of structure, content, and style. To demonstrate its application, we recruited technical editors to apply the framework when evaluating examples from several genres of software documentation. We summarise their assessments -- for example, reference documentation and README files excel in quality whereas blog articles have more problems -- and we describe our vision for reasoning about software documentation quality and for the expansion and potential of a unified quality framework."	Arxiv	0	['Justin Middleton', 'Thushari Atapattu']
342	Manifestations of Empathy in Software Engineering: How, Why, and When It Matters	Hashini Gunatilake	2025-08-06T14:30:02Z	http://arxiv.org/abs/2508.04479v2	Empathy plays a crucial role in software engineering (SE), influencing collaboration, communication, and decision-making. While prior research has highlighted the importance of empathy in SE, there is limited understanding of how empathy manifests in SE practice, what motivates SE practitioners to demonstrate empathy, and the factors that influence empathy in SE work. Our study explores these aspects through 22 interviews and a large scale survey with 116 software practitioners. Our findings provide insights into the expression of empathy in SE, the drivers behind empathetic practices, SE activities where empathy is perceived as useful or not, and the other factors that influence empathy. In addition, we offer practical implications for SE practitioners and researchers, offering a deeper understanding of how to effectively integrate empathy into SE processes.	Arxiv	0	['John Grundy', 'Rashina Hoda', 'Ingo Mueller']
343	Applications of Causality and Causal Inference in Software Engineering	Patrick Chadbourne	2023-03-29T19:38:19Z	http://arxiv.org/abs/2303.16989v1	Causal inference is a study of causal relationships between events and the statistical study of inferring these relationships through interventions and other statistical techniques. Causal reasoning is any line of work toward determining causal relationships, including causal inference. This paper explores the relationship between causal reasoning and various fields of software engineering. This paper aims to uncover which software engineering fields are currently benefiting from the study of causal inference and causal reasoning, as well as which aspects of various problems are best addressed using this methodology. With this information, this paper also aims to find future subjects and fields that would benefit from this form of reasoning and to provide that information to future researchers. This paper follows a systematic literature review, including; the formulation of a search query, inclusion and exclusion criteria of the search results, clarifying questions answered by the found literature, and synthesizing the results from the literature review. Through close examination of the 45 found papers relevant to the research questions, it was revealed that the majority of causal reasoning as related to software engineering is related to testing through root cause localization. Furthermore, most causal reasoning is done informally through an exploratory process of forming a Causality Graph as opposed to strict statistical analysis or introduction of interventions. Finally, causal reasoning is also used as a justification for many tools intended to make the software more human-readable by providing additional causal information to logging processes or modeling languages.	Arxiv	0	['Nasir Eisty']
344	What Pakistani Computer Science and Software Engineering Students Think about Software Testing?	Luiz Fernando Capretz	2023-06-01T16:55:01Z	http://arxiv.org/abs/2306.01033v1	Software testing is one of the crucial supporting processes of the software life cycle. Unfortunately for the software industry, the role is stigmatized, partly due to misperception and partly due to treatment of the role. The present study aims to analyze the situation to explore what restricts computer science and software engineering students from taking up a testing career in the software industry. To conduct this study, we surveyed 88 Pakistani students taking computer science or software engineering degrees. The results showed that the present study supports previous work into the unpopularity of testing compared to other software life cycle roles. Furthermore, the findings of our study showed that the role of tester has become a social role, with as many social connotations as technical implications.	Arxiv	0	['Abdul Rehman Gilal']
345	A Study about the Knowledge and Use of Requirements Engineering Standards in Industry	Xavier Franch	2021-05-28T16:31:25Z	http://arxiv.org/abs/2105.13961v3	Context: The use of standards is considered a vital part of any engineering discipline. So one could expect that standards play an important role in Requirements Engineering (RE) as well. However, little is known about the actual knowledge and use of RE-related standards in industry. Objective: In this article, we investigate to which extent standards and related artifacts such as templates or guidelines are known and used by RE practitioners. Method: To this end, we have conducted a questionnaire-based online survey. We could analyze the replies from 90 RE practitioners using a combination of closed and open-text questions. Results: Our results indicate that the knowledge and use of standards and related artifacts in RE is less widespread than one might expect from an engineering perspective. For example, about 47% of the respondents working as requirements engineers or business analysts do not know the core standard in RE, ISO/IEC/IEEE 29148. Participants in our study mostly use standards by personal decision rather than being imposed by their respective company, customer, or regulator. Beyond insufficient knowledge, we also found cultural and organizational factors impeding the widespread adoption of standards in RE. Conclusions: Overall, our results provide empirically informed insights into the actual use of standards and related artifacts in RE practice and - indirectly - about the value that the current standards create for RE practitioners.	Arxiv	0	['Martin Glinz', 'Daniel Mendez', 'Norbert Seyff']
346	Quantum Computing for Software Engineering: Prospects	Andriy Miranskyy	2022-03-07T18:16:48Z	http://arxiv.org/abs/2203.03575v3	Quantum computers (QCs) are maturing. When QCs are powerful enough, they may be able to handle problems in chemistry, physics, and finance that are not classically solvable. However, the applicability of quantum algorithms to speed up Software Engineering (SE) tasks has not been explored. We examine eight groups of quantum algorithms that may accelerate SE tasks across the different phases of SE and sketch potential opportunities and challenges.	Arxiv	0	['Mushahid Khan', 'Jean Paul Latyr Faye', 'Udson C. Mendes']
347	Modeling Uncertainty and Evolving Self-Adaptive Software: A Fuzzy Theory Based Requirements Engineering Approach	Zhuoqun Yang	2017-04-04T04:53:10Z	http://arxiv.org/abs/1704.00873v1	Self-adaptive software (SAS) is capable of adjusting its behavior in response to meaningful changes in the operational context and itself. Due to the inherent volatility of the open and changeable environment in which SAS is embedded, the ability of adaptation is highly demanded by many software-intensive systems. Two concerns, i.e., the requirements uncertainty and the context uncertainty are most important among others at Requirements Engineering (RE) stage. However, requirements analyzers can hardly figure out the mathematical relation between requirements, system behavior and context, especially for complex and nonlinear systems, due to the existence of above uncertainties, misunderstanding and ambiguity of prior knowledge. An essential issue to be addressed is how to model and specify these uncertainties at RE stage and how to utilize the prior knowledge to achieve adaptation. In this paper, we propose a fuzzy-based approach to modeling uncertainty and achieving evolution. The approach introduces specifications to describe fuzziness. Based on the specifications, we derive a series of reasoning rules as knowledge base for achieving adaptation and evolution. These two targets are implemented through four reasoning schemas from a control theory perspective. Specifically, forward reasoning schema is used for direct adaptation; backward reasoning schema is used for optimal adaptation. Parameter-identified schema implements learning evolution by considering SAS as the gray-box system, while system-identified reasoning schema implements learning evolution by considering SAS as the gray-box system. The former two schemas function as the control group, while the latter two are de-signed as the experimental groups to illustrate the learning ability. Our approach is implemented under three types of context through the demonstration of a mobile computing application.	Arxiv	0	['Zhi Jin', 'Zhi Li']
348	Leveraging Creativity as a Problem Solving Tool in Software Engineering	Wouter Groeneveld	2025-02-05T15:35:33Z	http://arxiv.org/abs/2502.03280v1	Today's software engineering (SE) complexities require a more diverse tool set going beyond technical expertise to be able to successfully tackle all challenges. Previous studies have indicated that creativity is a prime indicator for overcoming these hurdles. In this paper, we port results from creativity research in the field of cognitive psychology to the field of SE. After all, programming is a highly creative endeavour. We explore how to leverage creativity as a practical problem solving tool to wield for software developers. The seven distinct but intertwined creative problem solving themes unfolded in this paper are accompanied with practical perspectives, specifically geared for software professionals. Just like technical skills such as knowledge of programming languages, we believe that creativity can be learned and improved with practice.	Arxiv	0	[]
349	How Tertiary Studies perform Quality Assessment of Secondary Studies in Software Engineering	Dolors Costal	2021-10-07T22:45:30Z	http://arxiv.org/abs/2110.03820v1	Context: Tertiary studies are becoming increasingly popular in software engineering as an instrument to synthesise evidence on a research topic in a systematic way. In order to understand and contextualize their findings, it is important to assess the quality of the selected secondary studies. Objective: This paper aims to provide a state of the art on the assessment of secondary studies' quality as conducted in tertiary studies in the area of software engineering, reporting the frameworks used as instruments, the facets examined in these frameworks, and the purposes of the quality assessment. Method: We designed this study as a systematic mapping responding to four research questions derived from the objective above. We applied a rigorous search protocol over the Scopus digital library, resulting in 47 papers after application of inclusion and exclusion criteria. The extracted data was synthesised using content analysis. Results: A majority of tertiary studies perform quality assessment. It is not often used for excluding studies, but to support some kind of investigation. The DARE quality assessment framework is the most frequently used, with customizations in some cases to cover missing facets. We outline the first steps towards building a new framework to address the shortcomings identified. Conclusion: This paper is a step forward establishing a foundation for researchers in two different ways. As authors of tertiary studies, understanding the different possibilities in which they can perform quality assessment of secondary studies. As readers, having an instrument to understand the methodological rigor upon which tertiary studies may claim their findings.	Arxiv	0	['Carles Farr√©', 'Xavier Franch', 'Carme Quer']
350	Software Artifact Mining in Software Engineering Conferences: A Meta-Analysis	Zeinab Abou Khalil	2022-07-18T08:41:52Z	http://arxiv.org/abs/2207.08436v1	Background: Software development results in the production of various types of artifacts: source code, version control system metadata, bug reports, mailing list conversations, test data, etc. Empirical software engineering (ESE) has thrived mining those artifacts to uncover the inner workings of software development and improve its practices. But which artifacts are studied in the field is a moving target, which we study empirically in this paper.Aims: We quantitatively characterize the most frequently mined and co-mined software artifacts in ESE research and the research purposes they support.Method: We conduct a meta-analysis of artifact mining studies published in 11 top conferences in ESE, for a total of 9621 papers. We use natural language processing (NLP) techniques to characterize the types of software artifacts that are most often mined and their evolution over a 16-year period (2004-2020). We analyze the combinations of artifact types that are most often mined together, as well as the relationship between study purposes and mined artifacts.Results: We find that: (1) mining happens in the vast majority of analyzed papers, (2) source code and test data are the most mined artifacts, (3) there is an increasing interest in mining novel artifacts, together with source code, (4) researchers are most interested in the evaluation of software systems and use all possible empirical signals to support that goal.	Arxiv	0	['Stefano Zacchiroli']
351	Generative AI and Empirical Software Engineering: A Paradigm Shift	Christoph Treude	2025-02-12T04:13:07Z	http://arxiv.org/abs/2502.08108v2	"The adoption of large language models (LLMs) and autonomous agents in software engineering marks an enduring paradigm shift. These systems create new opportunities for tool design, workflow orchestration, and empirical observation, while fundamentally reshaping the roles of developers and the artifacts they produce. Although traditional empirical methods remain central to software engineering research, the rapid evolution of AI introduces new data modalities, alters causal assumptions, and challenges foundational constructs such as ""developer"", ""artifact"", and ""interaction"". As humans and AI agents increasingly co-create, the boundaries between social and technical actors blur, and the reproducibility of findings becomes contingent on model updates and prompt contexts. This vision paper examines how the integration of LLMs into software engineering disrupts established research paradigms. We discuss how it transforms the phenomena we study, the methods and theories we rely on, the data we analyze, and the threats to validity that arise in dynamic AI-mediated environments. Our aim is to help the empirical software engineering community adapt its questions, instruments, and validation standards to a future in which AI systems are not merely tools, but active collaborators shaping software engineering and its study."	Arxiv	0	['Margaret-Anne Storey']
352	Making Fair ML Software using Trustworthy Explanation	Joymallya Chakraborty	2020-07-06T17:12:30Z	http://arxiv.org/abs/2007.02893v2	Machine learning software is being used in many applications (finance, hiring, admissions, criminal justice) having a huge social impact. But sometimes the behavior of this software is biased and it shows discrimination based on some sensitive attributes such as sex, race, etc. Prior works concentrated on finding and mitigating bias in ML models. A recent trend is using instance-based model-agnostic explanation methods such as LIME to find out bias in the model prediction. Our work concentrates on finding shortcomings of current bias measures and explanation methods. We show how our proposed method based on K nearest neighbors can overcome those shortcomings and find the underlying bias of black-box models. Our results are more trustworthy and helpful for the practitioners. Finally, We describe our future framework combining explanation and planning to build fair software.	Arxiv	0	['Kewen Peng', 'Tim Menzies']
353	Research Software Science: Expanding the Impact of Research Software Engineering	Michael A. Heroux	2022-11-16T16:44:23Z	http://arxiv.org/abs/2211.09034v1	Software plays a central role in scientific discovery. Improving how we develop and use software for research can have both broad and deep impacts on a spectrum of challenges and opportunities society faces today. The emergence of Research Software Engineer (RSE) as a role correlates with the growing complexity of scientific challenges and diversity of software team skills. In this paper, we describe research software science (RSS), an idea related to RSE, and particularly suited to research software teams. RSS promotes the use of scientific methodologies to explore and establish broadly applicable knowledge. Using RSS, we can pursue sustainable, repeatable, and reproducible software improvements that positively impact research software toward improved scientific discovery.	Arxiv	0	[]
354	The General Index of Software Engineering Papers	Zeinab Abou Khalil	2022-04-07T06:52:35Z	http://arxiv.org/abs/2204.03254v1	We introduce the General Index of Software Engineering Papers, a dataset of fulltext-indexed papers from the most prominent scientific venues in the field of Software Engineering. The dataset includes both complete bibliographic information and indexed ngrams (sequence of contiguous words after removal of stopwords and non-words, for a total of 577 276 382 unique n-grams in this release) with length 1 to 5 for 44 581 papers retrieved from 34 venues over the 1971-2020 period.The dataset serves use cases in the field of meta-research, allowing to introspect the output of software engineering research even when access to papers or scholarly search engines is not possible (e.g., due to contractual reasons). The dataset also contributes to making such analyses reproducible and independently verifiable, as opposed to what happens when they are conducted using 3rd-party and non-open scholarly indexing services.The dataset is available as a portable Postgres database dump and released as open data.	Arxiv	0	['Stefano Zacchiroli']
355	Battle of the Blocs: Quantity and Quality of Software Engineering Research by Origin	Lorenz Graf-Vlachy	2023-03-13T21:07:16Z	http://arxiv.org/abs/2303.07467v1	Software engineering capabilities are increasingly important to the success of economic and political blocs. This paper analyzes quantity and quality of software engineering research output originating from the US, Europe, and China over time. The results indicate that the quantity of research is increasing across the board with Europe leading the field. Depending of the scope of the analysis, either the US or China come in second. Regarding research quality, Europe appears to be lagging the other blocs, with China having caught up to and even having overtaken the US over time.	Arxiv	0	[]
356	Reflections on Software Failure Analysis	Paschal C. Amusuo	2022-09-07T04:51:34Z	http://arxiv.org/abs/2209.02930v2	Failure studies are important in revealing the root causes, behaviors, and life cycle of defects in software systems. These studies either focus on understanding the characteristics of defects in specific classes of systems or the characteristics of a specific type of defect in the systems it manifests in. Failure studies have influenced various software engineering research directions, especially in the area of software evolution, defect detection, and program repair.   In this paper, we reflect on the conduct of failure studies in software engineering. We reviewed a sample of 52 failure study papers. We identified several recurring problems in these studies, some of which hinder the ability of the engineering community to trust or replicate the results. Based on our findings, we suggest future research directions, including identifying and analyzing failure causal chains, standardizing the conduct of failure studies, and tool support for faster defect analysis.	Arxiv	0	['Aishwarya Sharma', 'Siddharth R. Rao', 'Abbey Vincent', 'James C. Davis']
357	Requirements Engineering for Research Software: A Vision	Adrian Bajraktari	2024-05-13T14:25:01Z	http://arxiv.org/abs/2405.07781v2	Modern science is relying on software more than ever. The behavior and outcomes of this software shape the scientific and public discourse on important topics like climate change, economic growth, or the spread of infections. Most researchers creating software for scientific purposes are not trained in Software Engineering. As a consequence, research software is often developed ad hoc without following stringent processes. With this paper, we want to characterize research software as a new application domain that needs attention from the Requirements Engineering community. We conducted an exploratory study based on 8 interviews with 12 researchers who develop software. We describe how researchers elicit, document, and analyze requirements for research software and what processes they follow. From this, we derive specific challenges and describe a vision of Requirements Engineering for research software.	Arxiv	0	['Michelle Binder', 'Andreas Vogelsang']
358	The Daily Life of Software Engineers during the COVID-19 Pandemic	Daniel Russo	2021-01-12T09:22:39Z	http://arxiv.org/abs/2101.04363v1	Following the onset of the COVID-19 pandemic and subsequent lockdowns, software engineers' daily life was disrupted and abruptly forced into remote working from home. This change deeply impacted typical working routines, affecting both well-being and productivity. Moreover, this pandemic will have long-lasting effects in the software industry, with several tech companies allowing their employees to work from home indefinitely if they wish to do so. Therefore, it is crucial to analyze and understand how a typical working day looks like when working from home and how individual activities affect software developers' well-being and productivity. We performed a two-wave longitudinal study involving almost 200 globally carefully selected software professionals, inferring daily activities with perceived well-being, productivity, and other relevant psychological and social variables. Results suggest that the time software engineers spent doing specific activities from home was similar when working in the office. However, we also found some significant mean differences. The amount of time developers spent on each activity was unrelated to their well-being, perceived productivity, and other variables. We conclude that working remotely is not per se a challenge for organizations or developers.	Arxiv	0	['Paul P. H. Hanel', 'Seraphina Altnickel', 'Niels van Berkel']
359	What prevents Finnish women from applying to software engineering roles? A preliminary analysis of survey data	Annika Wolff	2020-02-05T16:03:25Z	http://arxiv.org/abs/2002.01840v1	Finland is considered a country with a good track record in gender equality. Whilst statistics support the notion that Finland is performing well compared to many other countries in terms of workplace equality, there are still many areas for improvement. This paper focuses on the problems that some women face in obtaining software engineering roles. We report a preliminary analysis of survey data from 252 respondents. These are mainly women who have shown an interest in gaining programming roles by joining the Mimmit koodaa initiative, which aims to increase equality and diversity within the software industry. The survey sought to understand what early experiences may influence later career choices and feelings of efficacy and confidence needed to pursue technology-related careers. These initial findings reveal that women's feelings of computing self-efficacy and attitudes towards software engineering are shaped by early experiences. More negative experiences decrease the likelihood of working in software engineering roles in the future, despite expressing an interest in the field.	Arxiv	0	['Antti Knutas', 'Paula Savolainen']
360	A Software Engineering Perspective on Engineering Machine Learning Systems: State of the Art and Challenges	G√∂rkem Giray	2020-12-14T20:06:31Z	http://arxiv.org/abs/2012.07919v3	Context: Advancements in machine learning (ML) lead to a shift from the traditional view of software development, where algorithms are hard-coded by humans, to ML systems materialized through learning from data. Therefore, we need to revisit our ways of developing software systems and consider the particularities required by these new types of systems. Objective: The purpose of this study is to systematically identify, analyze, summarize, and synthesize the current state of software engineering (SE) research for engineering ML systems. Method: I performed a systematic literature review (SLR). I systematically selected a pool of 141 studies from SE venues and then conducted a quantitative and qualitative analysis using the data extracted from these studies. Results: The non-deterministic nature of ML systems complicates all SE aspects of engineering ML systems. Despite increasing interest from 2018 onwards, the results reveal that none of the SE aspects have a mature set of tools and techniques. Testing is by far the most popular area among researchers. Even for testing ML systems, engineers have only some tool prototypes and solution proposals with weak experimental proof. Many of the challenges of ML systems engineering were identified through surveys and interviews. Researchers should conduct experiments and case studies, ideally in industrial environments, to further understand these challenges and propose solutions. Conclusion: The results may benefit (1) practitioners in foreseeing the challenges of ML systems engineering; (2) researchers and academicians in identifying potential research questions; and (3) educators in designing or updating SE courses to cover ML systems engineering.	Arxiv	0	[]
361	Automated Description Generation for Software Patches	Thanh Trong Vu	2024-02-06T08:46:14Z	http://arxiv.org/abs/2402.03805v2	Software patches are pivotal in refining and evolving codebases, addressing bugs, vulnerabilities, and optimizations. Patch descriptions provide detailed accounts of changes, aiding comprehension and collaboration among developers. However, manual description creation poses challenges in terms of time consumption and variations in quality and detail. In this paper, we propose PATCHEXPLAINER, an approach that addresses these challenges by framing patch description generation as a machine translation task. In PATCHEXPLAINER, we leverage explicit representations of critical elements, historical context, and syntactic conventions. Moreover, the translation model in PATCHEXPLAINER is designed with an awareness of description similarity. Particularly, the model is explicitly trained to recognize and incorporate similarities present in patch descriptions clustered into groups, improving its ability to generate accurate and consistent descriptions across similar patches. The dual objectives maximize similarity and accurately predict affiliating groups. Our experimental results on a large dataset of real-world software patches show that PATCHEXPLAINER consistently outperforms existing methods, with improvements up to 189% in BLEU, 5.7X in Exact Match rate, and 154% in Semantic Similarity, affirming its effectiveness in generating software patch descriptions.	Arxiv	0	['Tuan-Dung Bui', 'Thanh-Dat Do', 'Thu-Trang Nguyen', 'Hieu Dinh Vo', 'Son Nguyen']
362	Building a Sustainable Structure for Research Software Engineering Activities	Jeremy Cohen	2018-07-11T11:12:53Z	http://arxiv.org/abs/1807.04072v2	The profile of research software engineering has been greatly enhanced by developments at institutions around the world to form groups and communities that can support effective, sustainable development of research software. We observe, however, that there is still a long way to go to build a clear understanding about what approaches provide the best support for research software developers in different contexts, and how such understanding can be used to suggest more formal structures, models or frameworks that can help to further support the growth of research software engineering. This paper sets out some preliminary thoughts and proposes an initial high-level model based on discussions between the authors around the concept of a set of pillars representing key activities and processes that form the core structure of a successful research software engineering offering.	Arxiv	0	['Daniel S. Katz', 'Michelle Barker', 'Robert Haines', 'Neil Chue Hong']
363	Quality Attributes Optimization of Software Architecture: Research Challenges and Directions	Daniele Di Pompeo	2023-01-18T13:37:21Z	http://arxiv.org/abs/2301.07516v1	The estimation and improvement of quality attributes in software architectures is a challenging and time-consuming activity. On modern software applications, a model-based representation is crucial to face the complexity of such activity. One main challenge is that the improvement of distinctive quality attributes may require contrasting refactoring actions on the architecture, for instance when looking for trade-off between performance and reliability (or other non-functional quality attributes). In such cases, multi-objective optimization can provide the designer with a more complete view on these trade-offs and, consequently, can lead to identify suitable refactoring actions that take into account independent or even competing objectives.   In this paper, we present open challenges and research directions to fill current gaps in the context of multi-objective software architecture optimization.	Arxiv	0	['Michele Tucci']
364	How does Object-Oriented Code Refactoring Influence Software Quality? Research Landscape and Challenges	Satnam Kaur	2019-08-15T03:22:57Z	http://arxiv.org/abs/1908.05399v1	Context: Software refactoring aims to improve software quality and developer productivity. Numerous empirical studies investigating the impact of refactoring activities on software quality have been conducted over the last two decades. Objective: This study aims to perform a comprehensive systematic mapping study of existing empirical studies on evaluation of the effect of object-oriented code refactoring activities on software quality attributes. Method: We followed a multi-stage scrutinizing process to select 142 primary studies published till December 2017. The selected primary studies were further classified based on several aspects to answer the research questions defined for this work. In addition, we applied vote-counting approach to combine the empirical results and their analysis reported in primary studies. Results: The findings indicate that studies conducted in academic settings found more positive impact of refactoring on software quality than studies performed in industries. In general, refactoring activities caused all quality attributes to improve or degrade except for cohesion, complexity, inheritance, fault-proneness and power consumption attributes. Furthermore, individual refactoring activities have variable effects on most quality attributes explored in primary studies, indicating that refactoring does not always improve all quality attributes. Conclusions: This study points out several open issues which require further investigation, e.g., lack of industrial validation, lesser coverage of refactoring activities, limited tool support, etc.	Arxiv	0	['Paramvir Singh']
365	A Benchmark Study on Sentiment Analysis for Software Engineering Research	Nicole Novielli	2018-03-17T15:51:01Z	http://arxiv.org/abs/1803.06525v1	A recent research trend has emerged to identify developers' emotions, by applying sentiment analysis to the content of communication traces left in collaborative development environments. Trying to overcome the limitations posed by using off-the-shelf sentiment analysis tools, researchers recently started to develop their own tools for the software engineering domain. In this paper, we report a benchmark study to assess the performance and reliability of three sentiment analysis tools specifically customized for software engineering. Furthermore, we offer a reflection on the open challenges, as they emerge from a qualitative analysis of misclassified texts.	Arxiv	0	['Daniela Girardi', 'Filippo Lanubile']
366	Lost in Transition: The Struggle of Women Returning to Software Engineering Research after Career Breaks	Shalini Chakraborty	2025-09-25T20:19:42Z	http://arxiv.org/abs/2509.21533v1	The IT industry provides supportive pathways such as returnship programs, coding boot camps, and buddy systems for women re-entering their job after a career break. Academia, however, offers limited opportunities to motivate women to return. We propose a diverse multicultural research project investigating the challenges faced by women with software engineering (SE) backgrounds re-entering academia or related research roles after a career break. Career disruptions due to pregnancy, immigration status, or lack of flexible work options can significantly impact women's career progress, creating barriers for returning as lecturers, professors, or senior researchers. Although many companies promote gender diversity policies, such measures are less prominent and often under-recognized within academic institutions. Our goal is to explore the specific challenges women encounter when re-entering academic roles compared to industry roles; to understand the institutional perspective, including a comparative analysis of existing policies and opportunities in different countries for women to return to the field; and finally, to provide recommendations that support transparent hiring practices. The research project will be carried out in multiple universities and in multiple countries to capture the diverse challenges and policies that vary by location.	Arxiv	0	['Sebastian Baltes']
367	An overview to Software Architecture in Intrusion Detection System	Mehdi Bahrami	2012-05-20T05:38:36Z	http://arxiv.org/abs/1205.4385v2	Today by growing network systems, security is a key feature of each network infrastructure. Network Intrusion Detection Systems (IDS) provide defense model for all security threats which are harmful to any network. The IDS could detect and block attack-related network traffic. The network control is a complex model. Implementation of an IDS could make delay in the network. Several software-based network intrusion detection systems are developed. However, the model has a problem with high speed traffic. This paper reviews of many type of software architecture in intrusion detection systems and describes the design and implementation of a high-performance network intrusion detection system that combines the use of software-based network intrusion detection sensors and a network processor board. The network processor which is a hardware-based model could acts as a customized load balancing splitter. This model cooperates with a set of modified content-based network intrusion detection sensors rather than IDS in processing network traffic and controls the high-speed.	Arxiv	0	['Mohammad Bahrami']
368	Automated categorization of pre-trained models for software engineering: A case study with a Hugging Face dataset	Claudio Di Sipio	2024-05-21T20:26:17Z	http://arxiv.org/abs/2405.13185v1	Software engineering (SE) activities have been revolutionized by the advent of pre-trained models (PTMs), defined as large machine learning (ML) models that can be fine-tuned to perform specific SE tasks. However, users with limited expertise may need help to select the appropriate model for their current task. To tackle the issue, the Hugging Face (HF) platform simplifies the use of PTMs by collecting, storing, and curating several models. Nevertheless, the platform currently lacks a comprehensive categorization of PTMs designed specifically for SE, i.e., the existing tags are more suited to generic ML categories.   This paper introduces an approach to address this gap by enabling the automatic classification of PTMs for SE tasks. First, we utilize a public dump of HF to extract PTMs information, including model documentation and associated tags. Then, we employ a semi-automated method to identify SE tasks and their corresponding PTMs from existing literature. The approach involves creating an initial mapping between HF tags and specific SE tasks, using a similarity-based strategy to identify PTMs with relevant tags. The evaluation shows that model cards are informative enough to classify PTMs considering the pipeline tag. Moreover, we provide a mapping between SE tasks and stored PTMs by relying on model names.	Arxiv	0	['Riccardo Rubei', 'Juri Di Rocco', 'Davide Di Ruscio', 'Phuong T. Nguyen']
369	Recruiting Software Engineers on Prolific	Daniel Russo	2022-03-28T12:49:27Z	http://arxiv.org/abs/2203.14695v1	Recruiting participants for software engineering research has been a primary concern of the human factors community. This is particularly true for quantitative investigations that require a minimum sample size not to be statistically underpowered. Traditional data collection techniques, such as mailing lists, are highly doubtful due to self-selection biases. The introduction of crowdsourcing platforms allows researchers to select informants with the exact requirements foreseen by the study design, gather data in a concise time frame, compensate their work with fair hourly pay, and most importantly, have a high degree of control over the entire data collection process. This experience report discusses our experience conducting sample studies using Prolific, an academic crowdsourcing platform. Topics discussed are the type of studies, selection processes, and power computation.	Arxiv	0	[]
370	Multi-objective Software Architecture Refactoring driven by Quality Attributes	Daniele Di Pompeo	2023-01-18T13:17:16Z	http://arxiv.org/abs/2301.07500v1	Architecture optimization is the process of automatically generating design options, typically to enhance software's quantifiable quality attributes, such as performance and reliability. Multi-objective optimization approaches have been used in this situation to assist the designer in selecting appropriate trade-offs between a number of non-functional features. Through automated refactoring, design alternatives can be produced in this process, and assessed using non-functional models.   This type of optimization tasks are hard and time- and resource-intensive, which frequently hampers their use in software engineering procedures.   In this paper, we present our optimization framework where we examined the performance of various genetic algorithms. We also exercised our framework with two case studies with various levels of size, complexity, and domain served as our test subjects.	Arxiv	0	['Michele Tucci']
371	A comprehensive safety engineering approach for software-intensive systems based on STPA	Asim Abdulkhaleq	2016-12-09T17:59:02Z	http://arxiv.org/abs/1612.03109v1	Formal verification and testing are complementary approaches which are used in the development process to verify the functional correctness of software. However, the correctness of software cannot ensure the safe operation of safety-critical software systems. The software must be verified against its safety requirements which are identified by safety analysis, to ensure that potential hazardous causes cannot occur. The complexity of software makes defining appropriate software safety requirements with traditional safety analysis techniques difficult. STPA (Systems-Theoretic Processes Analysis) is a unique safety analysis approach that has been developed to identify system hazards, including the software-related hazards. This paper presents a comprehensive safety engineering approach based on STPA, including software testing and model checking approaches for the purpose of developing safe software. The proposed approach can be embedded within a defined software engineering process or applied to existing software systems, allow software and safety engineers integrate the analysis of software risks with their verification. The application of the proposed approach is illustrated with an automotive software controller.	Arxiv	0	['Stefan Wagner', 'Nancy Leveson']
372	"Just Enough, Just in Time, Just for ""Me"": Fundamental Principles for Engineering IoT-native Software Systems"	Zheng Li	2022-01-24T19:37:37Z	http://arxiv.org/abs/2201.09931v1	"By seamlessly integrating everyday objects and by changing the way we interact with our surroundings, Internet of Things (IoT) is drastically improving the life quality of households and enhancing the productivity of businesses. Given the unique IoT characteristics, IoT applications have emerged distinctively from the mainstream application types. Inspired by the outlook of a programmable world, we further foresee an IoT-native trend in designing, developing, deploying, and maintaining software systems. However, although the challenges of IoT software projects are frequently discussed, addressing those challenges are still in the ""crossing the chasm"" period. By participating in a few various IoT projects, we gradually distilled three fundamental principles for engineering IoT-native software systems, such as just enough, just in time, and just for ""me"". These principles target the challenges that are associated with the most typical features of IoT environments, ranging from resource limits to technology heterogeneity of IoT devices. We expect this research to trigger dedicated efforts, techniques and theories for the topic IoT-native software engineering."	Arxiv	0	['Rajiv Ranjan']
373	An Exploration of the Mentorship Needs of Research Software Engineers	Reed Milewicz	2021-10-05T18:03:59Z	http://arxiv.org/abs/2110.02251v1	As a newly designated professional title, research software engineers (RSEs) link the two worlds of software engineering and research science. They lack clear development and training opportunities, particularly in the realm of mentoring. In this paper, we discuss mentorship as it pertains to the unique needs of RSEs and propose ways in which organizations and institutions can support mentor/mentee relationships for RSEs	Arxiv	0	['Miranda Mundt']
374	Characterizing the Usage, Evolution and Impact of Java Annotations in Practice	Zhongxing Yu	2018-05-04T23:29:19Z	http://arxiv.org/abs/1805.01965v2	Annotations have been formally introduced into Java since Java 5. Since then, annotations have been widely used by the Java community for different purposes, such as compiler guidance and runtime processing. Despite the ever-growing use, there is still limited empirical knowledge about the actual usage of annotations in practice, the changes made to annotations during software evolution, and the potential impact of annotations on code quality. To fill this gap, we perform the first large-scale empirical study about Java annotations on 1,094 notable open-source projects hosted on GitHub. Our study systematically investigates annotation usage, annotation evolution, and annotation impact, and generates 10 novel and important findings. We also present the implications of our findings, which shed light for developers, researchers, tool builders, and language or library designers in order to improve all facets of Java annotation engineering.	Arxiv	0	['Chenggang Bai', 'Lionel Seinturier', 'Martin Monperrus']
375	Software engineering for artificial intelligence and machine learning software: A systematic literature review	Elizamary Nascimento	2020-11-07T11:06:28Z	http://arxiv.org/abs/2011.03751v1	Artificial Intelligence (AI) or Machine Learning (ML) systems have been widely adopted as value propositions by companies in all industries in order to create or extend the services and products they offer. However, developing AI/ML systems has presented several engineering problems that are different from those that arise in, non-AI/ML software development. This study aims to investigate how software engineering (SE) has been applied in the development of AI/ML systems and identify challenges and practices that are applicable and determine whether they meet the needs of professionals. Also, we assessed whether these SE practices apply to different contexts, and in which areas they may be applicable. We conducted a systematic review of literature from 1990 to 2019 to (i) understand and summarize the current state of the art in this field and (ii) analyze its limitations and open challenges that will drive future research. Our results show these systems are developed on a lab context or a large company and followed a research-driven development process. The main challenges faced by professionals are in areas of testing, AI software quality, and data management. The contribution types of most of the proposed SE practices are guidelines, lessons learned, and tools.	Arxiv	0	['Anh Nguyen-Duc', 'Ingrid Sundb√∏', 'Tayana Conte']
376	Misaligned Values in Software Engineering Organizations	Per Lenberg	2018-10-14T20:53:09Z	http://arxiv.org/abs/1810.06104v2	The values of software organizations are crucial for achieving high performance; in particular, agile development approaches emphasize their importance. Researchers have thus far often assumed that a specific set of values, compatible with the development methodologies, must be adopted homogeneously throughout the company. It is not clear, however, to what extent such assumptions are accurate.   Preliminary findings have highlighted the misalignment of values between groups as a source of problems when engineers discuss their challenges. Therefore, in this study, we examine how discrepancies in values between groups affect software companies' performance.   To meet our objectives, we chose a mixed method research design. First, we collected qualitative data by interviewing fourteen (\textit{N} = 14) employees working in four different organizations and processed it using thematic analysis. We then surveyed seven organizations (\textit{N} = 184). Our analysis indicated that value misalignment between groups is related to organizational performance. The aligned companies were more effective, more satisfied, had higher trust, and fewer conflicts.   Our efforts provide encouraging findings in a critical software engineering research area. They can help to explain why some companies are more efficient than others and, thus, point the way to interventions to address organizational challenges.	Arxiv	0	['Robert Feldt', 'Lars G√∂ran Wallgren Tengberg']
377	The Innovative Behaviour of Software Engineers: Findings from a Pilot Case Study	Cleviton Monteiro	2016-12-02T16:19:29Z	http://arxiv.org/abs/1612.04648v1	Context: In the workplace, some individuals engage in the voluntary and intentional generation, promotion, and realization of new ideas for the benefit of individual performance, group effectiveness, or the organization. The literature classifies this phenomenon as innovative behaviour. Despite its importance to the development of innovation, innovative behaviour has not been fully investigated in software engineering. Objective: To understand the factors that support or inhibit innovative behaviour in software engineering practice. Method: We conducted a pilot case study in a Canadian software company using interviews and observations as data collection techniques. Using qualitative analysis, we identified relevant factors and relationships not addressed by studies from other areas. Results: Individual innovative behaviour is influenced by individual attitudes and also by situational factors such as relationships in the workplace, organizational characteristics, and project type. We built a model to express the interacting effects of these factors. Conclusions: Innovative behaviour is dependent on individual and contextual factors. Our results contribute to relevant impacts on research and practice, and to topics that deserve further study.	Arxiv	0	['Fabio Queda Bueno da Silva', 'Luiz Fernando Capretz']
378	Software Engineering Knowledge Areas in Startup Companies: A Mapping Study	Eriks Klotins	2023-08-15T08:26:02Z	http://arxiv.org/abs/2308.07628v1	Background - Startup companies are becoming important suppliers of innovative and software intensive products. The failure rate among startups is high due to lack of resources, immaturity, multiple influences and dynamic technologies. However, software product engineering is the core activity in startups, therefore inadequacies in applied engineering practices might be a significant contributing factor for high failure rates. Aim - This study identifies and categorizes software engineering knowledge areas utilized in startups to map out the state-of-art, identifying gaps for further research. Method - We perform a systematic literature mapping study, applying snowball sampling to identify relevant primary studies. Results - We have identified 54 practices from 14 studies. Although 11 of 15 main knowledge areas from SWEBOK are covered, a large part of categories is not. Conclusions - Existing research does not provide reliable support for software engineering in any phase of a startup life cycle. Transfer of results to other startups is difficult due to low rigor in current studies.	Arxiv	0	['Michael Unterkalmsteiner', 'Tony Gorschek']
379	Integrating Sustainability Concerns into Agile Software Development Process	Shola Oyedeji	2024-07-09T11:58:00Z	http://arxiv.org/abs/2407.17426v1	Software has the potential to be a key driver in fostering sustainability. Despite this potential, it is not clear if and how the software industry integrates consideration of sustainability into its common software development processes. This research starts by investigating the current state of sustainability consideration within the software engineering industry through a survey. The results highlight a lack of progress in practically integrating sustainability considerations into software development activities. To address this gap, a case study with an industry partner is conducted to demonstrate how sustainability concerns and effects can be integrated into agile software development. The findings of this case study demonstrate practical approaches to integrating sustainability into software development practices. Reflecting on the findings from the survey and the case study, we note some insights on scaling up the adoption of sustainability consideration into the daily practice of agile software development.	Arxiv	0	['Ruzanna Chitchyan', 'Mikhail Ola Adisa', 'Hatef Shamshiri']
380	Programming the Universe: The First Commandment of Software Engineering for all Varieties of Information Systems	Silvio Meira	2016-09-25T23:57:57Z	http://arxiv.org/abs/1609.07818v2	Since the early days of computers and programs, the process and outcomes of software development has been a minefield plagued with problems and failures, as much as the complexity and complication of software and its development has increased by a thousandfold in half a century. Over the years, a number of theories, laws, best practices, manifestos and methodologies have emerged, with varied degrees of (un)success. Our experience as software engineers of complex and large-scale systems shows that those guidelines are bound to previously defined and often narrow scopes. Enough is enough. Nowadays, nearly every company is in the software and services business and everything is - or is managed by - software. It is about time, then, that the laws that govern our universe ought to be redefined. In this context, we discuss and present a set of universal laws that leads us to propose the first commandment of software engineering for all varieties of information systems.	Arxiv	0	['Vanilson Bur√©gio', 'Paulo Borba', 'Vinicius Garcia', 'Jones Albuquerque', 'Sergio Soares']
381	Using Experience Sampling to link Software Repositories with Emotions and Work Well-Being	Miikka Kuutila	2018-08-16T10:50:43Z	http://arxiv.org/abs/1808.05409v2	Background: The experience sampling method studies everyday experiences of humans in natural environments. In psychology it has been used to study the relationships between work well-being and productivity. To our best knowledge, daily experience sampling has not been previously used in software engineering. Aims: Our aim is to identify links between software developers self-reported affective states and work well-being and measures obtained from software repositories. Method: We perform an experience sampling study in a software company for a period of eight months, we use logistic regression to link the well-being measures with development activities, i.e. number of commits and chat messages. Results: We find several significant relationships between questionnaire variables and software repository variables. To our surprise relationship between hurry and number of commits is negative, meaning more perceived hurry is linked with a smaller number of commits. We also find a negative relationship between social interaction and hindered work well-being. Conclusions: The negative link between commits and hurry is counter-intuitive and goes against previous lab-experiments in software engineering that show increased efficiency under time pressure. Overall, our work is an initial step in using experience sampling in software engineering and validating theories on work well-being from other fields in the domain of software engineering.	Arxiv	0	['Mika M√§ntyl√§', 'Ma√´lick Claes', 'Marko Elovainio', 'Bram Adams']
382	Inferencing into the void: problems with implicit populations Comments on `Empirical software engineering experts on the use of students and professionals in experiments'	Martin Shepperd	2018-10-17T05:49:32Z	http://arxiv.org/abs/1810.07392v1	I welcome the contribution from Falessi et al. [1] hereafter referred to as F++ , and the ensuing debate. Experimentation is an important tool within empirical software engineering, so how we select participants is clearly a relevant question. Moreover as F++ point out, the question is considerably more nuanced than the simple dichotomy it might appear to be at first sight.   This commentary is structured as follows. In Section 2 I briefly summarise the arguments of F++ and comment on their approach. Next, in Section 3, I take a step back to consider the nature of representativeness in inferential arguments and the need for careful definition. Then I give three examples of using different types of participant to consider impact. I conclude by arguing, largely in agreement with F++, that the question of whether student participants are representative or not depends on the target population. However, we need to give careful consideration to defining that population and, in particular, not to overlook the representativeness of tasks and environment. This is facilitated by explicit description of the target populations.	Arxiv	0	[]
383	Software Testing with Large Language Models: Survey, Landscape, and Vision	Junjie Wang	2023-07-14T08:26:12Z	http://arxiv.org/abs/2307.07221v3	Pre-trained large language models (LLMs) have recently emerged as a breakthrough technology in natural language processing and artificial intelligence, with the ability to handle large-scale datasets and exhibit remarkable performance across a wide range of tasks. Meanwhile, software testing is a crucial undertaking that serves as a cornerstone for ensuring the quality and reliability of software products. As the scope and complexity of software systems continue to grow, the need for more effective software testing techniques becomes increasingly urgent, making it an area ripe for innovative approaches such as the use of LLMs. This paper provides a comprehensive review of the utilization of LLMs in software testing. It analyzes 102 relevant studies that have used LLMs for software testing, from both the software testing and LLMs perspectives. The paper presents a detailed discussion of the software testing tasks for which LLMs are commonly used, among which test case preparation and program repair are the most representative. It also analyzes the commonly used LLMs, the types of prompt engineering that are employed, as well as the accompanied techniques with these LLMs. It also summarizes the key challenges and potential opportunities in this direction. This work can serve as a roadmap for future research in this area, highlighting potential avenues for exploration, and identifying gaps in our current understanding of the use of LLMs in software testing.	Arxiv	0	['Yuchao Huang', 'Chunyang Chen', 'Zhe Liu', 'Song Wang', 'Qing Wang']
384	Do Software Languages Engineers Evaluate their Languages?	Pedro Gabriel	2011-09-30T11:25:41Z	http://arxiv.org/abs/1109.6794v1	Domain Specific Languages (DSLs) can contribute to increment productivity, while reducing the required maintenance and programming expertise. We hypothesize that Software Languages Engineering (SLE) developers consistently skip, or relax, Language Evaluation. Based on the experience of engineering other types of software products, we assume that this may potentially lead to the deployment of inadequate languages. The fact that the languages already deal with concepts from the problem domain, and not the solution domain, is not enough to validate several issues at stake, such as its expressiveness, usability, effectiveness, maintainability, or even the domain expert's productivity while using them. We present a systematic review on articles published in top ranked venues, from 2001 to 2008, which report DSLs' construction, to characterize the common practice. This work confirms our initial hypothesis and lays the ground for the discussion on how to include a systematic approach to DSL evaluation in the SLE process.	Arxiv	0	['Miguel Goul√£o', 'Vasco Amaral']
385	On the Diversity of Software Package Popularity Metrics: An Empirical Study of npm	Ahmed Zerouali	2019-01-14T10:07:16Z	http://arxiv.org/abs/1901.04217v1	Software systems often leverage on open source software libraries to reuse functionalities. Such libraries are readily available through software package managers like npm for JavaScript. Due to the huge amount of packages available in such package distributions, developers often decide to rely on or contribute to a software package based on its popularity. Moreover, it is a common practice for researchers to depend on popularity metrics for data sampling and choosing the right candidates for their studies. However, the meaning of popularity is relative and can be defined and measured in a diversity of ways, that might produce different outcomes even when considered for the same studies. In this paper, we show evidence of how different is the meaning of popularity in software engineering research. Moreover, we empirically analyse the relationship between different software popularity measures. As a case study, for a large dataset of 175k npm packages, we computed and extracted 9 different popularity metrics from three open source tracking systems: libraries.io, npmjs.com and GitHub. We found that indeed popularity can be measured with different unrelated metrics, each metric can be defined within a specific context. This indicates a need for a generic framework that would use a portfolio of popularity metrics drawing from different concepts.	Arxiv	0	['Tom Mens', 'Gregorio Robles', 'Jesus M. Gonzalez-Barahona']
386	Seeking Enlightenment: Incorporating Evidence-Based Practice Techniques in a Research Software Engineering Team	Reed Milewicz	2024-03-25T14:52:18Z	http://arxiv.org/abs/2403.16827v1	Evidence-based practice (EBP) in software engineering aims to improve decision-making in software development by complementing practitioners' professional judgment with high-quality evidence from research. We believe the use of EBP techniques may be helpful for research software engineers (RSEs) in their work to bring software engineering best practices to scientific software development. In this study, we present an experience report on the use of a particular EBP technique, rapid reviews, within an RSE team at Sandia National Laboratories, and present practical recommendations for how to address barriers to EBP adoption within the RSE community.	Arxiv	0	['Jon Bisila', 'Miranda Mundt', 'Joshua Teves']
387	Applications of statistical causal inference in software engineering	Julien Siebert	2022-11-21T14:16:55Z	http://arxiv.org/abs/2211.11482v3	This paper reviews existing work in software engineering that applies statistical causal inference methods. These methods aim at estimating causal effects from observational data. The review covers 32 papers published between 2010 and 2022. Our results show that the application of statistical causal inference methods is relatively recent and that the corresponding research community remains relatively fragmented.	Arxiv	0	[]
388	Ten Simple Rules for Catalyzing Collaborations and Building Bridges between Research Software Engineers and Software Engineering Researchers	Nasir U. Eisty	2025-06-03T15:51:17Z	http://arxiv.org/abs/2506.03012v1	In the evolving landscape of scientific and scholarly research, effective collaboration between Research Software Engineers (RSEs) and Software Engineering Researchers (SERs) is pivotal for advancing innovation and ensuring the integrity of computational methodologies. This paper presents ten strategic guidelines aimed at fostering productive partnerships between these two distinct yet complementary communities. The guidelines emphasize the importance of recognizing and respecting the cultural and operational differences between RSEs and SERs, proactively initiating and nurturing collaborations, and engaging within each other's professional environments. They advocate for identifying shared challenges, maintaining openness to emerging problems, ensuring mutual benefits, and serving as advocates for one another. Additionally, the guidelines highlight the necessity of vigilance in monitoring collaboration dynamics, securing institutional support, and defining clear, shared objectives. By adhering to these principles, RSEs and SERs can build synergistic relationships that enhance the quality and impact of research outcomes.	Arxiv	0	['Jeffrey C. Carver', 'Johanna Cohoon', 'Ian A. Cosden', 'Carole Goble', 'Samuel Grayson']
389	Software startup within a university -- producing industry-ready graduates	Saara Tenhunen	2023-01-17T17:11:54Z	http://arxiv.org/abs/2301.07020v1	Previous research has demonstrated that preparing students for life in software engineering is not a trivial task. Authentic learning experiences are challenging to provide, and there are gaps between what students have done at the university and what they are expected to master when getting into the industry after graduation. To address this challenge, we present a novel way of teaching industry-relevant skills in a university-led internal software startup called Software Development Academy (SDA). In addition to describing the SDA concept in detail, we have investigated what educational aspects characterise SDA and how it compares to capstone projects. The questions are answered based on 15 semi-structured interviews with alumni of SDA. Working with production-quality software and having a wide range of responsibilities were perceived as the most integral aspects of SDA and provided students with a comprehensive skill set for the future.	Arxiv	0	['Tomi M√§nnist√∂', 'Petri Ihantola', 'Jami Kousa', 'Matti Luukkainen']
390	Towards Emotionally Intelligent Software Engineers: Understanding Students' Self-Perceptions After a Cooperative Learning Experience	Allysson Allex Ara√∫jo	2025-02-07T17:29:08Z	http://arxiv.org/abs/2502.05108v1	[Background] Emotional Intelligence (EI) can impact Software Engineering (SE) outcomes through improved team communication, conflict resolution, and stress management. SE workers face increasing pressure to develop both technical and interpersonal skills, as modern software development emphasizes collaborative work and complex team interactions. Despite EI's documented importance in professional practice, SE education continues to prioritize technical knowledge over emotional and social competencies. [Objective] This paper analyzes SE students' self-perceptions of their EI after a two-month cooperative learning project, using Mayer and Salovey's four-ability model to examine how students handle emotions in collaborative development. [Method] We conducted a case study with 29 SE students organized into four squads within a project-based learning course, collecting data through questionnaires and focus groups that included brainwriting and sharing circles, then analyzing the data using descriptive statistics and open coding. [Results] Students demonstrated stronger abilities in managing their own emotions compared to interpreting others' emotional states. Despite limited formal EI training, they developed informal strategies for emotional management, including structured planning and peer support networks, which they connected to improved productivity and conflict resolution. [Conclusion] This study shows how SE students perceive EI in a collaborative learning context and provides evidence-based insights into the important role of emotional competencies in SE education.	Arxiv	0	['Marcos Kalinowski', 'Matheus Paixao', 'Daniel Graziotin']
391	Emotion-Centric Requirements Change Handling in Software Engineering	Kashumi Madampe	2022-05-12T01:29:27Z	http://arxiv.org/abs/2205.05827v1	Background: Requirements Changes (RCs) -- the additions/modifications/deletions of functional/non-functional requirements in software products -- are challenging for software practitioners to handle. Handling some changes may significantly impact the emotions of the practitioners. Objective: We wanted to know the key challenges that make RC handling difficult, how these impact the emotions of software practitioners, what influences their RC handling, and how RC handling can be made less emotionally challenging. Method: We followed a mixed-methods approach. We conducted two survey studies, with 40 participants and 201 participants respectively. The presentation of key quantitative data was followed by descriptive statistical analysis, and the qualitative data was analysed using Strauss-Corbinian Grounded Theory, and Socio-Technical Grounded Theory analysis techniques. Findings:We found (1) several key factors that make RC handling an emotional challenge, (2) varying emotions that practitioners feel when it is challenging to handle RCs, (3) how stakeholders, including practitioners themselves, peers, managers and customers, influence the RC handling and how practitioners feel due to the stakeholder influence, and (4) practices that can be used to better handle RCs. Conclusion: Some challenges are technical and some are social which also belong to aspects of agile practice, emotional intelligence, and cognitive intelligence. Therefore, to better handle RCs with positive emotions in socio-technical environments, agility, emotional intelligence, and cognitive intelligence need to cooperate with each other.	Arxiv	0	['Rashina Hoda', 'John Grundy']
392	The application of artificial intelligence in software engineering: a review challenging conventional wisdom	Feras A. Batarseh	2021-08-03T15:59:59Z	http://arxiv.org/abs/2108.01591v1	The field of artificial intelligence (AI) is witnessing a recent upsurge in research, tools development, and deployment of applications. Multiple software companies are shifting their focus to developing intelligent systems; and many others are deploying AI paradigms to their existing processes. In parallel, the academic research community is injecting AI paradigms to provide solutions to traditional engineering problems. Similarly, AI has evidently been proved useful to software engineering (SE). When one observes the SE phases (requirements, design, development, testing, release, and maintenance), it becomes clear that multiple AI paradigms (such as neural networks, machine learning, knowledge-based systems, natural language processing) could be applied to improve the process and eliminate many of the major challenges that the SE field has been facing. This survey chapter is a review of the most commonplace methods of AI applied to SE. The review covers methods between years 1975-2017, for the requirements phase, 46 major AI-driven methods are found, 19 for design, 15 for development, 68 for testing, and 15 for release and maintenance. Furthermore, the purpose of this chapter is threefold; firstly, to answer the following questions: is there sufficient intelligence in the SE lifecycle? What does applying AI to SE entail? Secondly, to measure, formulize, and evaluate the overlap of SE phases and AI disciplines. Lastly, this chapter aims to provide serious questions to challenging the current conventional wisdom (i.e., status quo) of the state-of-the-art, craft a call for action, and to redefine the path forward.	Arxiv	0	['Rasika Mohod', 'Abhinav Kumar', 'Justin Bui']
393	Software Engineering Education by Example	Nacer Boudjlida	2009-11-17T13:36:59Z	http://arxiv.org/abs/0911.3306v1	"Based on the old but famous distinction between ""in the small"" and ""in the large"" software development, at Nancy Universit√©, UHP Nancy 1, we experience for a while software engineering education thanks to actual project engineering. This education method has the merit to enable students to discover and to overcome actual problems when faced to a large project which may be conducted by a large development team. The mode of education is a simulation of an actual software engineering project as encountered in ""real life√©"" activities."	Arxiv	0	['Jean-Pierre Jacquot', 'Pascal Urso']
394	Systematic Mapping Study on Requirements Engineering for Regulatory Compliance of Software Systems	Oleksandr Kosenkov	2024-11-04T10:04:14Z	http://arxiv.org/abs/2411.01940v2	Context: As the diversity and complexity of regulations affecting Software-Intensive Products and Services (SIPS) is increasing, software engineers need to address the growing regulatory scrutiny. As with any other non-negotiable requirements, SIPS compliance should be addressed early in SIPS engineering - i.e., during requirements engineering (RE). Objectives: In the conditions of the expanding regulatory landscape, existing research offers scattered insights into regulatory compliance of SIPS. This study addresses the pressing need for a structured overview of the state of the art in software RE and its contribution to regulatory compliance of SIPS. Method: We conducted a systematic mapping study to provide an overview of the current state of research regarding challenges, principles and practices for regulatory compliance of SIPS related to RE. We focused on the role of RE and its contribution to other SIPS lifecycle phases. We retrieved 6914 studies published from 2017 until 2023 from four academic databases, which we filtered down to 280 relevant primary studies. Results: We identified and categorized the RE-related challenges in regulatory compliance of SIPS and their potential connection to six types of principles and practices. We found that about 13.6% of the primary studies considered the involvement of both software engineers and legal experts. About 20.7% of primary studies considered RE in connection to other process areas. Most primary studies focused on a few popular regulation fields and application domains. Our results suggest that there can be differences in terms of challenges and involvement of stakeholders across different fields of regulation. Conclusion: Our findings highlight the need for an in-depth investigation of stakeholders' roles, relationships between process areas, and specific challenges for distinct regulatory fields to guide research and practice.	Arxiv	0	['Parisa Elahidoost', 'Tony Gorschek', 'Jannik Fischbach', 'Daniel Mendez', 'Michael Unterkalmsteiner', 'Davide Fucci', 'Rahul Mohanani']
395	On Testing Quantum Programs	Andriy Miranskyy	2018-12-21T16:58:19Z	http://arxiv.org/abs/1812.09261v1	A quantum computer (QC) can solve many computational problems more efficiently than a classic one. The field of QCs is growing: companies (such as DWave, IBM, Google, and Microsoft) are building QC offerings. We position that software engineers should look into defining a set of software engineering practices that apply to QC's software. To start this process, we give examples of challenges associated with testing such software and sketch potential solutions to some of these challenges.	Arxiv	0	['Lei Zhang']
396	How (Un)Happiness Impacts on Software Engineers in Agile Teams?	Lu√≠s Felipe Amorim	2020-06-05T16:31:35Z	http://arxiv.org/abs/2006.03546v1	Information technology (IT) organizations are increasing the use of agile practices, which are based on a people-centred culture alongside the software development process. Thus, it is vital to understand the social and human factors of the individuals working in agile environments, such as happiness and unhappiness and how these factors impact this kind of environment. Therefore, five case-studies were developed inside agile projects, in a company that values innovation, aiming to identify how (un)happiness impacts software engineers in agile environments. According to the answers gathered from 67 participants through a survey, interviews and using a cross-analysis, happiness factors identified by agile teams were effective communication, motivated members, collaboration among members, proactive members, and present leaders.	Arxiv	0	['Marcelo Marinho', 'Suzana Sampaio']
397	Digitalization of Swedish Government Agencies - A Perspective Through the Lens of a Software Development Census	Markus Borg	2018-02-01T14:52:45Z	http://arxiv.org/abs/1802.00312v2	Software engineering is at the core of the digitalization of society. Ill-informed decisions can have major consequences, as made evident in the 2017 government crisis in Sweden, originating in a data breach caused by an outsourcing deal made by the Swedish Transport Agency. Many Government Agencies (GovAgs) in Sweden are rapidly undergoing a digital transition, thus it is important to overview how widespread, and mature, software development is in this part of the public sector. We present a software development census of Swedish GovAgs, complemented by document analysis and a survey. We show that 39.2% of the GovAgs develop software internally, some matching the number of developers in large companies. Our findings suggest that the development largely resembles private sector counterparts, and that established best practices are implemented. Still, we identify improvement potential in the areas of strategic sourcing, openness, collaboration across GovAgs, and quality requirements. The Swedish Government has announced the establishment of a new digitalization agency next year, and our hope is that the software engineering community will contribute its expertise with a clear voice.	Arxiv	0	['Thomas Olsson', 'Ulrik Franke', 'Sa√Ød Assar']
398	Semantically-enhanced Topic Recommendation System for Software Projects	Maliheh Izadi	2022-05-31T19:54:42Z	http://arxiv.org/abs/2206.00085v2	Software-related platforms have enabled their users to collaboratively label software entities with topics. Tagging software repositories with relevant topics can be exploited for facilitating various downstream tasks. For instance, a correct and complete set of topics assigned to a repository can increase its visibility. Consequently, this improves the outcome of tasks such as browsing, searching, navigation, and organization of repositories. Unfortunately, assigned topics are usually highly noisy, and some repositories do not have well-assigned topics. Thus, there have been efforts on recommending topics for software projects, however, the semantic relationships among these topics have not been exploited so far.   We propose two recommender models for tagging software projects that incorporate the semantic relationship among topics. Our approach has two main phases; (1) we first take a collaborative approach to curate a dataset of quality topics specifically for the domain of software engineering and development. We also enrich this data with the semantic relationships among these topics and encapsulate them in a knowledge graph we call SED-KGraph. Then, (2) we build two recommender systems; The first one operates only based on the list of original topics assigned to a repository and the relationships specified in our knowledge graph. The second predictive model, however, assumes there are no topics available for a repository, hence it proceeds to predict the relevant topics based on both textual information of a software project and SED-KGraph.   We built SED-KGraph in a crowd-sourced project with 170 contributors from both academia and industry. The experiment results indicate that our solutions outperform baselines that neglect the semantic relationships among topics by at least 25% and 23% in terms of ASR and MAP metrics.	Arxiv	0	['Mahtab Nejati', 'Abbas Heydarnoori']
399	Characterizing Role Models in Software Practitioners' Career: An Interview Study	Mary S√°nchez-Gord√≥n	2024-02-15T13:11:07Z	http://arxiv.org/abs/2402.09925v1	A role model is a person who serves as an example for others to follow, especially in terms of values, behavior, achievements, and personal characteristics. In this paper, authors study how role models influence software practitioners careers, an aspect not studied in the literature before. By means of this study, authors aim to understand if there are any salient role model archetypes and what characteristics are valued by participants in their role models. To do so, authors use a thematic coding approach to analyze the data collected from interviewing ten Latin American software practitioners. Findings reveal that role models were perceived as sources of knowledge, yet the majority of participants, regardless of their career stage, displayed a stronger interest in the human side and the moral values that their role models embodied. This study also shows that any practitioner can be viewed as a role model.	Arxiv	0	['Ricardo Colomo-Palacios', 'Alex Sanchez Gordon']
400	How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering	Rudrajit Choudhuri	2023-12-18T21:38:00Z	http://arxiv.org/abs/2312.11719v1	Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.	Arxiv	0	['Dylan Liu', 'Igor Steinmacher', 'Marco Gerosa', 'Anita Sarma']
401	The Weights can be Harmful: Pareto Search versus Weighted Search in Multi-Objective Search-Based Software Engineering	Tao Chen	2022-02-08T09:09:20Z	http://arxiv.org/abs/2202.03728v1	"In presence of multiple objectives to be optimized in Search-Based Software Engineering (SBSE), Pareto search has been commonly adopted. It searches for a good approximation of the problem's Pareto optimal solutions, from which the stakeholders choose the most preferred solution according to their preferences. However, when clear preferences of the stakeholders (e.g., a set of weights which reflect relative importance between objectives) are available prior to the search, weighted search is believed to be the first choice since it simplifies the search via converting the original multi-objective problem into a single-objective one and enable the search to focus on what only the stakeholders are interested in.   This paper questions such a ""weighted search first"" belief. We show that the weights can, in fact, be harmful to the search process even in the presence of clear preferences. Specifically, we conduct a large scale empirical study which consists of 38 systems/projects from three representative SBSE problems, together with two types of search budget and nine sets of weights, leading to 604 cases of comparisons. Our key finding is that weighted search reaches a certain level of solution quality by consuming relatively less resources at the early stage of the search; however, Pareto search is at the majority of the time (up to 77% of the cases) significantly better than its weighted counterpart, as long as we allow a sufficient, but not unrealistic search budget. This, together with other findings and actionable suggestions in the paper, allows us to codify pragmatic and comprehensive guidance on choosing weighted and Pareto search for SBSE under the circumstance that clear preferences are available. All code and data can be accessed at: https://github.com/ideas-labo/pareto-vs-weight-for-sbse."	Arxiv	0	['Miqing Li']
402	Java File Security System (JFSS) Evaluation Using Software Engineering Approaches	Brijender Kahanwal	2013-12-06T09:58:40Z	http://arxiv.org/abs/1312.1817v1	A Java File Security System (JFSS) [1] has been developed by us. That is an ecrypted file system. It is developed by us because there are so many file data breaches in the past and current history and they are going to increase day by day as the reports by DataLossDB (Open Security Foundation) organization, a non-profit organization in US so it is. The JFSS is evaluated regarding the two software engineering approaches. One of them is size metric that is Lines of Code (LOC) in the software product development. Another approach is the customer oriented namely User Satisfaction Testing methodology. Satisfying our customers is an essential element to stay in business in modern world of global competition. We must satisfy and even delight our customers with the value of our software products and services to gain their loyalty and repeat business. Customer satisfaction is therefore a primary goal of process improvement programs as well as quality predictions of our software. With the help of User Satisfaction Index that is calculated for many parameters regarding the customer satisfaction. Customer Satisfaction Surveys are the best way to find the satisfaction level of our product quality.	Arxiv	0	['Tejinder Pal Singh']
403	A Taxonomy of Data Quality Challenges in Empirical Software Engineering	Michael Franklin Bosu	2021-06-11T02:56:09Z	http://arxiv.org/abs/2106.06141v1	Reliable empirical models such as those used in software effort estimation or defect prediction are inherently dependent on the data from which they are built. As demands for process and product improvement continue to grow, the quality of the data used in measurement and prediction systems warrants increasingly close scrutiny. In this paper we propose a taxonomy of data quality challenges in empirical software engineering, based on an extensive review of prior research. We consider current assessment techniques for each quality issue and proposed mechanisms to address these issues, where available. Our taxonomy classifies data quality issues into three broad areas: first, characteristics of data that mean they are not fit for modeling; second, data set characteristics that lead to concerns about the suitability of applying a given model to another data set; and third, factors that prevent or limit data accessibility and trust. We identify this latter area as of particular need in terms of further research.	Arxiv	0	['Stephen G. MacDonell']
404	"Development of formal models, algorithms, procedures, engineering and functioning of the software system ""Instrumental complex for ontological engineering purpose"""	A. V. Palagin	2018-03-24T07:14:00Z	http://arxiv.org/abs/1803.10684v2	"The given paper considered a generalized model representation of the software system ""Instrumental complex for ontological engineering purpose"". Represented complete software system development process. Developed relevant formal models of the software system ""Instrumental complex for ontological engineering purpose"", represented as mathematical expressions, UML diagrams, and also described the three-tier architecture of the software system ""Instrumental complex for ontological engineering purpose"" in a client-server environment."	Arxiv	0	['N. G. Petrenko', 'V. Yu. Velychko', 'K. S. Malakhov']
405	Can ChatGPT support software verification?	Christian Jan√üen	2023-11-04T15:25:18Z	http://arxiv.org/abs/2311.02433v2	Large language models have become increasingly effective in software engineering tasks such as code generation, debugging and repair. Language models like ChatGPT can not only generate code, but also explain its inner workings and in particular its correctness. This raises the question whether we can utilize ChatGPT to support formal software verification.   In this paper, we take some first steps towards answering this question. More specifically, we investigate whether ChatGPT can generate loop invariants. Loop invariant generation is a core task in software verification, and the generation of valid and useful invariants would likely help formal verifiers. To provide some first evidence on this hypothesis, we ask ChatGPT to annotate 106 C programs with loop invariants. We check validity and usefulness of the generated invariants by passing them to two verifiers, Frama-C and CPAchecker. Our evaluation shows that ChatGPT is able to produce valid and useful invariants allowing Frama-C to verify tasks that it could not solve before. Based on our initial insights, we propose ways of combining ChatGPT (or large language models in general) and software verifiers, and discuss current limitations and open issues.	Arxiv	0	['Cedric Richter', 'Heike Wehrheim']
406	A Comprehensive Study on Challenges in Deploying Deep Learning Based Software	Zhenpeng Chen	2020-05-02T09:20:29Z	http://arxiv.org/abs/2005.00760v4	Deep learning (DL) becomes increasingly pervasive, being used in a wide range of software applications. These software applications, named as DL based software (in short as DL software), integrate DL models trained using a large data corpus with DL programs written based on DL frameworks such as TensorFlow and Keras. A DL program encodes the network structure of a desirable DL model and the process by which the model is trained using the training data. To help developers of DL software meet the new challenges posed by DL, enormous research efforts in software engineering have been devoted. Existing studies focus on the development of DL software and extensively analyze faults in DL programs. However, the deployment of DL software has not been comprehensively studied. To fill this knowledge gap, this paper presents a comprehensive study on understanding challenges in deploying DL software. We mine and analyze 3,023 relevant posts from Stack Overflow, a popular Q&A website for developers, and show the increasing popularity and high difficulty of DL software deployment among developers. We build a taxonomy of specific challenges encountered by developers in the process of DL software deployment through manual inspection of 769 sampled posts and report a series of actionable implications for researchers, developers, and DL framework vendors.	Arxiv	0	['Yanbin Cao', 'Yuanqiang Liu', 'Haoyu Wang', 'Tao Xie', 'Xuanzhe Liu']
407	Web Engineering	Yogesh Deshpande	2003-06-18T03:13:44Z	http://arxiv.org/abs/cs/0306108v1	Web Engineering is the application of systematic, disciplined and quantifiable approaches to development, operation, and maintenance of Web-based applications. It is both a pro-active approach and a growing collection of theoretical and empirical research in Web application development. This paper gives an overview of Web Engineering by addressing the questions: a) why is it needed? b) what is its domain of operation? c) how does it help and what should it do to improve Web application development? and d) how should it be incorporated in education and training? The paper discusses the significant differences that exist between Web applications and conventional software, the taxonomy of Web applications, the progress made so far and the research issues and experience of creating a specialisation at the master's level. The paper reaches a conclusion that Web Engineering at this stage is a moving target since Web technologies are constantly evolving, making new types of applications possible, which in turn may require innovations in how they are built, deployed and maintained.	Arxiv	0	['San Murugesan', 'Athula Ginige', 'Steve Hansen', 'Daniel Schwabe', 'Martin Gaedke', 'Bebo White']
408	ACM SIGSOFT SEN Empirical Software Engineering: Introducing Our New Regular Column	Justus Bogner	2025-10-02T13:28:54Z	http://arxiv.org/abs/2510.02007v2	From its early foundations in the 1970s, empirical software engineering (ESE) has evolved into a mature research discipline that embraces a plethora of different topics, methodologies, and industrial practices. Despite its remarkable progress, the ESE research field still needs to keep evolving, as new impediments, shortcoming, and technologies emerge. Research reproducibility, limited external validity, subjectivity of reviews, and porting research results to industrial practices are just some examples of the drivers for improvements to ESE research. Additionally, several facets of ESE research are not documented very explicitly, which makes it difficult for newcomers to pick them up. With this new regular ACM SIGSOFT SEN column (SEN-ESE), we introduce a venue for discussing meta-aspects of ESE research, ranging from general topics such as the nature and best practices for replication packages, to more nuanced themes such as statistical methods, interview transcription tools, and publishing interdisciplinary research. Our aim for the column is to be a place where we can regularly spark conversations on ESE topics that might not often be touched upon or are left implicit. Contributions to this column will be grounded in expert interviews, focus groups, surveys, and position pieces, with the goal of encouraging reflection and improvement in how we conduct, communicate, teach, and ultimately improve ESE research. Finally, we invite feedback from the ESE community on challenging, controversial, or underexplored topics, as well as suggestions for voices you would like to hear from. While we cannot promise to act on every idea, we aim to shape this column around the community interests and are grateful for all contributions.	Arxiv	0	['Roberto Verdecchia']
409	Quality Classifiers for Open Source Software Repositories	George Tsatsaronis	2009-04-29T21:33:39Z	http://arxiv.org/abs/0904.4708v1	Open Source Software (OSS) often relies on large repositories, like SourceForge, for initial incubation. The OSS repositories offer a large variety of meta-data providing interesting information about projects and their success. In this paper we propose a data mining approach for training classifiers on the OSS meta-data provided by such data repositories. The classifiers learn to predict the successful continuation of an OSS project. The `successfulness' of projects is defined in terms of the classifier confidence with which it predicts that they could be ported in popular OSS projects (such as FreeBSD, Gentoo Portage).	Arxiv	0	['Maria Halkidi', 'Emmanouel A. Giakoumakis']
410	On Cloud-Based Engineering of Dependable Systems	Sami Alajrami	2014-04-29T20:01:55Z	http://arxiv.org/abs/1404.7509v1	The cloud computing paradigm is being adopted by many organizations in different application domains as it is cost effective and offers a virtually unlimited pool of resources. Engineering critical systems can benefit from clouds in attaining all dependability means: fault tolerance, fault prevention, fault removal and fault forecasting. Our research aims to investigate the potential of supporting engineering of dependable software systems with cloud computing and proposes an open, extensible, and elastic cloud-based software engineering workflow system which represents and executes software processes to improve collaboration, reliability and quality assurance, and automation in software projects.	Arxiv	0	[]
411	Augmenting the Generality and Performance of Large Language Models for Software Engineering	Fabian C. Pe√±a	2025-06-13T08:00:38Z	http://arxiv.org/abs/2506.11548v1	Large Language Models (LLMs) are revolutionizing software engineering (SE), with special emphasis on code generation and analysis. However, their applications to broader SE practices including conceptualization, design, and other non-code tasks, remain partially underexplored. This research aims to augment the generality and performance of LLMs for SE by (1) advancing the understanding of how LLMs with different characteristics perform on various non-code tasks, (2) evaluating them as sources of foundational knowledge in SE, and (3) effectively detecting hallucinations on SE statements. The expected contributions include a variety of LLMs trained and evaluated on domain-specific datasets, new benchmarks on foundational knowledge in SE, and methods for detecting hallucinations. Initial results in terms of performance improvements on various non-code tasks are promising.	Arxiv	0	[]
412	Knowledge Management in Software Engineering: A Systematic Review of Studied Concepts, Findings and Research Methods Used	Finn Olav Bj√∏rnson	2018-11-29T16:12:27Z	http://arxiv.org/abs/1811.12278v1	Software engineering is knowledge-intensive work, and how to manage software engineering knowledge has received much attention. This systematic review identifies empirical studies of knowledge management initiatives in software engineering, and discusses the concepts studied, the major findings, and the research methods used. Seven hundred and sixty-two articles were identified, of which 68 were studies in an industry context. Of these, 29 were empirical studies and 39 reports of lessons learned. More than half of the empirical studies were case studies. The majority of empirical studies relate to technocratic and behavioural aspects of knowledge management, while there are few studies relating to economic, spatial and cartographic approaches. A finding reported across multiple papers was the need to not focus exclusively on explicit knowledge, but also consider tacit knowledge. We also describe implications for research and for practice.	Arxiv	0	['Torgeir Dings√∏yr']
413	A Large-Scale Study of Model Integration in ML-Enabled Software Systems	Yorick Sens	2024-08-12T15:28:40Z	http://arxiv.org/abs/2408.06226v2	The rise of machine learning (ML) and its integration into software systems has drastically changed development practices. While software engineering traditionally focused on manually created code artifacts with dedicated processes and architectures, ML-enabled systems require additional data-science methods and tools to create ML artifacts -- especially ML models and training data. However, integrating models into systems, and managing the many different artifacts involved, is far from trivial. ML-enabled systems can easily have multiple ML models that interact with each other and with traditional code in intricate ways. Unfortunately, while challenges and practices of building ML-enabled systems have been studied, little is known about the characteristics of real-world ML-enabled systems beyond isolated examples. Improving engineering processes and architectures for ML-enabled systems requires improving the empirical understanding of these systems. We present a large-scale study of 2,928 open-source ML-enabled software systems. We classified and analyzed them to determine system characteristics, model and code reuse practices, and architectural aspects of integrating ML models. Our findings show that these systems still mainly consist of traditional source code, and that ML model reuse through code duplication or pre-trained models is common. We also identified different ML integration patterns and related implementation practices. We hope that our results help improve practices for integrating ML models, bringing data science and software engineering closer together.	Arxiv	0	['Henriette Knopp', 'Sven Peldszus', 'Thorsten Berger']
414	Overwhelmed Software Developers	Lisa-Marie Michels	2024-06-06T13:25:18Z	http://arxiv.org/abs/2406.04057v1	We have conducted a qualitative psychology study to explore the experience of feeling overwhelmed in the realm of software development. Through the candid confessions of two participants who have recently faced overwhelming challenges, we have identified seven distinct categories: communication-induced, disturbance-related, organizational, variety, technical, temporal, and positive overwhelm. While most types of overwhelm tend to deteriorate productivity and increase stress levels, developers sometimes perceive overwhelm as a catalyst for heightened focus, self-motivation, and productivity. Stress was often found to be a common companion of overwhelm. Our findings align with previous studies conducted in diverse disciplines. However, we believe that software developers possess unique traits that may enable them to navigate through the storm of overwhelm more effectively.	Arxiv	0	['Aleksandra Petkova', 'Marcel Richter', 'Andreas Farley', 'Daniel Graziotin', 'Stefan Wagner']
415	Towards Maintainable Platform Software -- Delivery Cost Control in Continuous Software Development	Ning Luo	2022-03-29T09:42:21Z	http://arxiv.org/abs/2203.15396v1	Modern platform software delivery cost increases rapidly as it usually needs to align with many hardware and silicon's TTMs, feature evolvement and involves hundreds of engineers. In this paper, citing one ultra-large-scale software - Intel Media Driver as an example, we analyze the hotspots leading to delivery cost increase in continuous software development, the challenges on our software design and our experiences on software delivery cost shrink against the targeted design enhancements. We expect the identified hotspots can help more researchers to form the corresponding research agendas and the experiences shared can help following practitioners to apply similar enhancements.	Arxiv	0	['Yue Xiong']
416	Improving Software Developer's Competence: Is the Personal Software Process Working?	Pekka Abrahamsson	2013-11-01T17:23:06Z	http://arxiv.org/abs/1311.0228v1	Emerging agile software development methods are people oriented development approaches to be used by the software industry. The personal software process (PSP) is an accepted method for improving the capabilities of a single software engineer. Five original hypotheses regarding the impact of the PSP to individual performance are tested. Data is obtained from 58 computer science students in three university courses on the master level, which were held in two different educational institutions in Finland and Denmark. Statistical data treatment shows that the use of PSP did not improve size and time estimation skills but that the productivity did not decrease and the resulting product quality was improved. The implications of these findings are briefly addressed.	Arxiv	0	['Karlheinz Kautz', 'Heikki Sieppi', 'Jouni Lappalainen']
417	Understanding the Context of IoT Software Systems in DevOps	Igor Muzetti Pereira	2021-04-20T17:39:47Z	http://arxiv.org/abs/2104.10147v2	The growing demand for connected devices and the increase in investments in the Internet of Things (IoT) sector induce the growth of the market for this technology. IoT permeates all areas of life of an individual, from smartwatches to entire home assistants and solutions in different areas. The IoT concept is gradually increasing all over the globe. IoT projects induce an articulation of studies in software engineering to prepare the development and operation of software systems materialized in physical objects and structures interconnected with embedded software and hosted in clouds. IoT projects have boundaries between development and operation stages. This study search for evidence in scientific literature to support these boundaries through Development and Operations (DevOps) principles. We rely on a Systematic Literature Review to investigate the relations of DevOps in IoT software systems. As a result, we identify concepts, characterize the benefits and challenges in the context of knowledge previously reported in primary studies in the literature. The main contributions of this paper are: (i) discussion of benefits and challenges for DevOps in IoT software systems, (ii) identification of tools, concepts, and programming languages used, and, (iii) perceived pipeline for this kind of software development.	Arxiv	0	['Tiago Garcia de Senna Carneiro', 'Eduardo Figueiredo']
418	The Four Pillars of Research Software Engineering	J. Cohen	2020-02-03T22:27:05Z	http://arxiv.org/abs/2002.01035v2	Building software that can support the huge growth in data and computation required by modern research needs individuals with increasingly specialist skill sets that take time to develop and maintain. The Research Software Engineering movement, which started in the UK and has been built up over recent years, aims to recognise and support these individuals. Why does research software matter to professional software development practitioners outside the research community? Research software can have great impact on the wider world and recent progress means the area can now be considered as a more realistic option for a professional software development career. In this article we present a structure, along with supporting evidence of real-world activities, that defines four elements that we believe are key to providing comprehensive and sustainable support for Research Software Engineering. We also highlight ways that the wider developer community can learn from, and engage with, these activities.	Arxiv	0	['D. S. Katz', 'M. Barker', 'N. Chue Hong', 'R. Haines', 'C. Jay']
419	Individual Differences Limit Predicting Well-being and Productivity Using Software Repositories: A Longitudinal Industrial Study	Miikka Kuutila	2021-04-28T11:37:39Z	http://arxiv.org/abs/2104.13713v1	Reports of poor work well-being and fluctuating productivity in software engineering have been reported in both academic and popular sources. Understanding and predicting these issues through repository analysis might help manage software developers' well-being. Our objective is to link data from software repositories, that is commit activity, communication, expressed sentiments, and job events, with measures of well-being obtained with a daily experience sampling questionnaire. To achieve our objective, we studied a single software project team for eight months in the software industry. Additionally, we performed semi-structured interviews to explain our results. The acquired quantitative data are analyzed with generalized linear mixed-effects models with autocorrelation structure. We find that individual variance accounts for most of the $R^2$ values in models predicting developers' experienced well-being and productivity. In other words, using software repository variables to predict developers' well-being or productivity is challenging due to individual differences. Prediction models developed for each developer individually work better, with fixed effects $R^2$ value of up to 0.24. The semi-structured interviews give insights into the well-being of software developers and the benefits of chat interaction. Our study suggests that individualized prediction models are needed for well-being and productivity prediction in software development.	Arxiv	0	['Mika M√§ntyl√§', 'Ma√´lick', 'Claes', 'Marko Elovainio', 'Bram Adams']
420	Predicting User Actions in Software Processes	Michael Deynet	2011-10-06T15:42:02Z	http://arxiv.org/abs/1110.1301v1	This paper describes an approach for user (e.g. SW architect) assisting in software processes. The approach observes the user's action and tries to predict his next step. For this we use approaches in the area of machine learning (sequence learning) and adopt these for the use in software processes.   Keywords: Software engineering, Software process description languages, Software processes, Machine learning, Sequence prediction	Arxiv	0	[]
421	Automated Software Vulnerability Assessment with Concept Drift	Triet H. M. Le	2021-03-21T06:28:45Z	http://arxiv.org/abs/2103.11316v1	Software Engineering researchers are increasingly using Natural Language Processing (NLP) techniques to automate Software Vulnerabilities (SVs) assessment using the descriptions in public repositories. However, the existing NLP-based approaches suffer from concept drift. This problem is caused by a lack of proper treatment of new (out-of-vocabulary) terms for the evaluation of unseen SVs over time. To perform automated SVs assessment with concept drift using SVs' descriptions, we propose a systematic approach that combines both character and word features. The proposed approach is used to predict seven Vulnerability Characteristics (VCs). The optimal model of each VC is selected using our customized time-based cross-validation method from a list of eight NLP representations and six well-known Machine Learning models. We have used the proposed approach to conduct large-scale experiments on more than 100,000 SVs in the National Vulnerability Database (NVD). The results show that our approach can effectively tackle the concept drift issue of the SVs' descriptions reported from 2000 to 2018 in NVD even without retraining the model. In addition, our approach performs competitively compared to the existing word-only method. We also investigate how to build compact concept-drift-aware models with much fewer features and give some recommendations on the choice of classifiers and NLP representations for SVs assessment.	Arxiv	0	['Bushra Sabir', 'M. Ali Babar']
422	The Effects of Continuous Integration on Software Development: a Systematic Literature Review	Eliezio Soares	2021-03-09T14:35:22Z	http://arxiv.org/abs/2103.05451v3	Context: Continuous integration (CI) is a software engineering technique that proclaims a set of frequent activities to assure the health of the software product. Researchers and practitioners mention several benefits related to CI. However, no systematic study surveys state of the art regarding such benefits or cons. Objective: This study aims to identify and interpret empirical evidence regarding how CI impacts software development. Method: Through a Systematic Literature Review, we search for studies in six digital libraries. Starting from 479 studies, we select 101 empirical studies that evaluate CI for any software development activity (e.g., testing). We thoroughly read and extract information regarding (i) CI environment, (ii) findings related to effects of CI, and (iii) the employed methodology. We apply a thematic synthesis to group and summarize the findings. Results: Existing research has explored the positive effects of CI, such as better cooperation, or negative effects, such as adding technical and process challenges. From our thematic synthesis, we identify six themes: development activities, software process, quality assurance, integration patterns, issues & defects, and build patterns. Conclusions: Empirical research in CI has been increasing over recent years. We found that much of the existing research reveals that CI brings positive effects to the software development phenomena. However, CI may also bring technical challenges to software development teams. Despite the overall positive outlook regarding CI, we still find room for improvements in the existing empirical research that evaluates the effects of CI.	Arxiv	0	['Gustavo Sizilio', 'Jadson Santos', 'Daniel Alencar', 'Uira Kulesza']
423	Towards a Strategy for Supporting the Engineering of Contemporary Software Systems	Rebeca C. Motta	2019-04-26T09:44:37Z	http://arxiv.org/abs/1904.11741v1	Contemporary software systems, such as the Internet of Things, Industry 4.0 and Intelligent Cities, present challenges for their engineering, since they question our traditional form of software development. They represent a promising paradigm for the integration of communication devices and technologies. It is leading to a shift from the classical monolithic view of development where stakeholders receive a software product at the end, to materialized software systems through physical objects interconnected by networks and with embedded smartness to support activities. Therefore, it is necessary to revisit our way of developing software systems and begin to consider the particularities required by these new types of applications. This thesis aims to investigate the particularities of these new types of applications to support the definition of a framework to support decision-making in the engineering of this kind of applications and systems. To this end, we use IoT systems as surrogate for CSS, since they present the contemporaneity and multidisciplinarity that we aim to investigate.	Arxiv	0	[]
424	FAIL: Analyzing Software Failures from the News Using LLMs	Dharun Anandayuvaraj	2024-06-12T13:51:51Z	http://arxiv.org/abs/2406.08221v2	Software failures inform engineering work, standards, regulations. For example, the Log4J vulnerability brought government and industry attention to evaluating and securing software supply chains. Accessing private engineering records is difficult, so failure analyses tend to use information reported by the news media. However, prior works in this direction have relied on manual analysis. That has limited the scale of their analyses. The community lacks automated support to enable such analyses to consider a wide range of news sources and incidents. In this paper, we propose the Failure Analysis Investigation with LLMs (FAIL) system to fill this gap. FAIL collects, analyzes, and summarizes software failures as reported in the news. FAIL groups articles that describe the same incidents. It then analyzes incidents using existing taxonomies for postmortems, faults, and system characteristics. To tune and evaluate FAIL, we followed the methods of prior works by manually analyzing 31 software failures. FAIL achieved an F1 score of 90% for collecting news about software failures, a V-measure of 0.98 for merging articles reporting on the same incident, and extracted 90% of the facts about failures. We then applied FAIL to a total of 137,427 news articles from 11 providers published between 2010 and 2022. FAIL identified and analyzed 2457 distinct failures reported across 4,184 articles. Our findings include: (1) current generation of large language models are capable of identifying news articles that describe failures, and analyzing them according to structured taxonomies; (2) high recurrences of similar failures within organizations and across organizations; and (3) severity of the consequences of software failures have increased over the past decade. The full FAIL database is available so that researchers, engineers, and policymakers can learn from a diversity of software failures.	Arxiv	0	['Matthew Campbell', 'Arav Tewari', 'James C. Davis']
425	Categorizing Bugs with Social Networks: A Case Study on Four Open Source Software Communities	Marcelo Serrano Zanetti	2013-02-27T13:32:15Z	http://arxiv.org/abs/1302.6764v2	Efficient bug triaging procedures are an important precondition for successful collaborative software engineering projects. Triaging bugs can become a laborious task particularly in open source software (OSS) projects with a large base of comparably inexperienced part-time contributors. In this paper, we propose an efficient and practical method to identify valid bug reports which a) refer to an actual software bug, b) are not duplicates and c) contain enough information to be processed right away. Our classification is based on nine measures to quantify the social embeddedness of bug reporters in the collaboration network. We demonstrate its applicability in a case study, using a comprehensive data set of more than 700,000 bug reports obtained from the Bugzilla installation of four major OSS communities, for a period of more than ten years. For those projects that exhibit the lowest fraction of valid bug reports, we find that the bug reporters' position in the collaboration network is a strong indicator for the quality of bug reports. Based on this finding, we develop an automated classification scheme that can easily be integrated into bug tracking platforms and analyze its performance in the considered OSS communities. A support vector machine (SVM) to identify valid bug reports based on the nine measures yields a precision of up to 90.3% with an associated recall of 38.9%. With this, we significantly improve the results obtained in previous case studies for an automated early identification of bugs that are eventually fixed. Furthermore, our study highlights the potential of using quantitative measures of social organization in collaborative software engineering. It also opens a broad perspective for the integration of social awareness in the design of support infrastructures.	Arxiv	0	['Ingo Scholtes', 'Claudio Juan Tessone', 'Frank Schweitzer']
426	An Empirical Study of Bots in Software Development -- Characteristics and Challenges from a Practitioner's Perspective	Linda Erlenhov	2020-05-28T13:17:43Z	http://arxiv.org/abs/2005.13969v2	"Software engineering bots - automated tools that handle tedious tasks - are increasingly used by industrial and open source projects to improve developer productivity. Current research in this area is held back by a lack of consensus of what software engineering bots (DevBots) actually are, what characteristics distinguish them from other tools, and what benefits and challenges are associated with DevBot usage. In this paper we report on a mixed-method empirical study of DevBot usage in industrial practice. We report on findings from interviewing 21 and surveying a total of 111 developers. We identify three different personas among DevBot users (focusing on autonomy, chat interfaces, and ""smartness""), each with different definitions of what a DevBot is, why developers use them, and what they struggle with. We conclude that future DevBot research should situate their work within our framework, to clearly identify what type of bot the work targets, and what advantages practitioners can expect. Further, we find that there currently is a lack of general purpose ""smart"" bots that go beyond simple automation tools or chat interfaces. This is problematic, as we have seen that such bots, if available, can have a transformative effect on the projects that use them."	Arxiv	0	['Francisco Gomes de Oliveira Neto', 'Philipp Leitner']
427	SEER: Sustainability Enhanced Engineering of Software Requirements	Mandira Roy	2025-10-10T03:48:30Z	http://arxiv.org/abs/2510.08981v1	The rapid expansion of software development has significant environmental, technical, social, and economic impacts. Achieving the United Nations Sustainable Development Goals by 2030 compels developers to adopt sustainable practices. Existing methods mostly offer high-level guidelines, which are time-consuming to implement and rely on team adaptability. Moreover, they focus on design or implementation, while sustainability assessment should start at the requirements engineering phase. In this paper, we introduce SEER, a framework which addresses sustainability concerns in the early software development phase. The framework operates in three stages: (i) it identifies sustainability requirements (SRs) relevant to a specific software product from a general taxonomy; (ii) it evaluates how sustainable system requirements are based on the identified SRs; and (iii) it optimizes system requirements that fail to satisfy any SR. The framework is implemented using the reasoning capabilities of large language models and the agentic RAG (Retrieval Augmented Generation) approach. SEER has been experimented on four software projects from different domains. Results generated using Gemini 2.5 reasoning model demonstrate the effectiveness of the proposed approach in accurately identifying a broad range of sustainability concerns across diverse domains.	Arxiv	0	['Novarun Deb', 'Nabendu Chaki', 'Agostino Cortesi']
428	What Is Software Engineering?	Fedor Dzerzhinskiy	2015-08-09T14:34:00Z	http://arxiv.org/abs/1508.02031v2	A later translation (2015) of the article in Russian published in 1990. The article proposes an approach to defining a set of basic notions for subject area of software engineering discipline. The set of notions is intended to serve as a basis for detection and correction of some widespread conceptual mistakes in the efforts aimed at improving the quality and work productivity in creation and operation of software.	Arxiv	0	['Leonid D. Raykov']
429	The Future of Generative AI in Software Engineering: A Vision from Industry and Academia in the European GENIUS Project	Robin Gr√∂pler	2025-11-03T08:56:23Z	http://arxiv.org/abs/2511.01348v2	Generative AI (GenAI) has recently emerged as a groundbreaking force in Software Engineering, capable of generating code, identifying bugs, recommending fixes, and supporting quality assurance. While its use in coding tasks shows considerable promise, applying GenAI across the entire Software Development Life Cycle (SDLC) has not yet been fully explored. Critical uncertainties in areas such as reliability, accountability, security, and data privacy demand deeper investigation and coordinated action. The GENIUS project, comprising over 30 European industrial and academic partners, aims to address these challenges by advancing AI integration across all SDLC phases. It focuses on GenAI's potential, the development of innovative tools, and emerging research challenges, actively shaping the future of software engineering. This vision paper presents a shared perspective on the future of GenAI-driven software engineering, grounded in cross-sector dialogue as well as experiences and findings within the GENIUS consortium. The paper explores four central elements: (1) a structured overview of current challenges in GenAI adoption across the SDLC; (2) a forward-looking vision outlining key technological and methodological advances expected over the next five years; (3) anticipated shifts in the roles and required skill sets of software professionals; and (4) the contribution of GENIUS in realising this transformation through practical tools and industrial validation. This paper focuses on aligning technical innovation with business relevance. It aims to inform both research agendas and industrial strategies, providing a foundation for reliable, scalable, and industry-ready GenAI solutions for software engineering teams.	Arxiv	0	['Steffen Klepke', 'Jack Johns', 'Andreas Dreschinski', 'Klaus Schmid', 'Benedikt Dornauer', 'Eray T√ºz√ºn', 'Joost Noppen', 'Mohammad Reza Mousavi', 'Yongjian Tang', 'Johannes Viehmann', 'Selin ≈ûirin Aslang√ºl', 'Beum Seuk Lee', 'Adam Ziolkowski', 'Eric Zie']
430	Unifying Classification Schemes for Software Engineering Meta-Research	Angelika Kaplan	2022-09-21T16:49:30Z	http://arxiv.org/abs/2209.10491v1	Background: Classifications in meta-research enable researchers to cope with an increasing body of scientific knowledge. They provide a framework for, e.g., distinguishing methods, reports, reproducibility, and evaluation in a knowledge field as well as a common terminology. Both eases sharing, understanding and evolution of knowledge. In software engineering (SE), there are several classifications that describe the nature of SE research. Regarding the consolidation of the large body of classified knowledge in SE research, a generally applicable classification scheme is crucial. Moreover, the commonalities and differences among different classification schemes have rarely been studied. Due to the fact that classifications are documented textual, it is hard to catalog, reuse, and compare them. To the best of our knowledge, there is no research work so far that addresses documentation and systematic investigation of classifications in SE meta-research. Objective: We aim to construct a unified, generally applicable classification scheme for SE meta-research by collecting and documenting existing classification schemes and unifying their classes and categories. Method: Our execution plan is divided into three phases: construction, validation, and evaluation phase. For the construction phase, we perform a literature review to identify, collect, and analyze a set of established SE research classifications. In the validation phase, we analyze individual categories and classes of included papers. We use quantitative metrics from literature to conduct and assess the unification process to build a generally applicable classification scheme for SE research. Lastly, we investigate the applicability of the unified scheme. Therefore, we perform a workshop session followed by user studies w.r.t. investigations about reliability, correctness, and ease of use.	Arxiv	0	['Thomas K√ºhn', 'Ralf Reussner']
431	Sustainability is Stratified: Toward a Better Theory of Sustainable Software Engineering	Sean McGuire	2023-01-26T14:27:35Z	http://arxiv.org/abs/2301.11129v1	Background: Sustainable software engineering (SSE) means creating software in a way that meets present needs without undermining our collective capacity to meet our future needs. It is typically conceptualized as several intersecting dimensions or ``pillars'' -- environmental, social, economic, technical and individual. However; these pillars are theoretically underdeveloped and require refinement. Objectives: The objective of this paper is to generate a better theory of SSE. Method: First, a scoping review was conducted to understand the state of research on SSE and identify existing models thereof. Next, a meta-synthesis of qualitative research on SSE was conducted to critique and improve the existing models identified. Results: 961 potentially relevant articles were extracted from five article databases. These articles were de-duplicated and then screened independently by two screeners, leaving 243 articles to examine. Of these, 109 were non-empirical, the most common empirical method was systematic review, and no randomized controlled experiments were found. Most papers focus on ecological sustainability (158) and the sustainability of software products (148) rather than processes. A meta-synthesis of 36 qualitative studies produced several key propositions, most notably, that sustainability is stratified (has different meanings at different levels of abstraction) and multisystemic (emerges from interactions among multiple social, technical, and sociotechnical systems). Conclusion: The academic literature on SSE is surprisingly non-empirical. More empirical evaluations of specific sustainability interventions are needed. The sustainability of software development products and processes should be conceptualized as multisystemic and stratified, and assessed accordingly.	Arxiv	0	['Erin Shultz', 'Bimpe Ayoola', 'Paul Ralph']
432	Contrasting the Hyperparameter Tuning Impact Across Software Defect Prediction Scenarios	Mohamed Sami Rakha	2025-10-18T23:36:06Z	http://arxiv.org/abs/2510.16665v1	Software defect prediction (SDP) is crucial for delivering high-quality software products. Recent research has indicated that prediction performance improvements in SDP are achievable by applying hyperparameter tuning to a particular SDP scenario. However, the positive impact resulting from the hyperparameter tuning step may differ based on the targeted SDP scenario. Comparing the impact of hyperparameter tuning across SDP scenarios is necessary to provide comprehensive insights and enhance the robustness, generalizability, and, eventually, the practicality of SDP modeling for quality assurance.   Therefore, in this study, we contrast the impact of hyperparameter tuning across two pivotal and consecutive SDP scenarios: (1) Inner Version Defect Prediction (IVDP) and (2) Cross Version Defect Prediction (CVDP). The main distinctions between the two scenarios lie in the scope of defect prediction and the selected evaluation setups. This study's experiments use common evaluation setups, 28 machine learning (ML) algorithms, 53 post-release software datasets, two tuning algorithms, and five optimization metrics. We apply statistical analytics to compare the SDP performance impact differences by investigating the overall impact, the single ML algorithm impact, and variations across different software dataset sizes.   The results indicate that the SDP gains within the IVDP scenario are significantly larger than those within the CVDP scenario. The results reveal that asserting performance gains for up to 24 out of 28 ML algorithms may not hold across multiple SDP scenarios. Furthermore, we found that small software datasets are more susceptible to larger differences in performance impacts. Overall, the study findings recommend software engineering researchers and practitioners to consider the effect of the selected SDP scenario when expecting performance gains from hyperparameter tuning.	Arxiv	0	['Andriy Miranskyy', 'Daniel Alencar da Costa']
433	Quantum vs. Classical Machine Learning Algorithms for Software Defect Prediction: Challenges and Opportunities	Md Nadim	2024-12-10T17:38:36Z	http://arxiv.org/abs/2412.07698v1	Software defect prediction is a critical aspect of software quality assurance, as it enables early identification and mitigation of defects, thereby reducing the cost and impact of software failures. Over the past few years, quantum computing has risen as an exciting technology capable of transforming multiple domains; Quantum Machine Learning (QML) is one of them. QML algorithms harness the power of quantum computing to solve complex problems with better efficiency and effectiveness than their classical counterparts. However, research into its application in software engineering to predict software defects still needs to be explored. In this study, we worked to fill the research gap by comparing the performance of three QML and five classical machine learning (CML) algorithms on the 20 software defect datasets. Our investigation reports the comparative scenarios of QML vs. CML algorithms and identifies the better-performing and consistent algorithms to predict software defects. We also highlight the challenges and future directions of employing QML algorithms in real software defect datasets based on the experience we faced while performing this investigation. The findings of this study can help practitioners and researchers further progress in this research domain by making software systems reliable and bug-free.	Arxiv	0	['Mohammad Hassan', 'Ashis Kumar Mandal', 'Chanchal K. Roy']
434	IMPRESS: Improving Engagement in Software Engineering Courses through Gamification	Tanja E. J. Vos	2019-12-14T14:09:15Z	http://arxiv.org/abs/1912.06850v1	Software Engineering courses play an important role for preparing students with the right knowledge and attitude for software development in practice. The implication is far reaching, as the quality of the software that we use ultimately depends on the quality of the people that make them. Educating Software Engineering, however, is quite challenging, as the subject is not considered as most exciting by students, while teachers often have to deal with exploding number of students. The EU project IMPRESS seeks to explore the use of gamification in educating software engineering at the university level to improve students' engagement and hence their appreciation for the taught subjects. This paper presents the project, its objectives, and its current progress.	Arxiv	0	['I. S. W. B. Prasetya', 'Gordon Fraser', 'Ivan Martinez-Ortiz', 'Ivan Perez-Colado', 'Rui Prada', 'Jose Rocha', 'Antonio Rito Silva']
435	Agile Risk Management for Multi-Cloud Software Development	Victor Munt√©s-Mulero	2020-01-10T09:16:32Z	http://arxiv.org/abs/2001.03356v1	Industry in all sectors is experiencing a profound digital transformation that puts software at the core of their businesses. In order to react to continuously changing user requirements and dynamic markets, companies need to build robust workflows that allow them to increase their agility in order to remain competitive. This increasingly rapid transformation, especially in domains like IoT or Cloud computing, poses significant challenges to guarantee high quality software, since dynamism and agile short-term planning reduce the ability to detect and manage risks. In this paper, we describe the main challenges related to managing risk in agile software development, building on the experience of more than 20 agile coaches operating continuously for 15 years with hundreds of teams in industries in all sectors. We also propose a framework to manage risks that considers those challenges and supports collaboration, agility, and continuous development. An implementation of that framework is then described in a tool that handles risks and mitigation actions associated with the development of multi-cloud applications. The methodology and the tool have been validated by a team of evaluators that were asked to consider its use in developing an urban smart mobility service and an airline flight scheduling system.	Arxiv	0	['Oscar Ripolles', 'Smrati Gupta', 'Jacek Dominiak', 'Eric Willeke', 'Peter Matthews', 'Bal√°zs Somosk√∂i']
436	Many-Objective Optimization of Non-Functional Attributes based on Refactoring of Software Models	Vittorio Cortellessa	2023-01-23T16:32:55Z	http://arxiv.org/abs/2301.09531v1	Software quality estimation is a challenging and time-consuming activity, and models are crucial to face the complexity of such activity on modern software applications. In this context, software refactoring is a crucial activity within development life-cycles where requirements and functionalities rapidly evolve. One main challenge is that the improvement of distinctive quality attributes may require contrasting refactoring actions on software, as for trade-off between performance and reliability (or other non-functional attributes). In such cases, multi-objective optimization can provide the designer with a wider view on these trade-offs and, consequently, can lead to identify suitable refactoring actions that take into account independent or even competing objectives. In this paper, we present an approach that exploits NSGA-II as the genetic algorithm to search optimal Pareto frontiers for software refactoring while considering many objectives. We consider performance and reliability variations of a model alternative with respect to an initial model, the amount of performance antipatterns detected on the model alternative, and the architectural distance, which quantifies the effort to obtain a model alternative from the initial one. We applied our approach on two case studies: a Train Ticket Booking Service, and CoCoME. We observed that our approach is able to improve performance (by up to 42\%) while preserving or even improving the reliability (by up to 32\%) of generated model alternatives. We also observed that there exists an order of preference of refactoring actions among model alternatives. We can state that performance antipatterns confirmed their ability to improve performance of a subject model in the context of many-objective optimization. In addition, the metric that we adopted for the architectural distance seems to be suitable for estimating the refactoring effort.	Arxiv	0	['Daniele Di Pompeo', 'Vincenzo Stoico', 'Michele Tucci']
437	Mining for Process Improvements: Analyzing Software Repositories in Agile Retrospectives	Christoph Matthies	2020-07-16T11:32:30Z	http://arxiv.org/abs/2007.08265v1	Software Repositories contain knowledge on how software engineering teams work, communicate, and collaborate. It can be used to develop a data-informed view of a team's development process, which in turn can be employed for process improvement initiatives. In modern, Agile development methods, process improvement takes place in Retrospective meetings, in which the last development iteration is discussed. However, previously proposed activities that take place in these meetings often do not rely on project data, instead depending solely on the perceptions of team members. We propose new Retrospective activities, based on mining the software repositories of individual teams, to complement existing approaches with more objective, data-informed process views.	Arxiv	0	['Franziska Dobrigkeit', 'Guenter Hesse']
438	How Do Static and Dynamic Test Case Prioritization Techniques Perform on Modern Software Systems? An Extensive Study on GitHub Projects	Qi Luo	2018-06-26T03:01:21Z	http://arxiv.org/abs/1806.09774v1	Test Case Prioritization (TCP) is an increasingly important regression testing technique for reordering test cases according to a pre-defined goal, particularly as agile practices gain adoption. To better understand these techniques, we perform the first extensive study aimed at empirically evaluating four static TCP techniques, comparing them with state-of-research dynamic TCP techniques across several quality metrics. This study was performed on 58 real-word Java programs encompassing 714 KLoC and results in several notable observations. First, our results across two effectiveness metrics (the Average Percentage of Faults Detected APFD and the cost cognizant APFDc) illustrate that at test-class granularity, these metrics tend to correlate, but this correlation does not hold at test-method granularity. Second, our analysis shows that static techniques can be surprisingly effective, particularly when measured by APFDc. Third, we found that TCP techniques tend to perform better on larger programs, but that program size does not affect comparative performance measures between techniques. Fourth, software evolution does not significantly impact comparative performance results between TCP techniques. Fifth, neither the number nor type of mutants utilized dramatically impact measures of TCP effectiveness under typical experimental settings. Finally, our similarity analysis illustrates that highly prioritized test cases tend to uncover dissimilar faults.	Arxiv	0	['Kevin Moran', 'Lingming Zhang', 'Denys Poshyvanyk']
439	A German Gold-Standard Dataset for Sentiment Analysis in Software Engineering	Martin Obaidi	2025-07-09T22:55:37Z	http://arxiv.org/abs/2507.07325v1	Sentiment analysis is an essential technique for investigating the emotional climate within developer teams, contributing to both team productivity and project success. Existing sentiment analysis tools in software engineering primarily rely on English or non-German gold-standard datasets. To address this gap, our work introduces a German dataset of 5,949 unique developer statements, extracted from the German developer forum Android-Hilfe.de. Each statement was annotated with one of six basic emotions, based on the emotion model by Shaver et al., by four German-speaking computer science students. Evaluation of the annotation process showed high interrater agreement and reliability. These results indicate that the dataset is sufficiently valid and robust to support sentiment analysis in the German-speaking software engineering community. Evaluation with existing German sentiment analysis tools confirms the lack of domain-specific solutions for software engineering. We also discuss approaches to optimize annotation and present further use cases for the dataset.	Arxiv	0	['Marc Herrmann', 'Elisa Schmid', 'Raymond Ochsner', 'Kurt Schneider', 'Jil Kl√ºnder']
440	Content and structure of laboratory packages for software engineering experiments	Mart√≠n Solari	2024-02-11T14:29:15Z	http://arxiv.org/abs/2402.07217v1	Context: Experiment replications play a central role in the scientific method. Although software engineering experimentation has matured a great deal, the number of experiment replications is still relatively small. Software engineering experiments are composed of complex concepts, procedures and artefacts. Laboratory packages are a means of transfer-ring knowledge among researchers to facilitate experiment replications. Objective: This paper investigates the experiment replication process to find out what information is needed to successfully replicate an experiment. Our objective is to propose the content and structure of laboratory packages for software engineering experiments. Method: We evaluated seven replications of three different families of experiments. Each replication had a different experimenter who was, at the time, unfamiliar with the experi-ment. During the first iterations of the study, we identified experimental incidents and then proposed a laboratory package structure that addressed these incidents, including docu-ment usability improvements. We used the later iterations to validate and generalize the laboratory package structure for use in all software engineering experiments. We aimed to solve a specific problem, while at the same time looking at how to contribute to the body of knowledge on laboratory packages. Results: We generated a laboratory package for three different experiments. These packages eased the replication of the respective experiments. The evaluation that we conducted shows that the laboratory package proposal is acceptable and reduces the effort currently required to replicate experiments in software engineering. Conclusion: We think that the content and structure that we propose for laboratory pack-ages can be useful for other software engineering experiments.	Arxiv	0	['Sira Vegas', 'Natalia Juristo']
441	It is Giving Major Satisfaction: Why Fairness Matters for Software Practitioners	Emeralda Sesari	2024-10-03T13:40:00Z	http://arxiv.org/abs/2410.02482v5	Software practitioners often encounter workplace unfairness, such as unequal recognition and gender bias. While the link between fairness and job satisfaction has been established in other fields, its relevance to software professionals remains underexplored. This study examines how fairness perceptions relate to job satisfaction among software practitioners, focusing on both general trends and demographic-specific differences. We conducted an online survey of 108 software practitioners, followed by ordinal logistic regression to analyze the relationship between fairness perceptions and job satisfaction in software engineering contexts, with moderation analysis examining how this relationship varies across demographic groups. Our findings indicate that all four fairness dimensions (namely distributive, procedural, interpersonal, and informational fairness) significantly affect overall job satisfaction and satisfaction with job security. Among these, interpersonal fairness has the biggest impact. The relationship between fairness and job satisfaction is stronger for female, ethnically underrepresented, less experienced practitioners, and those with work limitations. Fairness in authorship emerged as an important factor for job satisfaction collectively, while fairness in policy implementation, high-demand situations, and working hours impacted specific demographic groups. This study highlights the role of fairness among software practitioners, offering strategies for organizations to promote fair practices and targeted approaches for certain demographic groups.	Arxiv	0	['Federica Sarro', 'Ayushi Rastogi']
442	How to Evaluate Solutions in Pareto-based Search-Based Software Engineering? A Critical Review and Methodological Guidance	Miqing Li	2020-02-20T22:12:13Z	http://arxiv.org/abs/2002.09040v4	With modern requirements, there is an increasing tendency of considering multiple objectives/criteria simultaneously in many Software Engineering (SE) scenarios. Such a multi-objective optimization scenario comes with an important issue -- how to evaluate the outcome of optimization algorithms, which typically is a set of incomparable solutions (i.e., being Pareto non-dominated to each other). This issue can be challenging for the SE community, particularly for practitioners of Search-Based SE (SBSE). On one hand, multi-objective optimization could still be relatively new to SE/SBSE researchers, who may not be able to identify the right evaluation methods for their problems. On the other hand, simply following the evaluation methods for general multi-objective optimization problems may not be appropriate for specific SE problems, especially when the problem nature or decision maker's preferences are explicitly/implicitly available. This has been well echoed in the literature by various inappropriate/inadequate selection and inaccurate/misleading use of evaluation methods. In this paper, we first carry out a systematic and critical review of quality evaluation for multi-objective optimization in SBSE. We survey 717 papers published between 2009 and 2019 from 36 venues in seven repositories, and select 95 prominent studies, through which we identify five important but overlooked issues in the area. We then conduct an in-depth analysis of quality evaluation indicators/methods and general situations in SBSE, which, together with the identified issues, enables us to codify a methodological guidance for selecting and using evaluation methods in different SBSE scenarios.	Arxiv	0	['Tao Chen', 'Xin Yao']
443	Quantum Software Development Lifecycle	Benjamin Weder	2021-06-17T08:41:26Z	http://arxiv.org/abs/2106.09323v1	With recent advances in the development of more powerful quantum computers, the research area of quantum software engineering is emerging, having the goal to provide concepts, principles, and guidelines to develop high-quality quantum applications. In classical software engineering, lifecycles are used to document the process of designing, implementing, maintaining, analyzing, and adapting software. Such lifecycles provide a common understanding of how to develop and operate an application, which is especially important due to the interdisciplinary nature of quantum computing. Since today`s quantum applications are, in most cases, hybrid, consisting of quantum and classical programs, the lifecycle for quantum applications must involve the development of both kinds of programs. However, the existing lifecycles only target the development of quantum or classical programs in isolation. Additionally, the various programs must be orchestrated, e.g., using workflows. Thus, the development of quantum applications also incorporates the workflow lifecycle. In this chapter, we analyze the software artifacts usually comprising a quantum application and present their corresponding lifecycles. Furthermore, we identify the points of connection between the various lifecycles and integrate them into the overall quantum software development lifecycle. Therefore, the integrated lifecycle serves as a basis for the development and execution of hybrid quantum applications.	Arxiv	0	['Johanna Barzen', 'Frank Leymann', 'Daniel Vietz']
444	A Progression Model of Software Engineering Goals, Challenges, and Practices in Start-Ups	Eriks Klotins	2023-12-12T09:36:43Z	http://arxiv.org/abs/2312.07106v1	Context: Software start-ups are emerging as suppliers of innovation and software-intensive products. However, traditional software engineering practices are not evaluated in the context, nor adopted to goals and challenges of start-ups. As a result, there is insufficient support for software engineering in the start-up context. Objective: We aim to collect data related to engineering goals, challenges, and practices in start-up companies to ascertain trends and patterns characterizing engineering work in start-ups. Such data allows researchers to understand better how goals and challenges are related to practices. This understanding can then inform future studies aimed at designing solutions addressing those goals and challenges. Besides, these trends and patterns can be useful for practitioners to make more informed decisions in their engineering practice. Method: We use a case survey method to gather first-hand, in-depth experiences from a large sample of software start-ups. We use open coding and cross-case analysis to describe and identify patterns, and corroborate the findings with statistical analysis. Results: We analyze 84 start-up cases and identify 16 goals, 9 challenges, and 16 engineering practices that are common among start-ups. We have mapped these goals, challenges, and practices to start-up life-cycle stages (inception, stabilization, growth, and maturity). Thus, creating the progression model guiding software engineering efforts in start-ups. Conclusions: We conclude that start-ups to a large extent face the same challenges and use the same practices as established companies. However, the primary software engineering challenge in start-ups is to evolve multiple process areas at once, with a little margin for serious errors.	Arxiv	0	['Michael Unterkalmsteiner', 'Panagiota Chatzipetrou', 'Tony Gorschek', 'Rafael Prikladnicki', 'Nirnaya Tripathi', 'Leandro Bento Pompermaier']
445	Experiences and insights from using Github Classroom to support Project-Based Courses	Maria Augusta Nelson	2021-03-12T12:46:18Z	http://arxiv.org/abs/2103.07242v1	This work presents an approach for using GitHub classroom as a shared, structured, and persistent repository to support project-based courses at the Software Engineering Undergraduate program at PUC Minas, in Brazil. We discuss the needs of the different stakeholders that guided the development of the approach. Results on the perceptions of professors and students show that the approach brings benefits. Besides the lessons learned, we present insights on improving the education of the next generation of software engineers by employing metrics to monitor skill development, verifying student work portfolios, and employing tooling support in project-based courses.	Arxiv	0	['Lesandro Ponciano']
446	Are Comprehensive Quality Models Necessary for Evaluating Software Quality?	Klaus Lochmann	2017-03-13T09:25:08Z	http://arxiv.org/abs/1703.04298v1	The concept of software quality is very complex and has many facets. Reflecting all these facets and at the same time measuring everything related to these facets results in comprehensive but large quality models and extensive measurements. In contrast, there are also many smaller, focused quality models claiming to evaluate quality with few measures.   We investigate if and to what extent it is possible to build a focused quality model with similar evaluation results as a comprehensive quality model but with far less measures needed to be collected and, hence, reduced effort. We make quality evaluations with the comprehensive Quamoco base quality model and build focused quality models based on the same set of measures and data from over 2,000 open source systems. We analyse the ability of the focused model to predict the results of the Quamoco model by comparing them with a random predictor as a baseline. We calculate the standardised accuracy measure SA and effect sizes.   We found that for the Quamoco model and its 378 automatically collected measures, we can build a focused model with only 10 measures but an accuracy of 61% and a medium to high effect size. We conclude that we can build focused quality models to get an impression of a system's quality similar to comprehensive models. However, when including manually collected measures, the accuracy of the models stayed below 50%. Hence, manual measures seem to have a high impact and should therefore not be ignored in a focused model.	Arxiv	0	['Jasmin Ramadani', 'Stefan Wagner']
447	A Benchmark Study of the Contemporary Toxicity Detectors on Software Engineering Interactions	Jaydeb Sarker	2020-09-20T01:27:14Z	http://arxiv.org/abs/2009.09331v1	Automated filtering of toxic conversations may help an Open-source software (OSS) community to maintain healthy interactions among the project participants. Although, several general purpose tools exist to identify toxic contents, those may incorrectly flag some words commonly used in the Software Engineering (SE) context as toxic (e.g., 'junk', 'kill', and 'dump') and vice versa. To encounter this challenge, an SE specific tool has been proposed by the CMU Strudel Lab (referred as the `STRUDEL' hereinafter) by combining the output of the Perspective API with the output from a customized version of the Stanford's Politeness detector tool. However, since STRUDEL's evaluation was very limited with only 654 SE text, its practical applicability is unclear. Therefore, this study aims to empirically evaluate the Strudel tool as well as four state-of-the-art general purpose toxicity detectors on a large scale SE dataset. On this goal, we empirically developed a rubric to manually label toxic SE interactions. Using this rubric, we manually labeled a dataset of 6,533 code review comments and 4,140 Gitter messages. The results of our analyses suggest significant degradation of all tools' performances on our datasets. Those degradations were significantly higher on our dataset of formal SE communication such as code review than on our dataset of informal communication such as Gitter messages. Two of the models from our study showed significant performance improvements during 10-fold cross validations after we retrained those on our SE datasets. Based on our manual investigations of the incorrectly classified text, we have identified several recommendations for developing an SE specific toxicity detector.	Arxiv	0	['Asif Kamal Turzo', 'Amiangshu Bosu']
448	Making FPGAs Accessible to Scientists and Engineers as Domain Expert Software Programmers with LabVIEW	Hugo A. Andrade	2014-08-20T16:39:15Z	http://arxiv.org/abs/1408.4715v1	In this paper we present a graphical programming framework, LabVIEW, and associated language and libraries, as well as programming techniques and patterns that we have found useful in making FPGAs accessible to scientists and engineers as domain expert software programmers.	Arxiv	0	['Simon Hogg', 'Stephan Ahrends']
449	Natural Language-Oriented Programming (NLOP): Towards Democratizing Software Creation	Amin Beheshti	2024-06-08T09:13:54Z	http://arxiv.org/abs/2406.05409v1	As generative Artificial Intelligence (AI) technologies evolve, they offer unprecedented potential to automate and enhance various tasks, including coding. Natural Language-Oriented Programming (NLOP), a vision introduced in this paper, harnesses this potential by allowing developers to articulate software requirements and logic in their natural language, thereby democratizing software creation. This approach streamlines the development process and significantly lowers the barrier to entry for software engineering, making it feasible for non-experts to contribute effectively to software projects. By simplifying the transition from concept to code, NLOP can accelerate development cycles, enhance collaborative efforts, and reduce misunderstandings in requirement specifications. This paper reviews various programming models, assesses their contributions and limitations, and highlights that natural language will be the new programming language. Through this comparison, we illustrate how NLOP stands to transform the landscape of software engineering by fostering greater inclusivity and innovation.	Arxiv	0	[]
450	ChatGPT as a Software Development Bot: A Project-based Study	Muhammad Waseem	2023-10-20T16:48:19Z	http://arxiv.org/abs/2310.13648v2	Artificial Intelligence has demonstrated its significance in software engineering through notable improvements in productivity, accuracy, collaboration, and learning outcomes. This study examines the impact of generative AI tools, specifically ChatGPT, on the software development experiences of undergraduate students. Over a three-month project with seven students, ChatGPT was used as a support tool. The research focused on assessing ChatGPT's effectiveness, benefits, limitations, and its influence on learning. Results showed that ChatGPT significantly addresses skill gaps in software development education, enhancing efficiency, accuracy, and collaboration. It also improved participants' fundamental understanding and soft skills. The study highlights the importance of incorporating AI tools like ChatGPT in education to bridge skill gaps and increase productivity, but stresses the need for a balanced approach to technology use. Future research should focus on optimizing ChatGPT's application in various development contexts to maximize learning and address specific challenges.	Arxiv	0	['Teerath Das', 'Aakash Ahmad', 'Peng Liang', 'Mahdi Fehmideh', 'Tommi Mikkonen']
451	An Introduction to Software Ecosystems	Tom Mens	2023-07-28T17:58:59Z	http://arxiv.org/abs/2307.15709v1	This chapter defines and presents different kinds of software ecosystems. The focus is on the development, tooling and analytics aspects of software ecosystems, i.e., communities of software developers and the interconnected software components (e.g., projects, libraries, packages, repositories, plug-ins, apps) they are developing and maintaining. The technical and social dependencies between these developers and software components form a socio-technical dependency network, and the dynamics of this network change over time. We classify and provide several examples of such ecosystems. The chapter also introduces and clarifies the relevant terms needed to understand and analyse these ecosystems, as well as the techniques and research methods that can be used to analyse different aspects of these ecosystems.	Arxiv	0	['Coen De Roover']
452	Useful Statistical Methods for Human Factors Research in Software Engineering: A Discussion on Validation with Quantitative Data	Lucas Gren	2019-04-04T10:20:58Z	http://arxiv.org/abs/1904.02457v1	In this paper we describe the usefulness of statistical validation techniques for human factors survey research. We need to investigate a diversity of validity aspects when creating metrics in human factors research, and we argue that the statistical tests used in other fields to get support for reliability and construct validity in surveys, should also be applied to human factors research in software engineering more often. We also show briefly how such methods can be applied (Test-Retest, Cronbach's Œ±, and Exploratory Factor Analysis).	Arxiv	0	['Alfredo Goldman']
453	The Impact of the Object-Oriented Software Evolution on Software Metrics: The Iris Approach	Ra'Fat Al-Msie'deen	2018-03-15T12:33:34Z	http://arxiv.org/abs/1803.09823v1	The Object-Oriented (OO) software system evolves over the time to meet the new requirements. Based on the initial release of software, the continuous modification of software code leads to software evolution. Software needs to evolve over the time to meet the new user's requirements. Software companies often develop variant software of the original one depends on customers' needs. The main hypothesis of this paper states that the software when it evolves over the time, its code continues to grow, change and become more complex. This paper proposes an automatic approach (Iris) to examine the proposed hypothesis. Originality of this approach is the exploiting of the software variants to study the impact of software evolution on the software metrics. This paper presents the results of experiments conducted on three releases of drawing shapes software, sixteen releases of rhino software, eight releases of mobile media software and ten releases of ArgoUML software. Based on the extracted software metrics, It has been found that Iris hypothesis is supported by the computed metrics.	Arxiv	0	['Anas H. Blasi']
454	"How to ""DODGE"" Complex Software Analytics?"	Amritanshu Agrawal	2019-02-05T18:16:56Z	http://arxiv.org/abs/1902.01838v2	"Machine learning techniques applied to software engineering tasks can be improved by hyperparameter optimization, i.e., automatic tools that find good settings for a learner's control parameters.   We show that such hyperparameter optimization can be unnecessarily slow, particularly when the optimizers waste time exploring ""redundant tunings""', i.e., pairs of tunings which lead to indistinguishable results. By ignoring redundant tunings, DODGE, a tuning tool, runs orders of magnitude faster, while also generating learners with more accurate predictions than seen in prior state-of-the-art approaches."	Arxiv	0	['Wei Fu', 'Di Chen', 'Xipeng Shen', 'Tim Menzies']
455	The Impact of Personality on Requirements Engineering Activities: A Mixed-Methods Study	Dulaji Hidellaarachchi	2022-10-13T01:25:00Z	http://arxiv.org/abs/2210.07807v3	Context: Requirements engineering (RE) is an important part of Software Engineering (SE), consisting of various human-centric activities that require the frequent collaboration of a variety of roles. Prior research has shown that personality is one such human aspect that has a huge impact on the success of a software project. However, a limited number of empirical studies exist focusing on the impact of personality on RE activities. Objective: The objective of this study is to explore and identify the impact of personality on RE activities, provide a better understanding of these impacts, and provide guidance on how to better handle these impacts in RE. Method: We used a mixed-methods approach, including a personality test-based survey (50 participants) and an in-depth interview study (15 participants) with software practitioners from around the world involved in RE activities. Results: Through personality test analysis, we found a majority of the practitioners have a high score on agreeableness and conscientiousness traits and an average score on extraversion and neuroticism traits. Through analysis of the interviews, we found a range of impacts related to the personality traits of software practitioners, their team members, and external stakeholders. These impacts can be positive or negative, depending on the RE activities, the overall software development process, and the people involved in these activities. Moreover, we found a set of strategies that can be applied to mitigate the negative impact of personality on RE activities. Conclusion: Our identified impacts of personality on RE activities and mitigation strategies serve to provide guidance to software practitioners on handling such possible personality impacts on RE activities and for researchers to investigate these impacts in greater depth in future.	Arxiv	0	['John Grundy', 'Rashina Hoda', 'Ingo Mueller']
456	Achieving Guidance in Applied Machine Learning through Software Engineering Techniques	Lars Reimann	2022-03-29T12:54:57Z	http://arxiv.org/abs/2203.15510v1	Development of machine learning (ML) applications is hard. Producing successful applications requires, among others, being deeply familiar with a variety of complex and quickly evolving application programming interfaces (APIs). It is therefore critical to understand what prevents developers from learning these APIs, using them properly at development time, and understanding what went wrong when it comes to debugging. We look at the (lack of) guidance that currently used development environments and ML APIs provide to developers of ML applications, contrast these with software engineering best practices, and identify gaps in the current state of the art. We show that current ML tools fall short of fulfilling some basic software engineering gold standards and point out ways in which software engineering concepts, tools and techniques need to be extended and adapted to match the special needs of ML application development. Our findings point out ample opportunities for research on ML-specific software engineering.	Arxiv	0	['G√ºnter Kniesel-W√ºnsche']
457	Software Metrics in Boa Large-Scale Software Mining Infrastructure: Challenges and Solutions	Agnieszka Patalas	2017-03-18T12:51:03Z	http://arxiv.org/abs/1703.06293v1	In this paper, we describe our experience implementing some of classic software engineering metrics using Boa - a large-scale software repository mining platform - and its dedicated language. We also aim to take an advantage of the Boa infrastructure to propose new software metrics and to characterize open source projects by software metrics to provide reference values of software metrics based on large number of open source projects. Presented software metrics, well known and proposed in this paper, can be used to build large-scale software defect prediction models. Additionally, we present the obstacles we met while developing metrics, and our analysis can be used to improve Boa in its future releases. The implemented metrics can also be used as a foundation for more complex explorations of open source projects and serve as a guide how to implement software metrics using Boa as the source code of the metrics is freely available to support reproducible research.	Arxiv	0	['Wojciech Cichowski', 'Micha≈Ç Malinka', 'Wojciech Stƒôpniak', 'Piotr Maƒákowiak', 'Lech Madeyski']
458	AI in Software Engineering: Case Studies and Prospects	Lei Wang	2023-09-27T16:37:05Z	http://arxiv.org/abs/2309.15768v1	Artificial intelligence (AI) and software engineering (SE) are two important areas in computer science. In recent years, researchers are trying to apply AI techniques in various stages of software development to improve the overall quality of software products. Moreover, there are also some researchers focus on the intersection between SE and AI. In fact, the relationship between SE and AI is very weak; however, methods and techniques in one area have been adopted in another area. More and more software products are capable of performing intelligent behaviour like human beings. In this paper, two cases studies which are IBM Watson and Google AlphaGo that use different AI techniques in solving real world challenging problems have been analysed, evaluated and compared. Based on the analysis of both case studies, using AI techniques such as deep learning and machine learning in software systems contributes to intelligent systems. Watson adopts 'decision making support' strategy to help human make decisions; whereas AlphaGo uses 'self-decision making' to choose operations that contribute to the best outcome. In addition, Watson learns from man-made resources such as paper; AlphaGo, on the other hand, learns from massive online resources such as photos. AlphaGo uses neural networks and reinforcement learning to mimic human brain, which might be very useful in medical research for diagnosis and treatment. However, there is still a long way to go if we want to reproduce human brain in machine and view computers as thinkers, because human brain and machines are intrinsically different. It would be more promising to see whether computers and software systems will become more and more intelligent to help with real world challenging problems that human beings cannot do.	Arxiv	0	[]
